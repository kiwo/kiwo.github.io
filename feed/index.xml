<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Mikhail Shilkov</title>
    <link href="https://mikhail.io/feed/" rel="self"/>
    <link href="https://mikhail.io"/>
    <updated>2018-04-16T13:10:33.398Z</updated>
    <id>https://mikhail.io/</id>
    <author>
        <name>Mikhail Shilkov</name>
        <email></email>
    </author>

    
    <entry>
        <title>Awesome F# Exchange 2018</title>
        <link href="https://mikhail.io/2018/04/fsharp-exchange-2018/"/>
        <updated>2018-04-07T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2018-04-07,/2018/04/fsharp-exchange-2018/</id>
        <content type="html"><![CDATA[<p>I&#39;m writing this post in the train to London Stensted, on my way back from F# Exchange 2018
conference.</p>
<p>F# Exchange is a yearly conference taking place in London, and 2018 edition was the first one
for me personally. I also had an honour to speak there about creating Azure Functions with
F#.</p>
<h2 id="impression">Impression</h2>
<p>F# is still relatively niche language, so the conference is not overcrowded, but that gives
it a special feeling of family gathering. There were 162 participants this year, and I have an
impression that every one of them is extremely friendly, enthusiastic and just plain awesome.</p>
<p>The conference itself had 2 tracks of 45-minute talks and 60-minute keynotes. Most talks were
of high quality, and the topics ranging from compiler internals to fun applications like 
music generation, car racing and map drawing.</p>
<p>Both Don Syme, the creator of F#, and Philip Carter, F# program manager, were there and gave
keynotes, but they were careful enough not to draw too much attention on Microsoft and let
the community speak loud.</p>
<h2 id="corridor-track">Corridor Track</h2>
<p>But the talks were just a part of the story. For me, the conference started in the evening
before the first day at the speakers drinks party, and only finished at 1 a.m. after the 
second day (the pubs in London are lovely).</p>
<p>I spoke to so many great people, I learnt a lot, and had fun too. I&#39;ve never seen so many
F# folks at the same place, and I guess there must be something about F# which attracts
the right kind of people to it.</p>
<p>And of course it&#39;s so much fun to meet face-to-face all those twitter, slack, github and 
Channel 9 persona&#39;s and to see that they are actually real people :)</p>
<h2 id="my-talk">My Talk</h2>
<p>The talk I gave was called &quot;Azure F#unctions&quot;. It was not a hard-core F# talk, but people
seemed to be genuinely interested in the topic.</p>
<p>A decent amount of attendees are already familiar with Azure Functions, and many either run 
them in production or plan to do so.</p>
<p>The reference version conflict problem is very well known and raises a lots of questions
or concerns. This even leads to workarounds like transpiling F# Functions to Javascript
with Fable. Yikes.</p>
<p>Durable Functions seem to be sparkling a lot of initial interest. I&#39;ll be definitely
spending more time to play with them, and maybe to make F# story more smooth.</p>
<p>Functions were mentioned in Philip&#39;s keynote as one of the important areas for F# 
application, which is cool. We should spend some extra effort to make the documentation
and onboarding story as smooth as possible.</p>
<h2 id="call-to-action">Call to Action</h2>
<p>Skills Matter is the company behind the conference. Carla, Nicole and others did a great
job preparing the event; everything went smooth, informal and fun.</p>
<p>The videos are already online at <a href="https://skillsmatter.com/conferences/9419-f-sharp-exchange-2018#skillscasts">Skillscasts</a> 
(requires free signup).</p>
<p><a href="https://skillsmatter.com/conferences/10869-f-sharp-exchange-2019">F# Exchange 2019</a> 
super early bird tickets are for sale now and until Monday April 9, go 
get one and join F# Exchange in London next year! </p>
<p>I&#39;m already missing you all.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Azure Durable Functions in F#</title>
        <link href="https://mikhail.io/2018/02/azure-durable-functions-in-fsharp/"/>
        <updated>2018-02-19T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2018-02-19,/2018/02/azure-durable-functions-in-fsharp/</id>
        <content type="html"><![CDATA[<p>Azure Functions are designed for stateless, fast-to-execute,
simple actions. Typically, they are triggered by an HTTP call or a queue message,
then they read something from the storage or database and return the result
to the caller or send it to another queue. All within several seconds at most.</p>
<p>However, there exists a preview of <a href="https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-overview">Durable Functions</a>,
an extension that lets you write stateful functions for long-running workflows.
Here is a picture of one possible workflow from the docs:</p>
<p><img src="https://mikhail.io/2018/02/azure-durable-functions-in-fsharp//fan-out-fan-in.png" alt="Fan-out Fan-in Workflow"></p>
<p>Such workflows might take arbitrary time to complete. Instead of blocking and
waiting for all that period, Durable Functions use the combination of
Storage Queues and Tables to do all the work asynchronously.</p>
<p>The code still <em>feels</em> like one continuous thing because it&#39;s programmed
as a single orchestrator function. So, it&#39;s easier for a human to reason 
about the functionality without the complexities of low-level communication.</p>
<p>I won&#39;t describe Durable Functions any further, just go read
<a href="https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-overview">documentation</a>,
it&#39;s nice and clean.</p>
<h2 id="language-support">Language Support</h2>
<p>As of February 2018, Durable Functions are still in preview. That also means
that language support is limited:</p>
<blockquote>
<p>Currently C# is the only supported language for Durable Functions. This 
includes orchestrator functions and activity functions. In the future, 
we will add support for all languages that Azure Functions supports.</p>
</blockquote>
<p>I was a bit disappointed that F# is not an option. But actually, since
Durable Functions support precompiled .NET assembly model, pretty much
anything doable in C# can be done in F# too.</p>
<p>The goal of this post is to show that you can write Durable Functions in F#.
I used precompiled .NET Standard 2.0 F# Function App running on 2.0 preview
runtime.</p>
<h2 id="orchestration-functions">Orchestration Functions</h2>
<p>The stateful workflows are Azure Functions with a special <code>OrchestrationTrigger</code>.
Since they are asynchronous, C# code is always based on <code>Task</code> and <code>async</code>-<code>await</code>.
Here is a simple example of orchestrator in C#:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;List&lt;<span class="hljs-keyword">string</span>&gt;&gt; Run([OrchestrationTrigger] DurableOrchestrationContext context)
{
    <span class="hljs-keyword">var</span> outputs = <span class="hljs-keyword">new</span> List&lt;<span class="hljs-keyword">string</span>&gt;();

    outputs.Add(<span class="hljs-keyword">await</span> context.CallActivityAsync&lt;<span class="hljs-keyword">string</span>&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Tokyo"</span>));
    outputs.Add(<span class="hljs-keyword">await</span> context.CallActivityAsync&lt;<span class="hljs-keyword">string</span>&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Seattle"</span>));
    outputs.Add(<span class="hljs-keyword">await</span> context.CallActivityAsync&lt;<span class="hljs-keyword">string</span>&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"London"</span>));

    <span class="hljs-comment">// returns ["Hello Tokyo!", "Hello Seattle!", "Hello London!"]</span>
    <span class="hljs-keyword">return</span> outputs;
}
</code></pre>
<p>F# has its own preferred way of doing asynchronous code based on <code>async</code>
computation expression. The direct refactoring could look something like</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> Run(<span class="hljs-meta">[&lt;OrchestrationTrigger&gt;]</span> context: DurableOrchestrationContext) = async {
  <span class="hljs-keyword">let!</span> hello1 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Tokyo"</span>)   |&gt; Async.AwaitTask
  <span class="hljs-keyword">let!</span> hello2 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Seattle"</span>) |&gt; Async.AwaitTask
  <span class="hljs-keyword">let!</span> hello3 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"London"</span>)  |&gt; Async.AwaitTask
  <span class="hljs-keyword">return</span> [hello1; hello2; hello3]
} |&gt; Async.StartAsTask
</code></pre>
<p>That would work for a normal HTTP trigger, but it blows up for the Orchestrator
trigger because multi-threading operations are not allowed:</p>
<blockquote>
<p>Orchestrator code must never initiate any async operation except by 
using the DurableOrchestrationContext API. The Durable Task Framework 
executes orchestrator code on a single thread and cannot interact with 
any other threads that could be scheduled by other async APIs.</p>
</blockquote>
<p>To solve this issue, we need to keep working with <code>Task</code> directly. This is
not very handy with standard F# libraries. So, I pulled an extra NuGet
package <code>TaskBuilder.fs</code> which provides a <code>task</code> computation expression.</p>
<p>The above function now looks very simple:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> Run(<span class="hljs-meta">[&lt;OrchestrationTrigger&gt;]</span> context: DurableOrchestrationContext) = task {
  <span class="hljs-keyword">let!</span> hello1 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Tokyo"</span>)
  <span class="hljs-keyword">let!</span> hello2 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Seattle"</span>)
  <span class="hljs-keyword">let!</span> hello3 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"London"</span>)
  <span class="hljs-keyword">return</span> [hello1; hello2; hello3]
}
</code></pre>
<p>And the best part is that it works just fine.</p>
<p><code>SayHello</code> function is Activity trigger based, and no special effort is required
to implement it in F#:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-meta">[&lt;FunctionName("E1_SayHello")&gt;]</span>
<span class="hljs-keyword">let</span> SayHello(<span class="hljs-meta">[&lt;ActivityTrigger&gt;]</span> name) =
  sprintf <span class="hljs-string">"Hello %s!"</span> name
</code></pre>
<h2 id="more-examples">More Examples</h2>
<p>Durable Functions repository comes with 
<a href="https://github.com/Azure/azure-functions-durable-extension/tree/master/samples/precompiled">a set of 4 samples</a>
implemented in C#. I took all of those samples and ported them over to F#.</p>
<p>You&#39;ve already seen the first <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/12-durable/HelloSequence.fs"><code>Hello Sequence</code> sample</a>
above: the orchestrator calls the activity function 3 times and combines the
results. As simple as it looks, the function will actually run 3 times for each
execution, saving state before each subsequent call.</p>
<p>The second <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/12-durable/BackupSiteContent.fs"><code>Backup Site Content</code> sample</a>
is using this persistence mechanism to run
a potentially slow workflow of copying all files from a given directory to
a backup location. It shows how multiple activities can be executed in
parallel:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> tasks = Array.map (<span class="hljs-keyword">fun</span> f -&gt; backupContext.CallActivityAsync&lt;int64&gt;(<span class="hljs-string">"E2_CopyFileToBlob"</span>, f)) files
<span class="hljs-keyword">let!</span> results = Task.WhenAll tasks
</code></pre>
<p>The third <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/12-durable/Counter.fs"><code>Counter</code> example</a>
demos a potentially infinite actor-like workflow, where state can exist and
evolve for indefinite period of time. The key API calls are based on
<code>OrchestrationContext</code>:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> counterState = counterContext.GetInput&lt;int&gt;()
<span class="hljs-keyword">let!</span> command = counterContext.WaitForExternalEvent&lt;string&gt;(<span class="hljs-string">"operation"</span>)
</code></pre>
<p>The final elaborate <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/12-durable/PhoneVerification.fs"><code>Phone Verification</code> workflow</a>
has several twists, like output binding for activity (<code>ICollector</code> is required
instead of C#&#39;s <code>out</code> parameter), third-party integration (Twilio to send SMSs),
recursive sub-function to loop through several attempts and context-based
timers for reliable timeout implementation.</p>
<p>So, if you happen to be an F# fan, you can still give Durable Functions a try.
Be sure to leave your feedback, so that the library could get even better 
before going GA.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Load Testing Azure SQL Database by Copying Traffic from Production SQL Server</title>
        <link href="https://mikhail.io/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server/"/>
        <updated>2018-02-06T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2018-02-06,/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server/</id>
        <content type="html"><![CDATA[<p>Azure SQL Database is a managed service that provides low-maintenance SQL Server instances in the cloud.
You don&#39;t have to run and update VMs, or even take backups and setup failover clusters.
Microsoft will do administration for you, you just pay an hourly fee.</p>
<p>So, let&#39;s say you decide this value proposition is a good reason to migrate
away from your existing self-hosted SQL Server database running in production and replace
it with Azure SQL Database.</p>
<p>You do the functional testing and eventually everything works like charm. The next set of questions 
is going to be related to Database performance level:</p>
<ul>
<li>Which tier / how many DTU&#39;s should I provision?</li>
<li>How much will it cost?</li>
<li>Will it be able to handle my current production load?</li>
</ul>
<h2 id="dtus">DTUs</h2>
<p>Even if you collect all the specs of the hardware behind your existing SQL Server, you can&#39;t
directly use that knowledge to choose the right Azure SQL Database size.</p>
<p>The sizes are measured in Database Transaction Units (DTUs). These are abstract units
of measure which don&#39;t necessarily mean much on their own. Within a given tier
(Standard / Premium), doubling the DTU amount will double the max throughput.</p>
<p>That doesn&#39;t really help to plan for workload migrations.</p>
<p>There are some ways to estimate the DTU requirements by measuring metrics like CPU
and IOPS on your existing server. Have a look at <a href="http://dtucalculator.azurewebsites.net/">DTU Calculator</a>:
it consists of a data collector and an online converter from metric values to DTUs.</p>
<p>While useful as a first approximation, I&#39;m reluctant to provision Azure SQL Database 
size solely based on such estimates.</p>
<p>My answer to the problem is: Measure It!</p>
<h2 id="synthetic-tests">Synthetic Tests</h2>
<p>Go get a backup of your existing production database and Export / Import it into
Azure SQL Database. Pick the size based on your gut feel, run a load test, evaluate
the results, adjust the size, repeat.</p>
<p>If you know your workload really well, you can create a synthetic test:</p>
<ul>
<li>Create a script or scenario which resembles the real production load</li>
<li>Run it for a given period of time</li>
<li>Measure the DTU&#39;s consumed</li>
</ul>
<p>Unfortunately, I&#39;m yet to see a non-trivial database where I could manually create
such script and be reasonably sure that it reflects the reality. Most of the time
the load is consumer-driven, changes over time and heavily depends on exact query
parameter values.</p>
<p>Which brings me to the need of replaying <em>the actual production workload</em> on Azure
SQL Database.</p>
<h2 id="trace-and-replay">Trace and Replay</h2>
<p>SQL Server comes with a marvelous suite of tools refined over years of its existence.
It includes the tools to capture and replay the queries, so I started with those.</p>
<p>SQL Server Profiler has a trace template called <code>TSQL_Replay</code>:</p>
<blockquote>
<p>This template records information required to replay the trace. Use this template
to perform iterative turning, such as benchmark testing.</p>
</blockquote>
<p>This sounded like what I needed, so I ran the profiler with this template to save
a short trace.</p>
<p>Afterwards, it is possible to use the same SQL Server Profiler to replay the trace against
another target database. So the process looks like this:</p>
<p><img src="https://mikhail.io/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server//sql-trace-replay.png" alt="Replaying Traffic with SQL Server Profiler"></p>
<p>Unfortunately, this didn&#39;t go very well:</p>
<ul>
<li><p>Azure SQL Database is not supported by the tooling. The replay kind of runs, but
it throws lots of errors like reading from non-existent system tables, trying to
switch between databases and so on </p>
</li>
<li><p>Related or not to the previous item, but replay went terribly slow. It
seemed to slow down exponentially over time</p>
</li>
<li><p>The trace file itself was of huge size. Because the template tries to record pretty
much everything, tracing 5 minutes on production produced 10 GB of XML</p>
</li>
<li><p>Replay was not real-time: you first record, then you replay. This might not be a big
issue for many databases, but some of our queries have time parameter, and results would
change if I replay the trace 1 hour later</p>
</li>
</ul>
<p>Just to give you a rough idea, our production database-under-study is handling about
1000 RPC calls per second (mostly stored procedures).</p>
<h2 id="custom-trace-replay">Custom Trace &amp; Replay</h2>
<p>Since off-the-shelf solution didn&#39;t work for me, I decided to come up with my own
custom tool chain. Here is the idea:</p>
<p><img src="https://mikhail.io/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server//sql-trace-replay-event-hubs-functions.png" alt="Replaying Traffic with SQL Server Profiler"></p>
<p>There are two custom steps that I implemented:</p>
<ol>
<li><p>Run a console app which would host a custom trace server. The trace server
receives SQL commands and sends them to Azure Event Hubs in batches</p>
</li>
<li><p>Create an Azure Function application triggered by the Event Hub. Each function
call gets one SQL command to execute and runs it against Azure SQL database that
we are trying to load-test</p>
</li>
</ol>
<p>This setup worked remarkably well for me: I got the real-time replay of SQL commands
from production SQL Server to Azure SQL Database.</p>
<p>The rest of the article describes my setup so that you could reproduce it for your
workload.</p>
<h2 id="azure-sql-database">Azure SQL Database</h2>
<p>Ideally, you want your copy of the database to be as fresh as possible, so that the 
query plans and results match.</p>
<p>Some ideas to accomplish this are given in 
<a href="https://docs.microsoft.com/en-us/azure/sql-database/sql-database-cloud-migrate">SQL Server database migration to SQL Database in the cloud</a>.</p>
<p>Premium RS tier is great for testing, because it is much cheaper than Premium
tier, while it provides the same level of performance.</p>
<h2 id="event-hubs">Event Hubs</h2>
<p>I used Azure Event Hubs as messaging middleware between Trace Server and Replay 
Function App.</p>
<p>I started with Azure Storage Queues, but the server wasn&#39;t able to send messages
fast enough, mostly due to lack of batching.</p>
<p>Event Hubs match naturally my choice of Azure Functions: Functions have a built-in
trigger with dynamic scaling out of the box.</p>
<p>So, I just created a new Event Hub via the portal, with 32 partitions allocated.</p>
<h2 id="trace-definition-file">Trace Definition File</h2>
<p>In order to run a custom Trace Server, you still need a trace definition file.
The built-in template <code>TSQL_Replay</code> mentioned above could work, but
it&#39;s subscribed to way too many events and columns.</p>
<p>Instead, I produced my own trace template with minimal selection.
To do that, open SQL Server Profiler, then navigate to <code>File -&gt; Templates -&gt; New Template</code>,
give it a name and then on <code>Events Selection</code> tab exclude everything except
exactly the commands that you want to replay.</p>
<p>We use stored procedures for pretty much everything, so my selection looked
just like this:</p>
<p><img src="https://mikhail.io/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server//sql-profiler-template.png" alt="SQL Profiler Template"></p>
<p>For the first few runs, I advise you to restrict the trace even further. Click
<code>Column Filters</code> button, select <code>TextData</code> there and set <strong>Like</strong> filter
to a single stored procedure, e.g. matching the pattern <code>%spProductList%</code>.</p>
<p>This way you can debug your whole replay chain without immediately overloading
any part of it with huge stream of commands.</p>
<p>Once done, save the <code>tdf</code> file to disk. An example of such trace definition file
can be found in <a href="https://github.com/mikhailshilkov/sql-trace-replay/tree/master/TDF">my github</a>.</p>
<h2 id="trace-server">Trace Server</h2>
<p>My trace server is a simple C# console application.</p>
<p>Create a new console app and reference a NuGet package <code>Microsoft.SqlServer.SqlManagementObjects</code>.
Mine is of version <code>140.17218.0</code> (latest as of today).</p>
<p>Unfortunately, this NuGet package is not fully self-contained. In order to run
a profiling session, you have to install SQL Server Profiler tool on the machine
where you want to run the trace server.</p>
<p>Chances are that you already have it there, but be sure to update to the matching
version: mine works with <code>17.4 / 14.0.17213.0</code> but refused to work with older 
versions.</p>
<p>Now we can implement our trace server as a console application. The main
method looks like this:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Main</span>(<span class="hljs-params"><span class="hljs-keyword">string</span>[] args</span>) <span class="hljs-comment">// args: &lt;db server name&gt; &lt;db name&gt; &lt;trace file&gt;</span>
</span>{
    <span class="hljs-comment">// 1. Run trace server</span>
    <span class="hljs-keyword">var</span> connectionInfo = <span class="hljs-keyword">new</span> SqlConnectionInfo(args[<span class="hljs-number">0</span>])
    {
        DatabaseName = args[<span class="hljs-number">1</span>],
        UseIntegratedSecurity = <span class="hljs-literal">true</span>
    };
    <span class="hljs-keyword">var</span> trace = <span class="hljs-keyword">new</span> TraceServer();
    trace.InitializeAsReader(connectionInfo, args[<span class="hljs-number">2</span>]);

    <span class="hljs-comment">// 2. Continuously read traces and send them to event hubs</span>
    <span class="hljs-keyword">var</span> tokenSource = <span class="hljs-keyword">new</span> CancellationTokenSource();
    <span class="hljs-keyword">var</span> readerTask = Task.Factory.StartNew(() =&gt; ReadTrace(trace, tokenSource.Token), tokenSource.Token);
    <span class="hljs-keyword">var</span> senderTask = Task.Factory.StartNew(() =&gt; SendToEventHubs(tokenSource.Token), tokenSource.Token);

    <span class="hljs-comment">// 3. Stop the trace</span>
    Console.WriteLine(<span class="hljs-string">"Press any key to stop..."</span>);
    Console.ReadKey();
    tokenSource.Cancel();
    Task.WaitAll(readerTask, senderTask);
}
</code></pre>
<p>The first block initializes SQL connection using command line arguments and integrated
security, and then starts the Trace Server.</p>
<p>Because of the large volume, I made trace reader and event sender to work on separate
threads. They talk to each other via a concurrent queue:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">readonly</span> ConcurrentQueue&lt;<span class="hljs-keyword">string</span>&gt; eventQueue = <span class="hljs-keyword">new</span> ConcurrentQueue&lt;<span class="hljs-keyword">string</span>&gt;();
</code></pre>
<p>Finally, when operator presses any key, the cancellation is requested and the reader and
sender get shut down.</p>
<p>Trace Reader task is a loop crunching though trace data and sending the SQL statements
(with some exclusions) to the concurrent in-memory queue:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">ReadTrace</span>(<span class="hljs-params">TraceServer trace, CancellationToken token</span>)
</span>{ 
    <span class="hljs-keyword">while</span> (trace.Read() &amp;&amp; !token.IsCancellationRequested)
    {
        <span class="hljs-keyword">var</span> eventClass = trace[<span class="hljs-string">"EventClass"</span>].ToString();
        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">string</span>.Compare(eventClass, <span class="hljs-string">"RPC:Completed"</span>) == <span class="hljs-number">0</span>)
        {
            <span class="hljs-keyword">var</span> textData = trace[<span class="hljs-string">"TextData"</span>].ToString();
            <span class="hljs-keyword">if</span> (!textData.Contains(<span class="hljs-string">"sp_reset_connection"</span>)
                &amp;&amp; !textData.Contains(<span class="hljs-string">"sp_trace"</span>)
                &amp;&amp; !textData.Contains(<span class="hljs-string">"sqlagent"</span>))
            {
                eventQueue.Enqueue(textData);
            }
        }
    }

    trace.Stop();
    trace.Close();
}
</code></pre>
<p>Event Sender is dequeueing SQL commands from in-memory queue to collect batches of
events. As soon as a batch fills up, it gets dispatched to Event Hub:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">SendToEventHubs</span>(<span class="hljs-params">CancellationToken token</span>)
</span>{
    <span class="hljs-keyword">var</span> client = EventHubClient.CreateFromConnectionString(EventHubsConnectionString);
    <span class="hljs-keyword">var</span> batch = client.CreateBatch();
    <span class="hljs-keyword">while</span> (!token.IsCancellationRequested)
    {
        <span class="hljs-keyword">if</span> (!eventQueue.TryDequeue(<span class="hljs-keyword">out</span> <span class="hljs-keyword">string</span> sql))
        {
            Thread.Sleep(<span class="hljs-number">10</span>);
            <span class="hljs-keyword">continue</span>;
        }

        <span class="hljs-keyword">var</span> eventData = <span class="hljs-keyword">new</span> EventData(Encoding.UTF8.GetBytes(sql));
        <span class="hljs-keyword">if</span> (!batch.TryAdd(eventData) &amp;&amp; batch.Count &gt; <span class="hljs-number">0</span>)
        {
            client.SendAsync(batch.ToEnumerable())
                .ContinueWith(OnAsyncMethodFailed, token, TaskContinuationOptions.OnlyOnFaulted, TaskScheduler.Default);
            batch = client.CreateBatch();
            batch.TryAdd(eventData);
        }
    }
}
</code></pre>
<p>If your trace doesn&#39;t produce so many messages, you will probably want to periodically send out the batches
even before they get full, just to keep that process closer to real time.</p>
<p>Note that sender does not await <code>SendAsync</code> call. Instead, we only subscribe to failures via <code>OnAsyncMethodFailed</code>
callback to print it to console:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">OnMyAsyncMethodFailed</span>(<span class="hljs-params">Task task</span>)
</span>{
    Console.WriteLine(task.Exception?.ToString() ?? <span class="hljs-string">"null error"</span>);
}
</code></pre>
<p>And that concludes the implementation of the Trace Server. SQL commands now go to Event Hub, to be picked
up by Trace Replay.</p>
<h2 id="trace-replay-function-app">Trace Replay Function App</h2>
<p>To replay those traces against the target Azure SQL Database, I could make another console
application which would contain <code>EventProcessorHost</code> to receive and process SQL commands.</p>
<p>However, under high load a single machine might not be able to keep up with executing all
those commands in real time.</p>
<p>Instead, I decided to distribute such Replay App over multiple machines. To deploy a 
DDoS network, if you will :)</p>
<p>And I don&#39;t have to build, find, configure and synchronize all those servers myself, since we
are living in the world of serverless.</p>
<p><a href="https://azure.microsoft.com/en-us/services/functions/">Azure Functions</a> are the perfect tool for this job. Once you start the trace server,
Function App will start scaling up based on the amount of events in Event Hub, and will
expand until it catches up with the workload.</p>
<p>But as long as you don&#39;t run the trace server, it won&#39;t consume any servers and won&#39;t cost you
a dime. </p>
<p>Here is the implementation of Trace Replay Azure Function:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Replay</span>
{
    [<span class="hljs-meta">FunctionName(<span class="hljs-meta-string">"Replay"</span>)</span>]
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Run</span>(<span class="hljs-params">
        [EventHubTrigger(<span class="hljs-string">"sqltrace"</span>, Connection = <span class="hljs-string">"EventHubsConn"</span></span>)] <span class="hljs-keyword">string</span> sql,
        TraceWriter log)
    </span>{
        <span class="hljs-keyword">var</span> commandName = sql
            .Split(<span class="hljs-literal">null</span>)
            .SkipWhile(r =&gt; r != <span class="hljs-string">"exec"</span> &amp;&amp; r != <span class="hljs-string">"sp_executesql"</span>)
            .FirstOrDefault(r =&gt; !r.Contains(<span class="hljs-string">"exec"</span>)) ?? <span class="hljs-string">"&lt;empty&gt;"</span>;

        <span class="hljs-keyword">var</span> stopwatch = <span class="hljs-keyword">new</span> Stopwatch();
        stopwatch.Start();

        <span class="hljs-keyword">try</span>
        {
            <span class="hljs-keyword">using</span> (<span class="hljs-keyword">var</span> sqlConnection = <span class="hljs-keyword">new</span> SqlConnection(AzureSqlConnectionString))
            <span class="hljs-keyword">using</span> (<span class="hljs-keyword">var</span> cmd = <span class="hljs-keyword">new</span> SqlCommand())
            {
                sqlConnection.Open();

                cmd.CommandText = sql;
                cmd.CommandType = CommandType.Text;

                cmd.Connection = sqlConnection;

                <span class="hljs-keyword">int</span> count = <span class="hljs-number">0</span>;
                <span class="hljs-keyword">using</span> (<span class="hljs-keyword">var</span> reader = cmd.ExecuteReader())
                {
                    <span class="hljs-keyword">while</span> (reader.Read())
                    {
                        count++;
                    }
                }

                log.Info(<span class="hljs-string">$"Processed <span class="hljs-subst">{commandName}</span> in <span class="hljs-subst">{stopwatch.ElapsedMilliseconds}</span> ms with <span class="hljs-subst">{count}</span> rows"</span>);
            }
        }
        <span class="hljs-keyword">catch</span> (Exception ex)
        {
            log.Error(<span class="hljs-string">$"Error in <span class="hljs-subst">{commandName}</span> in <span class="hljs-subst">{stopwatch.ElapsedMilliseconds}</span> <span class="hljs-subst">{ex.Message}</span>"</span>);
            <span class="hljs-keyword">throw</span>;
        }
    }
}
</code></pre>
<p>It&#39;s super simple: the function gets a SQL statement, executes it with <code>SqlCommand</code> class and
logs the result with timing and returned row count. And that&#39;s everything required to start
bombarding my Azure SQL Database.</p>
<h2 id="evaluating-results">Evaluating Results</h2>
<p>The purpose of this whole exercise was to evaluate whether a provisioned DTU level
is enough to stand the load comparable to existing production.</p>
<p>So, after I ran the test, I could browse through the DTU usage chart in Azure portal to
get overall usage statistics.</p>
<p>I&#39;ve also spent quite some time analyzing the usage breakdown as reported by <code>sp_BlitzCache</code>
from <a href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit">Responder Kit</a>. 
Please note that it&#39;s not officially supported for Azure SQL Database, but it seems to work 
reasonably well.</p>
<p>Be sure to re-run your experiments multiple times, at different days and time intervals.</p>
<p>The full code sample can be found in <a href="https://github.com/mikhailshilkov/sql-trace-replay/tree/master/TDF">my github</a>.</p>
<p>I hope Azure SQL Database will perform to your expectations and within your budget. But
hope is not a good strategy, so go ahead and try it out!</p>
<p>Happy DDoS-ing!</p>
]]></content>
    </entry>
    
    <entry>
        <title>Tic-Tac-Toe with F#, Azure Functions, HATEOAS and Property-Based Testing</title>
        <link href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/"/>
        <updated>2018-01-23T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2018-01-23,/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/</id>
        <content type="html"><![CDATA[<p>This post describes a toy application that I&#39;ve built with F# and Azure Functions
in about 1 day of work. It shows a simple end-to-end implementation with some 
useful techniques applied, and can be used as a reference point for anyone interested in
one of the topics mentioned in the title.</p>
<p>The requirements for my application are quite simple:</p>
<ul>
<li>Implement the game of Tic-Tac-Toe for a human player to play against the computer</li>
<li>The field is 3x3, the player to have three-in-a-row wins</li>
<li>After the game, the score is calculated based on the number of moves combined 
with the duration of the game</li>
<li>The history of players&#39; scores is persisted and presented as the leaderboard</li>
</ul>
<p>Below I go through the code step by step. Feel free to jump to the part which interests
you the most: 
<a href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/#DomainModelling">Domain Modelling</a>, 
<a href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/#AzureFunctions">Azure Functions</a>, 
<a href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/#HATEOAS">HATEOAS</a>,
<a href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/#PropertyBasedTesting">Property-Based Testing</a>.</p>
<p>The game is online, so you can play it <a href="https://tictactoefs.azurewebsites.net/home">here</a>.</p>
<p>The full source code can be found in <a href="https://github.com/mikhailshilkov/tictactoe">my github</a>.</p>
<p><a name="DomainModelling" href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/undefined"></a></p>
<h2 id="modeling-the-game-with-types">Modeling the Game with Types</h2>
<p>I start with a domain model. The model is composed of immutable F# types (records and discriminated
unions) and pure functions.</p>
<p>We have two players, so we need a type for them:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Player</span> </span>= X | O
</code></pre>
<p>In addition, there is a useful function to return the other player based on the given one.
Simple pattern-matching will do:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">module</span> Player =
  <span class="hljs-keyword">let</span> other = <span class="hljs-keyword">function</span> | X -&gt; O | O -&gt; X
</code></pre>
<p>The domain code is the most important part of the application, so I want it to be covered
by unit tests. Of course, the above function doesn&#39;t really warrant testing, but it&#39;s a nice
and simple way to try out <a href="https://fsharpforfunandprofit.com/posts/property-based-testing/">Property-Based Testing</a>. 
That is, instead of defining specific tests, we define properties which hold for any valid input.</p>
<p>For <code>other</code> function, I came up with two properties:</p>
<ul>
<li>Other player is not equal to original player</li>
<li>Other player of other player is the player itself</li>
</ul>
<p>Here is the code with <a href="https://github.com/haf/expecto">Expecto</a> and <a href="https://github.com/fscheck/FsCheck">FsCheck</a>:</p>
<pre class="highlight"><code class="hljs fs">testProperty <span class="hljs-string">"Other player is not equal to player"</span> &lt;| <span class="hljs-keyword">fun</span> x -&gt;
  Expect.notEqual x (Player.other x) <span class="hljs-string">"Other should be different from original"</span>

testProperty <span class="hljs-string">"Other player of other player is the player itself"</span> &lt;| <span class="hljs-keyword">fun</span> x -&gt;
  Expect.equal x (Player.other (Player.other x)) <span class="hljs-string">"Other other should be equal to original"</span>
</code></pre>
<p>Let&#39;s move on to modelling the game. I decided to define a union type to be used for
horizontal and vertical positions of the cells:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Position</span> </span>= One | Two | Three
</code></pre>
<p>I could use the normal integers instead, but I don&#39;t want to be worried about validating
the ranges all the time.</p>
<p>My first record type models the move, or action done by a player: it has <code>X</code> and <code>Y</code>
positions of the chosen cell, plus the player information:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Move</span> </span>= {
  X: Position
  Y: Position
  By: Player
}
</code></pre>
<p>The following type <code>RunningGame</code> has just two properties, but its shape defines the
design of the whole application:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">RunningGame</span> </span>= {
  MovesDone: Move list
  PossibleMoves: Move list
}
</code></pre>
<p>This type models any state of the game which is not finished yet. </p>
<p><code>MovesDone</code> represents the ordered log of all moves, so we have the complete history 
of actions at any time. Event Sourcing in small.</p>
<p>Equally importantly, there is a list of all possible moves at this point of the game.
I could get away without this property: in the end, it can always be derived from
the history of done moves and 3x3 size of the field.</p>
<p>However, having the list of possible moves simplifies the design of all the decision
maker (client) code:</p>
<ul>
<li>Clients don&#39;t have to search for remaining cells based on move log</li>
<li>Validation of a move received from clients gets trivial: just check that it&#39;s in
the list of possible moves</li>
<li>Bot implementation gets easy: it just needs to pick one of the valid moves. The
most trivial bot is a one-liner: it picks a random move from the collection</li>
<li>Tests take advantage of this in a similar way, see <a href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/#PropertyBasedTesting">Game Tests</a> below</li>
<li>We build a nice bridge into HATEOAS-style API, where links provided in the response
correspond to possible moves, see <a href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/#HATEOAS">REST API</a> below</li>
</ul>
<p>Now, we can model a game which is already finished:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">GameOutcome</span> </span>= Won <span class="hljs-keyword">of</span> Player | Tie

<span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">FinishedGame</span> </span>= {
  MovesDone: Move list
  Outcome: GameOutcome
}
</code></pre>
<p>Each finished game has a list of moves and the outcome: either one player won, or there
was a tie.</p>
<p>Each state of a game can be described by the union of the previous two states:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">GameState</span> </span>= 
  | Finished <span class="hljs-keyword">of</span> FinishedGame
  | InProgress <span class="hljs-keyword">of</span> RunningGame
</code></pre>
<h2 id="modeling-game-flow">Modeling Game Flow</h2>
<p>Now, when all the types are in place, we can model the game flow. The flow is a sequence
of transitions between game states, implemented with pure functions.</p>
<p>First, each game starts at the same state, which is an empty field, and X turn. Here
is the value which represents this initial state:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">module</span> Game =
  <span class="hljs-keyword">let</span> initialState = 
    <span class="hljs-keyword">let</span> positions = [One; Two; Three]
    <span class="hljs-keyword">let</span> cells = seq { 
      <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> positions <span class="hljs-keyword">do</span>
         <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> positions <span class="hljs-keyword">do</span>
            <span class="hljs-keyword">yield</span> { X = x; Y = y; By = X }
      }
    { MovesDone = []; PossibleMoves = List.ofSeq cells }
</code></pre>
<p>After each move is made, we need a function to evaluate move outcome: whether current
game is finished or is still in progress. I defined a function <code>evaluate</code> for that:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> <span class="hljs-keyword">private</span> evaluate (history: Move list): GameOutcome option = ...
</code></pre>
<p>I don&#39;t show the full body here, since it&#39;s quite boring in evaluating rows, columns
and diagonals for three-in-a-row. See the <a href="https://github.com/mikhailshilkov/tictactoe/blob/master/TicTacToe/Game.fs#L42-L56">full code</a> 
if you want to.</p>
<p>The following function is even more important: that&#39;s the main domain function called 
<code>makeMove</code>. Its type is <code>RunningGame -&gt; Move -&gt; GameState</code> which perfectly communicates
its intent: given a running game and a move, it returns the game state after the move.
Note that</p>
<ul>
<li>You can&#39;t pass a finished game as an argument, because making a move on finished game
doesn&#39;t make sense</li>
<li>The result <em>can</em> be a finished game</li>
</ul>
<p>Here is the function implementation:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> makeMove (game: RunningGame) (move: Move): GameState =
  <span class="hljs-keyword">let</span> movesDone = move :: game.MovesDone
  <span class="hljs-keyword">match</span> evaluate movesDone <span class="hljs-keyword">with</span>
  | Some result -&gt; Finished { MovesDone = movesDone; Outcome = result }
  | None -&gt;
    <span class="hljs-keyword">let</span> possibleMoves = 
      List.except [move] game.PossibleMoves
      |&gt; List.map (<span class="hljs-keyword">fun</span> m -&gt; { m <span class="hljs-keyword">with</span> By = Player.other m.By })
    InProgress { MovesDone = movesDone; PossibleMoves = possibleMoves }
</code></pre>
<p>It works like this:</p>
<ul>
<li>Prepend the new move to moves done</li>
<li>Evaluate the game result of these combined moves</li>
<li>If the result is known, return a <code>Finished</code> game with calculated outcome</li>
<li>If the result is not clear yet, return <code>InProgress</code> game with possible
moves same as before, but excluding the move and assigned to the other player</li>
</ul>
<p>Tic-Tic-Toe is two-player game, so I defined another function which runs
a turn of 2 moves by 2 players, given the decision making functions of both
players (so it&#39;s a higher-order function):</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> makeRound player1 player2 gameState =
  <span class="hljs-keyword">let</span> newGameState = player1 gameState |&gt; makeMove gameState
  <span class="hljs-keyword">match</span> newGameState <span class="hljs-keyword">with</span>
  | Finished _ -&gt; newGameState
  | InProgress p -&gt; player2 p |&gt; makeMove p
</code></pre>
<p>Looks almost like monadic <code>bind</code> operation...</p>
<p><a name="PropertyBasedTesting" href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/undefined"></a></p>
<h2 id="property-based-testing">Property-Based Testing</h2>
<p>I&#39;ve already shown two simplistic properties for <code>other</code> function.</p>
<p>It&#39;s a bit more challenging to come up with invariant properties when it
comes to testing the game itself. After some brainstorming, I&#39;ve made the
following list:</p>
<ul>
<li>The game is never finished after 4 moves</li>
<li>The game is always finished after 9 moves</li>
<li>X and 0 have to make moves in turns</li>
<li>Player wins by filling one column</li>
<li>Player wins by filling one row</li>
<li>Player wins by filling diagonal</li>
<li>Evaluate a known tie</li>
</ul>
<p>Each property-based test should accept some input from the testing framework.
It should then evaluate the test against this input and assert the invariants.
If the property holds for any possible valid input, the test is green.</p>
<p>I decided to structure my property tests in the following way:</p>
<ul>
<li>Each test accepts a list of non-negative integers</li>
<li>Each integer is interpreted as an index of a possible move to select at turn <code>i</code>.
That means that the test receives a sequence which uniquely identifies the moves
to be made</li>
<li>We can restrict this sequence to a scenario under test, e.g. make it less
than 4 moves, or exactly 9 moves, or pick moves from a limited subset of all
possible moves</li>
<li>We apply the moves to calculate the end result</li>
<li>We assert that the result confirms the property under test</li>
</ul>
<p>Now, it&#39;s the responsibility of property based testing framework to generate
all kinds of input lists to try to break our property. If it succeeds, it will
print the exact input which causes the test to fail.</p>
<p>Here is how one such test is implemented.</p>
<p>A helper function plays a sequence of indexes as moves:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> playSequence moves = 
  <span class="hljs-keyword">let</span> playOne s i =
    <span class="hljs-keyword">match</span> s <span class="hljs-keyword">with</span>
    | InProgress p -&gt; Game.makeMove p (p.PossibleMoves.[i % p.PossibleMoves.Length])
    | _ -&gt; s
  List.fold playOne (InProgress Game.initialState) moves
</code></pre>
<p>Then the property &quot;The game is always finished after 9 moves&quot; is simply:</p>
<pre class="highlight"><code class="hljs fs">testProp <span class="hljs-string">"The game is always finished after 9 moves"</span> &lt;| <span class="hljs-keyword">fun</span> (Gen.ListOf9 xs) -&gt;
  <span class="hljs-keyword">let</span> result = playSequence xs
  Expect.isTrue (Game.isFinished result) <span class="hljs-string">"Game should be finished"</span>
</code></pre>
<p>Note the restriction <code>Gen.ListOf9 xs</code> that we put on the input sequence. It&#39;s a
generator that I <a href="https://github.com/mikhailshilkov/tictactoe/blob/master/TicTacToe.Tests/Gen.fs#L31-L32">defined</a>, 
so that the list always contains exactly 9 elements.</p>
<p>Other property tests follow a similar pattern, you can see them 
<a href="https://github.com/mikhailshilkov/tictactoe/blob/master/TicTacToe.Tests/GameTests.fs">here</a>.</p>
<p><a name="HATEOAS" href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/undefined"></a></p>
<h2 id="rest-api">REST API</h2>
<p>Now, when I&#39;m done with Game domain model, I want to define API that our HTTP
service will expose to the clients. I define my API in REST model.</p>
<p>The main resource is <code>/game</code> resource. To start a new game, a client has to send
<code>POST</code> command:</p>
<pre class="highlight"><code class="hljs stata"><span class="hljs-keyword">POST</span> /game
Content-<span class="hljs-keyword">Type</span>: application/json

{ <span class="hljs-string">"name"</span>: <span class="hljs-string">"Mikhail"</span> }
</code></pre><p>And the response body is JSON which denotes a new game created:</p>
<pre class="highlight"><code class="hljs json">{
    <span class="hljs-attr">"id"</span>: <span class="hljs-string">"5d7b2261"</span>,
    <span class="hljs-attr">"busyCells"</span>: [],
    <span class="hljs-attr">"links"</span>: [
        {
            <span class="hljs-attr">"rel"</span>: <span class="hljs-string">"x1y1"</span>,
            <span class="hljs-attr">"href"</span>: <span class="hljs-string">"/game/5d7b2261/move/0"</span>
        },
        {
            <span class="hljs-attr">"rel"</span>: <span class="hljs-string">"x1y2"</span>,
            <span class="hljs-attr">"href"</span>: <span class="hljs-string">"/game/5d7b2261/move/1"</span>
        },
        // ... <span class="hljs-number">7</span> more links follow
    ]
}
</code></pre>
<p>The response contains a game ID and the list of occupied cells, empty for now,
because no moves have been made.</p>
<p>More importantly, it contains a list of links, each one of which has a <code>rel</code>
field representing a cell, and a link. The client should <code>POST</code> to this link
if it wants to make a move on the corresponding cell:</p>
<pre class="highlight"><code class="hljs awk">POST <span class="hljs-regexp">/game/</span><span class="hljs-number">5</span>d7b2261<span class="hljs-regexp">/move/</span><span class="hljs-number">1</span>
</code></pre><p>And the response is:</p>
<pre class="highlight"><code class="hljs json">{
    <span class="hljs-attr">"id"</span>: <span class="hljs-string">"5d7b2261"</span>,
    <span class="hljs-attr">"result"</span>: <span class="hljs-literal">null</span>,
    <span class="hljs-attr">"busyCells"</span>: [
        {
            <span class="hljs-attr">"name"</span>: <span class="hljs-string">"x2y3"</span>,
            <span class="hljs-attr">"value"</span>: <span class="hljs-string">"O"</span>
        },
        {
            <span class="hljs-attr">"name"</span>: <span class="hljs-string">"x1y2"</span>,
            <span class="hljs-attr">"value"</span>: <span class="hljs-string">"X"</span>
        }
    ],
    <span class="hljs-attr">"links"</span>: [
        {
            <span class="hljs-attr">"rel"</span>: <span class="hljs-string">"x1y1"</span>,
            <span class="hljs-attr">"href"</span>: <span class="hljs-string">"/game/5d7b2261/move/0"</span>
        },
        {
            <span class="hljs-attr">"rel"</span>: <span class="hljs-string">"x1y3"</span>,
            <span class="hljs-attr">"href"</span>: <span class="hljs-string">"/game/5d7b2261/move/1"</span>
        },
        // ... <span class="hljs-number">5</span> more links follow
    ]
}
</code></pre>
<p>It has the same structure as before, but now two cells are occupied: one <code>X</code> and one <code>O</code>. The
list of links now has only 7 links, based on the count of free cells.</p>
<p>The client keeps navigating the links until it gets non-empty <code>result</code> field:</p>
<pre class="highlight"><code class="hljs json">{
    <span class="hljs-attr">"id"</span>: <span class="hljs-string">"5d7b2261"</span>,
    <span class="hljs-attr">"result"</span>: <span class="hljs-string">"You Win!"</span>,
    <span class="hljs-attr">"busyCells"</span>: [
        {
            <span class="hljs-attr">"name"</span>: <span class="hljs-string">"x3y1"</span>,
            <span class="hljs-attr">"value"</span>: <span class="hljs-string">"X"</span>
        },
        {
            <span class="hljs-attr">"name"</span>: <span class="hljs-string">"x3y2"</span>,
            <span class="hljs-attr">"value"</span>: <span class="hljs-string">"O"</span>
        },
        // ... more cells here
    ],
    <span class="hljs-attr">"links"</span>: [],
    <span class="hljs-attr">"score"</span>: <span class="hljs-number">401</span>
}
</code></pre><p>This denotes the end of the game. There&#39;s no more links to navigate, so the client knows it
has to stop playing.</p>
<p>This API is designed in HATEOAS-style (Hypermedia as the Engine of Application State). The
clients only need to know the initial URL, while all the other URLs are received from the
previous responses. It resembles the way a human navigates websites.</p>
<p><a name="AzureFunctions" href="https://mikhail.io/2018/01/tictactoe-with-fsharp-azurefunctions-hateoas-and-property-based-testing/undefined"></a></p>
<h2 id="azure-functions">Azure Functions</h2>
<p>I implemented the above API with Azure Functions. I used .NET Standard based v2 runtime
with precompiled F# functions.</p>
<p>The initial <code>POST /game</code> request is handled by <code>Start</code> function:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">GameRequest</span> </span>= { Name: string }

<span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Cell</span> </span>= { Name: string; Value: string }
<span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Link</span> </span>= { Rel:  string; Href:  string }

<span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">GameDTO</span> </span>= {
  Id: string
  Result: string
  BusyCells: Cell list
  Links: Link list
  Score: int
}

<span class="hljs-meta">[&lt;FunctionName("Start")&gt;]</span>
<span class="hljs-keyword">let</span> start(<span class="hljs-meta">[&lt;HttpTrigger(AuthorizationLevel.Anonymous, "POST", Route = "game")&gt;]</span> req: GameRequest,
          <span class="hljs-meta">[&lt;Table("TicTacToe")&gt;]</span> store: ICollector&lt;GameEntity&gt;) =
  <span class="hljs-keyword">let</span> gameid = Guid.NewGuid().ToString()
  <span class="hljs-keyword">let</span> state = InProgress Game.initialState
  <span class="hljs-keyword">let</span> serializedState = JsonConvert.SerializeObject state
  store.Add(GameEntity(PartitionKey = <span class="hljs-string">"default"</span>, RowKey = gameid, Name = req.Name, State = serializedState))
  ObjectResult(Api.serialize gameid state <span class="hljs-number">0</span>)
</code></pre>
<p>The outline of this function:</p>
<ul>
<li>It&#39;s triggered by HTTP POST request, as configured for <code>req</code> parameter</li>
<li>The request body is parsed to <code>GameRequest</code> type containing player name</li>
<li>It generates a new game ID</li>
<li>It creates initial game state of empty field</li>
<li>It serializes the state and saves it to Table Storage with <code>store</code> output binding</li>
<li>It returns HTTP body with 
<a href="https://github.com/mikhailshilkov/tictactoe/blob/master/TicTacToe.Functions/Api.fs#L30-L51">serialized</a> game response of type <code>GameDTO</code></li>
</ul>
<p>The second Function <code>Play</code> handles the moves:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-meta">[&lt;FunctionName("Play")&gt;]</span>
<span class="hljs-keyword">let</span> play(<span class="hljs-meta">[&lt;HttpTrigger(AuthorizationLevel.Anonymous, "POST", Route = "game/{gameid}/move/{index}")&gt;]</span> 
         req: HttpRequest, gameid: string, index: int,
         <span class="hljs-meta">[&lt;Table("TicTacToe", "default", "{gameid}")&gt;]</span> entity: GameEntity) =
  <span class="hljs-keyword">let</span> state = JsonConvert.DeserializeObject&lt;GameState&gt; entity.State
  <span class="hljs-keyword">match</span> state <span class="hljs-keyword">with</span>
  | Finished _ -&gt; BadRequestResult() :&gt; IActionResult
  | InProgress p <span class="hljs-keyword">when</span> index &lt; <span class="hljs-number">0</span> || index &gt;= p.PossibleMoves.Length -&gt; BadRequestResult() :&gt; IActionResult
  | InProgress p -&gt; 
    <span class="hljs-keyword">let</span> result = Game.makeRound (<span class="hljs-keyword">fun</span> _ -&gt; p.PossibleMoves.[index]) Bot.pickMove p
    entity.State &lt;- JsonConvert.SerializeObject result
    entity.Score &lt;- Scoring.calculateScore (DateTime.UtcNow - entity.StartedAt).TotalMilliseconds result
    ObjectResult(Api.serialize gameid result entity.Score) :&gt; IActionResult
</code></pre>
<p>The outline is very similar:</p>
<ul>
<li>It&#39;s triggered by a <code>POST</code> request with a URL template containing game ID and move index</li>
<li>It has an in/out Table Storage binding which reads the serialized state saved after previous
game and move requests</li>
<li>It validates the state: if the game is already finished, or if the move index is not in the valid range,
<code>Bad Request</code> HTTP status is returned</li>
<li>If the move is valid, it runs the round, including bot play</li>
<li>It also calculates the score, which is going to be non-zero only for finished games</li>
<li>The game state and the score are saved to Table Storage entity (that&#39;s the only mutation in the whole
application)</li>
</ul>
<h2 id="bot">Bot</h2>
<p>Azure Function above used a <code>Bot.pickMove</code> function which I haven&#39;t described yet.</p>
<p>This function has the type <code>RunningGame -&gt; Move</code>, exactly what is expected by <code>makeRound</code> game
function. Its goal is to pick the <code>O</code> move for any given game-in-progress.</p>
<p>Obviously, 3x3 Tic-Tac-Toe is a very simple game and it&#39;s quite easy to make a perfectly
playing bot. This wasn&#39;t the goal though: it&#39;s more fun for a human to win.</p>
<p>So, actually, the only property test that I ended up implementing is the following:</p>
<pre class="highlight"><code class="hljs fs">testProp <span class="hljs-string">"Bot is able to play O at any possible position"</span> &lt;| <span class="hljs-keyword">fun</span> (Gen.ListOfNonNegative xs) -&gt;
  <span class="hljs-keyword">let</span> human i p _ = p.PossibleMoves.[i % p.PossibleMoves.Length]
  <span class="hljs-keyword">let</span> round s i =
    <span class="hljs-keyword">match</span> s <span class="hljs-keyword">with</span>
    | InProgress p -&gt; Game.makeRound (human i p) Bot.pickMove p
    | _ -&gt; s
  List.fold round (InProgress Game.initialState) xs |&gt; ignore
</code></pre>
<p>It makes sure that for any possible sequence of human moves, bot is actually able to make
<em>any</em> move of its own. Bot just shouldn&#39;t crash :)</p>
<p>My very first implementation of the bot was just picking a random move. Such bot is fine,
but it&#39;s too boring to play against.</p>
<p>So, my current bot implementation has 3 rules:</p>
<ul>
<li>If there is a move that immediately wins the game, do that move</li>
<li>If possible, don&#39;t pick a move which leads to immediate loss after the next human move</li>
<li>Otherwise, pick a random move</li>
</ul>
<p>I implemented the bot using the approach described in my 
<a href="https://mikhail.io/2016/07/building-a-poker-bot-functional-fold-as-decision-tree-pattern/">Functional Fold as Decision Tree Pattern</a>
post:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> pickMove (game: RunningGame) = 
  [winNow O; notLoseNow; pickRandom]
  |&gt; Seq.ofList
  |&gt; Seq.choose (<span class="hljs-keyword">fun</span> x -&gt; x game)
  |&gt; Seq.head
</code></pre>
<p>So, there is a prioritized list of decision functions. The first one returning <code>Some</code>
decision will be promoted to final decision.</p>
<p>And here are those functions:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> winNow player (game: RunningGame) =
  <span class="hljs-keyword">let</span> isWin = <span class="hljs-keyword">function</span> | Finished { Outcome = Won x } <span class="hljs-keyword">when</span> x = player -&gt; <span class="hljs-keyword">true</span> | _ -&gt; <span class="hljs-keyword">false</span>
  game.PossibleMoves
  |&gt; List.tryFind (<span class="hljs-keyword">fun</span> move -&gt; Game.makeMove game move |&gt; isWin)

<span class="hljs-keyword">let</span> notLoseNow (game: RunningGame) =
  <span class="hljs-keyword">let</span> canLose = <span class="hljs-keyword">function</span> 
    | InProgress p -&gt; <span class="hljs-keyword">match</span> winNow X p <span class="hljs-keyword">with</span> | Some _ -&gt; <span class="hljs-keyword">true</span> | None -&gt; <span class="hljs-keyword">false</span>
    | _ -&gt; <span class="hljs-keyword">false</span>
  <span class="hljs-keyword">let</span> notLosingMoves =
    game.PossibleMoves
    |&gt; List.filter (<span class="hljs-keyword">fun</span> move -&gt; Game.makeMove game move |&gt; canLose |&gt; not)
  <span class="hljs-keyword">if</span> List.isEmpty notLosingMoves &amp;&amp; notLosingMoves.Length &lt; game.PossibleMoves.Length <span class="hljs-keyword">then</span> None
  <span class="hljs-keyword">else</span> Some (notLosingMoves.[random.Next notLosingMoves.Length])

<span class="hljs-keyword">let</span> pickRandom (game: RunningGame) = 
  Some (game.PossibleMoves.[random.Next game.PossibleMoves.Length])
</code></pre>
<p>Such rule-based setup is easy to extend, and also to test when it becomes needed.</p>
<h2 id="score-calculation">Score Calculation</h2>
<p>Last twist to the application is the scoring system. If a human player wins or gets a tie,
they are assigned a numeric score, which can be then compared to the historic leaderboard
of all players.</p>
<p>The score is calculated based on two principles: the less moves you make, and the faster
you play, the higher the score is. Move count is more important than timing.</p>
<p>These principles are nicely expressed as property tests:</p>
<pre class="highlight"><code class="hljs fs">testProp <span class="hljs-string">"The score of faster game is not lower than slower game"</span> 
  &lt;| <span class="hljs-keyword">fun</span> (Gen.Positive duration1) (Gen.Positive duration2) game -&gt;
  <span class="hljs-keyword">let</span> (slower, faster) = maxmin id duration1 duration2
  <span class="hljs-keyword">let</span> scoreFaster = Scoring.calculateScore faster game
  <span class="hljs-keyword">let</span> scoreSlower = Scoring.calculateScore slower game
  Expect.isGreaterThanOrEqual scoreFaster scoreSlower <span class="hljs-string">"Bigger duration has lower score (or same)"</span>

testProp <span class="hljs-string">"The score of won game in less moves is greater than game with more moves"</span> 
  &lt;| <span class="hljs-keyword">fun</span> (Gen.Positive duration1) (Gen.Positive duration2) game1 game2 -&gt;
  <span class="hljs-keyword">let</span> (slower, faster) = maxmin id duration1 duration2
  <span class="hljs-keyword">let</span> (moreMoves, lessMoves) = maxmin List.length game1 game2
  <span class="hljs-keyword">let</span> score1 = Scoring.calculateScore slower (Finished { Outcome = Won X; MovesDone = lessMoves })
  <span class="hljs-keyword">let</span> score2 = Scoring.calculateScore faster (Finished { Outcome = Won X; MovesDone = moreMoves })
  <span class="hljs-keyword">if</span> moreMoves.Length = lessMoves.Length <span class="hljs-keyword">then</span>
    Expect.isGreaterThanOrEqual score1 score2 <span class="hljs-string">"Bigger duration has lower score (or same)"</span>
  <span class="hljs-keyword">else</span>
    Expect.isGreaterThan score1 score2 <span class="hljs-string">"More moves have lower score"</span>
</code></pre>
<p>Note that tests are parameterized for durations and game states. We don&#39;t have to come up with specific
scenarios: the framework should take care of those.</p>
<p>One of the possible implementations for scoring is:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> calculateScore duration (state: GameState) =
  <span class="hljs-keyword">let</span> durationScore = (<span class="hljs-number">100.0</span> * (<span class="hljs-number">1.0</span> - duration / (duration + <span class="hljs-number">10000.0</span>))) |&gt; int
  <span class="hljs-keyword">match</span> state <span class="hljs-keyword">with</span>
  | Finished { Outcome = Won X; MovesDone = ms } -&gt; (<span class="hljs-number">11</span> - ms.Length) * <span class="hljs-number">100</span> + durationScore
  | Finished { Outcome = Tie } -&gt; durationScore
  | _ -&gt; <span class="hljs-number">0</span>
</code></pre>
<p>Now, the leaderboard piece. You&#39;ve already seen the bits of this functionality in Azure Functions: 
they store the game state into Azure Table Storage.</p>
<p>There is another Azure Function which handles <code>GET</code> requests to <code>/leaderboard</code> resource. It
loads all the past games from Table Storage, and then passes them to leaderboard calculation
function below:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> calculateLeaderboard top ns =
  ns
  |&gt; Seq.filter (<span class="hljs-keyword">fun</span> entity -&gt; snd entity &gt; <span class="hljs-number">0</span> &amp;&amp; not (String.IsNullOrEmpty (fst entity)))
  |&gt; Seq.sortByDescending snd
  |&gt; Seq.truncate top
  |&gt; Seq.mapi (<span class="hljs-keyword">fun</span> index entity -&gt; { Index = index + <span class="hljs-number">1</span>; Name = fst entity; Score = snd entity })
</code></pre>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>Ok, the application is simple, but the blog post ended up being quite long. Thank you if you
made it so far.</p>
<p>I touched base on several important concepts and tools, which can be useful apart or in
combination.</p>
<p>Please leave a comment if such kind of articles is useful, and which part you found most
inspirational or boring.</p>
<p>The full source code can be found in <a href="https://github.com/mikhailshilkov/tictactoe">my github</a>.</p>
<p>Happy coding!</p>
]]></content>
    </entry>
    
    <entry>
        <title>Azure Functions Get More Scalable and Elastic</title>
        <link href="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic/"/>
        <updated>2017-12-13T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-12-13,/2017/12/azure-functions-get-more-scalable-and-elastic/</id>
        <content type="html"><![CDATA[<p>Back in August this year, I&#39;ve posted 
<a href="https://mikhail.io/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic/">Azure Functions: Are They Really Infinitely Scalable and Elastic?</a>
with two experiments about Azure Function App auto scaling. I ran a simple
CPU-bound function based on Bcrypt hashing, and measured how well Azure
was running my Function under load.</p>
<p>The results were rather pessimistic. Functions were scaling up to many 
instances, but there were significant delays in doing so, so the processing
slowed down up to 40 minutes.</p>
<p>Azure Functions team notified me that they rolled out an updated version of
the service, which should significantly improve my results.</p>
<p>So I ran the exact same tests again, and got the new results. I will show
these results below.</p>
<p><em>TL;DR. Scaling responsiveness improved significantly. The max delay reduced
from 40 to 6 minutes. There are some improvements still to be desired: 
sub-minute latency is not yet reachable for similar scenarios.</em></p>
<h2 id="setup">Setup</h2>
<p>See the Function code and the description of the two experiments in
<a href="https://mikhail.io/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic/">my previous article</a>.</p>
<h2 id="experiment-1-steady-load">Experiment 1: Steady Load</h2>
<p>In &quot;Steady Load&quot; scenario 100,000 messages were sent to the queue at
constant pace, evenly spread over 2 hours.</p>
<p>Here are the <strong>old</strong> metrics of Queue Backlog and Instance Count over time:</p>
<p><img src="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic//FunctionAppScaling.png" alt="Function App Scaling (Old)"></p>
<p><em>Old charts are shown in gray background</em></p>
<p>You can see a huge delay of almost one hour before the function caught up 
to speed of incoming messages and half-an-hour more before the backlog
got cleared.</p>
<p>The <strong>new</strong> results on the same chart after the runtime update:</p>
<p><img src="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic//FunctionAppScalingNew.png" alt="Function App Scaling (New)"></p>
<p>This looks much better. The maximum backlog is 7 times lower; there&#39;s almost
no initial delay before the auto scaling kicks in; and overall instance 
allocation is much more stable.</p>
<hr>
<p>One more chart is from the same experiment, but it shows slightly different 
metrics. The <strong>old</strong> results of Delay (Age) in seconds and Processing Rate 
in messages per minute:</p>
<p><img src="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic//FunctionAppDelay.png" alt="Function App Delay"></p>
<p>The <strong>new</strong> chart after the runtime update:</p>
<p><img src="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic//FunctionAppDelayNew.png" alt="Function App Delay"></p>
<p>Again, much less delay overall, and processing rate more-or-less stabilizes 
after the first 15 minutes.</p>
<h2 id="experiment-2-spiky-load">Experiment 2: Spiky Load</h2>
<p>The second experiment spanned over 5 hours. The messages were sent mostly
at low-ish fixed rate, except for 5 periods of sudden spikes. The
green line on the charts below shows these spikes very well.</p>
<p>At the first run 4 months ago, Functions runtime had troubles keeping up
to speed even between those bursts of messages.</p>
<p>Here is the chart of the <strong>old</strong> spiky load processing:</p>
<p><img src="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic//SpikyLoadProcessing.png" alt="Spicky Load Processing (Old)"></p>
<p>You can see that the backlog after each spike goes down really slow. The
blue line of processing rate doesn&#39;t match the green line almost nowhere,
which reveals the struggle to adapt.</p>
<p>The <strong>new</strong> results of the same chart after the runtime update are quite
different:</p>
<p><img src="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic//SpikyLoadProcessingNew.png" alt="Spicky Load Processing (New)"></p>
<p>Notice how the backlog is empty and the blue processing rate matches exactly
the incoming rate during all time except after traffic bursts. The queue goes 
up during each spike, but the processing rate immediately accelerates too,
and the crisis is gone within 15 minutes.</p>
<h2 id="conclusions">Conclusions</h2>
<p>Azure Functions team is clearly working on improvements. While the results in
August were puzzling or even embarrassing, the December benchmark makes much
more sense.</p>
<p>Looks like Azure Functions are now suitable for CPU-intensive data processing
scenarios with flexible load, targeting the maximum delay at about several
minutes.</p>
<p>Obviously, the results are not perfect just yet. Here&#39;s what still can be
done better:</p>
<ul>
<li><p><strong>Scale faster initially</strong>. In the first experiment, the biggest delay
appeared right after the start, when the backlog was growing linearly for 
10 minutes. &quot;0 to 100&quot; might not be a very realistic scenario, but probably
that&#39;s how many folks will test Functions against their workloads.</p>
</li>
<li><p><strong>Do not scale down that fast after backlog goes to 0</strong>. Every time the
queue backlog goes to 0, the runtime kills the biggest part of instances
almost immediately. During my runs, this caused the queue to grow again without
a good reason from user&#39;s perspective.</p>
</li>
<li><p><strong>Do not allow the backlog to grow without message spikes</strong>. Related to
the previous item, but slightly different focus. When the load is stable,
I would expect the runtime to keep my queue as close to empty as possible.
I guess Azure tries to minimize the resources that it consumes behind
the scenes, but this should be balanced in favor of user experience.</p>
</li>
<li><p><strong>Make scaling algorithms more open</strong>. It&#39;s a black box right now. I
would love to see some documentation, if not code, to be published about
what exactly to expect from Consumption Plan auto scaling.</p>
</li>
</ul>
<p>I&#39;ll be running more scaling experiments with other types of workloads in the
nearest future, so... more benchmarks are coming.</p>
<p>Happy scaling!</p>
]]></content>
    </entry>
    
    <entry>
        <title>Precompiled Azure Functions in F#</title>
        <link href="https://mikhail.io/2017/12/precompiled-azure-functions-in-fsharp/"/>
        <updated>2017-12-03T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-12-03,/2017/12/precompiled-azure-functions-in-fsharp/</id>
        <content type="html"><![CDATA[<p><em>This post is giving a start to 
<a href="https://sergeytihon.com/2017/10/22/f-advent-calendar-in-english-2017/">F# Advent Calendar in English 2017</a>. 
Please follow the calendar for all the great posts to come.</em></p>
<p>Azure Functions is a &quot;serverless&quot; cloud offering from Microsoft. It
allows you to run your custom code as response to events in the cloud. 
Functions are very easy to
start with; and you only pay per execution - with free allowance sufficient
for any proof-of-concept, hobby project or even low-usage production loads.
And when you need more, Azure will scale your project up automatically.</p>
<p>F# is one of the officially supported languages for Azure Functions.
Originally, F# support started with F# Script files (authored directly
in Azure portal or copied from local editor), so you can find many articles
online to get started, e.g.
<a href="http://brandewinder.com/2017/02/11/fsharp-azure-function-from-the-ground-up-part-1/">Creating an Azure Function in F# from the ground up</a> and
<a href="http://brandewinder.com/2017/03/06/fsharp-azure-function-from-the-ground-up-part-2/">Part 2</a>
by Mathias Brandewinder.</p>
<p>However, I find script-based model a bit limited. In today&#39;s article I
will focus on creating Azure Functions as precompiled .NET libraries.
Along the way, I&#39;ll use cross-platform tools like .NET Core and VS Code,
and I&#39;ll show how to integrate Functions with some popular tools
like Suave and Paket.</p>
<h2 id="create-a-project">Create a Project</h2>
<p>You can follow this walkthrough on Windows or Mac, just make sure that
you have <code>.NET Core 2</code> and <code>Node.js 8.x</code> with <code>npm</code> installed. My editor of
choice is Visual Studio Code with Ionide plugin.</p>
<p>I&#39;ll show you how to create a new F# Function App from scratch. If you want to
jump to runnable project, you can get it from 
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/6-precompiled-timer">my github</a>.</p>
<p>We start with creating a new F# library project for .NET Standard 2. Run
in your command line:</p>
<pre class="highlight"><code class="hljs sh">dotnet new classlib --language F<span class="hljs-comment"># --name HelloFunctions</span>
</code></pre>
<p>This command creates a folder with two files: <code>HelloFunctions.fsproj</code> project
file and <code>Library.fs</code> source code file.</p>
<p>Now, add a reference to Azure Functions NuGet package:</p>
<pre class="highlight"><code class="hljs sh">dotnet add package Microsoft.NET.Sdk.Functions
</code></pre>
<h2 id="define-a-function">Define a Function</h2>
<p>Open <code>Library.fs</code> code file and change it to the following code:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">namespace</span> HelloFunctions

<span class="hljs-keyword">open</span> System
<span class="hljs-keyword">open</span> Microsoft.Azure.WebJobs
<span class="hljs-keyword">open</span> Microsoft.Azure.WebJobs.Host

<span class="hljs-keyword">module</span> Say =
  <span class="hljs-keyword">let</span> <span class="hljs-keyword">private</span> daysUntil (d: DateTime) =
    (d - DateTime.Now).TotalDays |&gt; int

  <span class="hljs-keyword">let</span> hello (timer: TimerInfo, log: TraceWriter) =
    <span class="hljs-keyword">let</span> christmas = <span class="hljs-keyword">new</span> DateTime(<span class="hljs-number">2017</span>, <span class="hljs-number">12</span>, <span class="hljs-number">25</span>)

    daysUntil christmas
    |&gt; sprintf <span class="hljs-string">"%d days until Christmas"</span>
    |&gt; log.Info
</code></pre>
<p>We defined a function <code>hello</code> which should be triggered by Functions runtime
based on time intervals. Every time the function is called, we log how many
days we still need to wait before Christmas 2017.</p>
<p>To convert this simple F# function to an Azure Function, create a folder called
<code>Hello</code> (or choose any other name) next to the project file and add 
<code>function.json</code> file in there:</p>
<pre class="highlight"><code class="hljs json">{
  <span class="hljs-attr">"bindings"</span>: [
    {
      <span class="hljs-attr">"name"</span>: <span class="hljs-string">"timer"</span>,
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"timerTrigger"</span>,
      <span class="hljs-attr">"schedule"</span>: <span class="hljs-string">"0 * * * * *"</span>
    }
  ],
  <span class="hljs-attr">"scriptFile"</span>: <span class="hljs-string">"../bin/HelloFunctions.dll"</span>,
  <span class="hljs-attr">"entryPoint"</span>: <span class="hljs-string">"HelloFunctions.Say.hello"</span>
}
</code></pre>
<p>We defined that:</p>
<ul>
<li>Our function is triggered by timer</li>
<li>It runs every minute at 0 seconds</li>
<li>The entry point is our <code>hello</code> function in the compiled assembly</li>
</ul>
<h2 id="prepare-local-runtime">Prepare Local Runtime</h2>
<p>There are a couple more configuration files needed to be able to
run the Function App locally. <code>host.json</code> defines hosting parameters; empty
file will do for now:</p>
<pre class="highlight"><code class="hljs json">{
}
</code></pre>
<p>Most triggers need to connect to a Storage Account. For examples, timer
trigger uses it to hold leases to define which running instance will 
actually execute the action every minute. Copy a connection string to your 
Storage Account (local Storage emulator is fine too) and put it into 
<code>local.settings.json</code> file:</p>
<pre class="highlight"><code class="hljs json">{
  <span class="hljs-attr">"IsEncrypted"</span>: <span class="hljs-literal">false</span>,
  <span class="hljs-attr">"Values"</span>: {
    <span class="hljs-attr">"AzureWebJobsStorage"</span>: <span class="hljs-string">"...your connection string..."</span>
  }
}
</code></pre>
<p>Note that this file is only used for local development and is not published
to Azure by default.</p>
<p>Finally, we need to modify <code>fsproj</code> file to make the build tool copy those
files into <code>bin</code> folder. Add the following section in there:</p>
<pre class="highlight"><code class="hljs xml"><span class="hljs-tag">&lt;<span class="hljs-name">ItemGroup</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">Content</span> <span class="hljs-attr">Include</span>=<span class="hljs-string">"Hello\function.json"</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">CopyToOutputDirectory</span>&gt;</span>PreserveNewest<span class="hljs-tag">&lt;/<span class="hljs-name">CopyToOutputDirectory</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">Content</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">Content</span> <span class="hljs-attr">Include</span>=<span class="hljs-string">"host.json"</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">CopyToOutputDirectory</span>&gt;</span>PreserveNewest<span class="hljs-tag">&lt;/<span class="hljs-name">CopyToOutputDirectory</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">Content</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">Content</span> <span class="hljs-attr">Include</span>=<span class="hljs-string">"local.settings.json"</span>&gt;</span>
    <span class="hljs-tag">&lt;<span class="hljs-name">CopyToOutputDirectory</span>&gt;</span>PreserveNewest<span class="hljs-tag">&lt;/<span class="hljs-name">CopyToOutputDirectory</span>&gt;</span>
  <span class="hljs-tag">&lt;/<span class="hljs-name">Content</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">ItemGroup</span>&gt;</span>
</code></pre>
<h2 id="run-app-locally">Run App Locally</h2>
<p>The first step is to build and publish our Function App with <code>dotnet</code>
commands:</p>
<pre class="highlight"><code class="hljs sh">dotnet build
dotnet publish
</code></pre>
<p>The first line produces the dll file and the second line copies it
and all of its dependencies to <code>publish</code> folder.</p>
<p>The nice thing about Azure Functions is that you can easily run them
locally on a development machine. Execute the following command to 
install the runtime and all the required libraries:</p>
<pre class="highlight"><code class="hljs sh">npm install -g azure-functions-core-tools@core
</code></pre>
<p>This will add a <code>func</code> CLI to your system which is the tool to
use for all Function related operations.</p>
<p>Navigate to <code>bin\Debug\netstandard2.0\publish</code> folder and run <code>func start</code> 
from there. You should see that your app is now running, and your timer
function is scheduled for execution:</p>
<p><img src="https://mikhail.io/2017/12/precompiled-azure-functions-in-fsharp/./funcstart.png" alt="Function App Start"></p>
<p>Once the next minute comes, the timer will trigger and you will see
messages in the log:</p>
<p><img src="https://mikhail.io/2017/12/precompiled-azure-functions-in-fsharp/./funcran.png" alt="Timer Trigger Working"></p>
<h2 id="integrate-into-vs-code-">Integrate into VS Code </h2>
<p>You are free to use full Visual Studio or any editor to develop Function
Apps in F#. I&#39;ve been mostly using VS Code for this purpose, and I believe
it&#39;s quite popular among F# community.</p>
<p>If you use VS Code, be sure to setup the tasks that you can use from within
the editor. I usually have at least 3 tasks: &quot;build&quot; (<code>dotnet build</code>),
&quot;publish&quot; (<code>dotnet publish</code>) and &quot;run&quot; (<code>func start --script-root bin\\debug\\netstandard2.0\\publish</code>),
with shortcuts configured to all of them.</p>
<p>You can find an example of <code>tasks.json</code> file
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/6-precompiled-timer/.vscode/tasks.json">here</a>.</p>
<p>Also, check out <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions">Azure Functions Extension</a>.</p>
<h2 id="deploy-to-azure">Deploy to Azure</h2>
<p>You can deploy the exact same application binaries to Azure. Start by 
creating an empty Function App in the portal, or via Azure CLI (<code>func</code> CLI
does not support that).</p>
<p>Then run the following command to deploy your precompiled function to
this app:</p>
<pre class="highlight"><code class="hljs sh">func azure functionapp publish &lt;FunctionAppName&gt;
</code></pre>
<p>At the first run, it will verify your Azure credentials.</p>
<p>In real-life production scenarios your workflow is probably going to be
similar to this:</p>
<ul>
<li>Change Function App code</li>
<li>Run it locally to test the change</li>
<li>Push the code changes to the source control repository</li>
<li>Have your CI/CD pipeline build it, run the tests and then push
the binaries to Azure Functions environment</li>
</ul>
<h2 id="http-trigger">HTTP Trigger</h2>
<p>Timer-triggered functions are useful, but that&#39;s just one limited use case.
Several other event types can trigger Azure Functions, and for all of them
you can create precompiled functions and run them locally.</p>
<p>The most ubiquotous trigger for any serverless app is probably HTTP. So,
for the rest of the article I will focus on several approaches to 
implement HTTP functions. Nonetheless, the same techique can be applied to
other triggers too.</p>
<p>F# code for the simplest HTTP Function can look like this:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">namespace</span> PrecompiledApp

<span class="hljs-keyword">open</span> Microsoft.AspNetCore.Mvc
<span class="hljs-keyword">open</span> Microsoft.AspNetCore.Http
<span class="hljs-keyword">open</span> Microsoft.Azure.WebJobs.Host

<span class="hljs-keyword">module</span> PrecompiledHttp =

  <span class="hljs-keyword">let</span> run(req: HttpRequest, log: TraceWriter) =
    log.Info(<span class="hljs-string">"F# HTTP trigger function processed a request."</span>)
    ContentResult(Content = <span class="hljs-string">"HO HO HO Merry Christmas"</span>, ContentType = <span class="hljs-string">"text/html"</span>)
</code></pre>
<p>You can find a full example of HTTP Function App 
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/5-precompiled">here</a>.</p>
<p>This code is using ASP.NET Core classes for request and response. It&#39;s still
just an F# function, so we need to bind it to a trigger in <code>function.json</code>:</p>
<pre class="highlight"><code class="hljs json">{
  <span class="hljs-attr">"bindings"</span>: [
    {
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"httpTrigger"</span>,
      <span class="hljs-attr">"methods"</span>: [<span class="hljs-string">"get"</span>],
      <span class="hljs-attr">"authLevel"</span>: <span class="hljs-string">"anonymous"</span>,
      <span class="hljs-attr">"name"</span>: <span class="hljs-string">"req"</span>,
      <span class="hljs-attr">"route"</span>: <span class="hljs-string">"hellosanta"</span>
    }
  ],
  <span class="hljs-attr">"scriptFile"</span>: <span class="hljs-string">"../bin/PrecompiledApp.dll"</span>,
  <span class="hljs-attr">"entryPoint"</span>: <span class="hljs-string">"PrecompiledApp.PrecompiledHttp.run"</span>
}
</code></pre>
<p>If you run the app, the function will be hosted at localhost</p>
<p><img src="https://mikhail.io/2017/12/precompiled-azure-functions-in-fsharp/./httpstart.png" alt="HTTP Trigger Working"></p>
<p>And a request to <code>http://localhost:7071/api/hellosanta</code> will get responded
with our &quot;HO HO HO&quot; message.</p>
<p>This function is of &quot;Hello World&quot; level, but the fact that it&#39;s inside a
normal F# library gives you lots of power.</p>
<p>Let&#39;s see at some examples of how to use it.</p>
<h2 id="suave-function">Suave Function</h2>
<p>What can we do to enhance developer experience? We can use our 
favourite F# libraries.</p>
<p><a href="http://suave.io/">Suave</a> is one of the most popular libraries to 
implement Web API&#39;s with. And we can use it in Azure Functions too!</p>
<p>Let&#39;s first make a small twist to HTTP trigger definition in <code>function.json</code>:</p>
<pre class="highlight"><code class="hljs undefined">"bindings": [
  {
    "type": "httpTrigger",
    "methods": ["get"],
    "authLevel": "anonymous",
    "name": "req",
    "route": "{*anything}"
  }
],
</code></pre>
<p>Binding now defines a wildcard route to redirect all requests 
to this function. That&#39;s because we want Suave to take care of routing
for us.</p>
<p>The definition of such routing will look familiar to all Suave users:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">module</span> App =
  <span class="hljs-keyword">open</span> Suave
  <span class="hljs-keyword">open</span> Suave.Successful
  <span class="hljs-keyword">open</span> Suave.Operators
  <span class="hljs-keyword">open</span> Suave.Filters

  <span class="hljs-keyword">let</span> app = 
    GET &gt;=&gt; choose
      [ path <span class="hljs-string">"/api/what"</span> &gt;=&gt; OK <span class="hljs-string">"Every time we love, every time we give, it's Christmas."</span>
        path <span class="hljs-string">"/api/when"</span> &gt;=&gt; OK <span class="hljs-string">"Christmas isn't a season. It's a feeling."</span>
        path <span class="hljs-string">"/api/how"</span> &gt;=&gt; OK <span class="hljs-string">"For it is in giving that we receive."</span> ]
</code></pre>
<p>Azure Function is just a one-liner wiring Suave app into the pipeline:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">module</span> Http =
  <span class="hljs-keyword">open</span> Suave.Azure.Functions.Context

  <span class="hljs-keyword">let</span> run req =
    req |&gt; runWebPart App.app  |&gt; Async.StartAsTask
</code></pre>
<p>The heavy lifting is done by <code>runWebPart</code> function, which is a utility
function defined in the same application. You can see the full code
of this wiring in <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/7-suave">my repo</a>.</p>
<p>Run the application and request the URL <code>http://localhost:7071/api/what</code> 
to see the function in action.</p>
<p>This example is very simple, but you can do lots of powerful stuff with Suave!
Most probably, you shouldn&#39;t go over the root and try to fit whole
mulpti-resource REST API into a single Azure Function. But it might still
make sense to keep related HTTP calls together, and Suave can help to keep
it cleaner.</p>
<h2 id="managing-dependencies-with-paket">Managing Dependencies with Paket</h2>
<p>Once your Function App becomes bigger and you start using multiple F#
projects, it makes sense to switch to <a href="https://fsprojects.github.io/Paket/">Paket</a>
package manager.</p>
<p>It is totally possible to use Paket with Azure Functions. There isn&#39;t much
specific to Azure Functions, really. Here is an example of <code>paket.dependecies</code>
file</p>
<pre class="highlight"><code class="hljs stylus">source https:<span class="hljs-comment">//www.nuget.org/api/v2</span>

framework: &gt;= netstandard2.<span class="hljs-number">0</span>
nuget FSharp<span class="hljs-selector-class">.Core</span>
nuget Microsoft<span class="hljs-selector-class">.NET</span><span class="hljs-selector-class">.Sdk</span><span class="hljs-selector-class">.Functions</span>
nuget Microsoft<span class="hljs-selector-class">.AspNetCore</span><span class="hljs-selector-class">.Mvc</span><span class="hljs-selector-class">.Core</span>
</code></pre><p>that I used in <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/8-paket">example</a> 
which demonstrates Paket + Functions combination.</p>
<h2 id="attribute-based-functions">Attribute-Based Functions</h2>
<p>Up until now, we were writing <code>function.json</code> files manually for each 
function. This is not very tedious, but it is error prone. Microsoft offers an alternative 
programming model where these files are auto-generated by Functions SDK.</p>
<p>This programming model is based on attributes, which are similar to WebJobs 
SDK attributes. With this approach, there&#39;s no <code>function.json</code> file in 
the project. Instead, the function declaration is decorated with attributes:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-meta">[&lt;FunctionName("AttributeBased")&gt;]</span>
<span class="hljs-keyword">let</span> run(<span class="hljs-meta">[&lt;HttpTrigger&gt;]</span> req: HttpRequest, log: TraceWriter)
</code></pre>
<p>The same development flow still works. Once you run <code>dotnet build</code>, a new 
<code>function.json</code> file will be generated and placed into <code>bin</code> folder. Functions 
runtime will be able to use it to run the function as usual.</p>
<p>Note that the generated file looks a bit different from the manual 
equivalent:</p>
<ol>
<li><p>It manifests itself with</p>
<pre class="highlight"><code class="hljs undefined"> "generatedBy": "Microsoft.NET.Sdk.Functions.Generator-1.0.6",
 "configurationSource": "attributes",
</code></pre>
</li>
<li><p>In case you use input and output bindings, you won&#39;t be able to see them
in the generated file. Only trigger will be visible in <code>json</code>. Don&#39;t worry,
input and output bindings will still work.</p>
</li>
</ol>
<p>You can find an example of HTTP function with attributes 
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/9-attributes">here</a>.</p>
<p>There are pro&#39;s and con&#39;s in this model. Obviously, not having to write
JSON files manually is beneficial. Some people find the binding attributes
really ugly though, especially when you have 3 or 4 bindings and each has 
multiple parameters. </p>
<p>My preference is to use attributes, but don&#39;t mix attribute decoration
with real code. I.e. keep the Function&#39;s body to a simple 1-liner, and
delegate the call to a properly defined F# function with the actual
domain logic.</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>Lots of F# users value the language for how quickly one can be productive
with it: based on concise syntax, powerful libraries and tools like FSI.</p>
<p>In my opinion, Azure Functions fit nicely into the picture. It takes just
several minutes before you can run your first Function App on developer
machine, and then seamlessly transfer it into the cloud.</p>
<p>I&#39;ve prepared a github repository where you can find more
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples">Examples of Azure Functions implemented in F#</a>.</p>
<p>Merry Serverless Functional Christmas!</p>
]]></content>
    </entry>
    
    <entry>
        <title>Azure F#unctions Talk at FSharping Meetup in Prague</title>
        <link href="https://mikhail.io/2017/11/azure-functions-fsharp-talk/"/>
        <updated>2017-11-10T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-11-10,/2017/11/azure-functions-fsharp-talk/</id>
        <content type="html"><![CDATA[<p>On November 8th 2017 I gave a talk about developing Azure Functions
in F# at
<a href="https://www.meetup.com/FSharping/events/244137693/">FSharping</a>
meetup in Prague. </p>
<p>I really enjoyed giving this talk: the audience was
great and asked awesome questions. One more prove that F# community is
so welcoming and energizing!</p>
<p>All the demos of that session can be found in my
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples">github repository</a>.</p>
<p>The slides were only a small portion of my talk, but you can see them
below anyways.</p>
<p>Link to full-screen HTML slides: 
<a href="https://mikhail.io/talks/fsharping-azure-functions/">Azure F#unctions</a></p>
<p>Slides on SlideShare:</p>
<iframe src="//www.slideshare.net/slideshow/embed_code/key/oQIZywbdCRXdQA" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> 
</iframe> 

<p>Thanks for attending my talk! Feel free to post any feedback in the comments.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Azure Function Triggered by Azure Event Grid</title>
        <link href="https://mikhail.io/2017/10/azure-function-triggered-by-azure-event-grid/"/>
        <updated>2017-10-05T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-10-05,/2017/10/azure-function-triggered-by-azure-event-grid/</id>
        <content type="html"><![CDATA[<p><em>Update: I missed the elephant in the room. There actually exists a specialized
trigger for Event Grid binding. In the portal, just select <code>Experimental</code>
in <code>Scenario</code> drop down while creating the function. In precompiled 
functions, reference <code>Microsoft.Azure.WebJobs.Extensions.EventGrid</code> NuGet
package.</em></p>
<p><em>The rest of the article describes my original approach to trigger an
Azure Function from <a href="https://azure.microsoft.com/en-us/services/event-grid/">Azure Event Grid</a> 
with generic Web Hook trigger.</em></p>
<p>Here are the steps to follow:</p>
<h2 id="create-a-function-with-webhook-trigger">Create a Function with Webhook Trigger</h2>
<p>I&#39;m not aware of a specialized trigger type for Event Grid, so
I decided to use Generic Webhook trigger (which is essentially an
HTTP trigger).</p>
<p>I used the Azure Portal to generate a function, so here is the 
<code>function.json</code> that I got:</p>
<pre class="highlight"><code class="hljs json">{
  <span class="hljs-attr">"bindings"</span>: [
    {
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"httpTrigger"</span>,
      <span class="hljs-attr">"direction"</span>: <span class="hljs-string">"in"</span>,
      <span class="hljs-attr">"webHookType"</span>: <span class="hljs-string">"genericJson"</span>,
      <span class="hljs-attr">"name"</span>: <span class="hljs-string">"req"</span>
    },
    {
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"http"</span>,
      <span class="hljs-attr">"direction"</span>: <span class="hljs-string">"out"</span>,
      <span class="hljs-attr">"name"</span>: <span class="hljs-string">"res"</span>
    }
  ],
  <span class="hljs-attr">"disabled"</span>: <span class="hljs-literal">false</span>
}
</code></pre>
<p>For precompiled functions, just decorate it with <code>HttpTriggerAttribute</code> with
POST method:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Task&lt;HttpResponseMessage&gt; <span class="hljs-title">Run</span>(<span class="hljs-params">
    [HttpTrigger(AuthorizationLevel.Function, <span class="hljs-string">"post"</span></span>)] HttpRequestMessage req)
</span></code></pre>
<h2 id="parse-the-payload">Parse the Payload</h2>
<p>Events from Event Grid will arrive in a specific predefined JSON format.
Here is an example of events to expect:</p>
<pre class="highlight"><code class="hljs json">[{
  <span class="hljs-attr">"id"</span>: <span class="hljs-string">"0001"</span>,
  <span class="hljs-attr">"eventType"</span>: <span class="hljs-string">"MyHelloWorld"</span>,
  <span class="hljs-attr">"subject"</span>: <span class="hljs-string">"Hello World!"</span>,
  <span class="hljs-attr">"eventTime"</span>: <span class="hljs-string">"2017-10-05T08:53:07"</span>,
  <span class="hljs-attr">"data"</span>: {
    <span class="hljs-attr">"hello"</span>: <span class="hljs-string">"world"</span>
  },
  <span class="hljs-attr">"topic"</span>: <span class="hljs-string">"/SUBSCRIPTIONS/GUID/RESOURCEGROUPS/NAME/PROVIDERS/MICROSOFT.EVENTGRID/TOPICS/MY-EVENTGRID-TOPIC1"</span>
}]
</code></pre>
<p>To be able to parse those data more easily, I defined a C# class to deserialize
JSON to:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">GridEvent</span>
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Id { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> EventType { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Subject { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> DateTime EventTime { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> Dictionary&lt;<span class="hljs-keyword">string</span>, <span class="hljs-keyword">string</span>&gt; Data { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Topic { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}
</code></pre>
<p>Now, the function can read the events (note, that they are sent in arrays)
from the body of POST request:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;HttpResponseMessage&gt; <span class="hljs-title">Run</span>(<span class="hljs-params">HttpRequestMessage req, TraceWriter log</span>)
</span>{
    <span class="hljs-keyword">string</span> jsonContent = <span class="hljs-keyword">await</span> req.Content.ReadAsStringAsync();
    <span class="hljs-keyword">var</span> events = JsonConvert.DeserializeObject&lt;GridEvent[]&gt;(jsonContent);

    <span class="hljs-comment">// do something with events</span>

    <span class="hljs-keyword">return</span> req.CreateResponse(HttpStatusCode.OK);
}
</code></pre>
<h2 id="validate-the-endpoint">Validate the Endpoint</h2>
<p>To prevent you from sending events to endpoints that you don&#39;t own, Event
Grid requires each subsriber to validate itself. For this purpose, Event
Grid will send events of the special type <code>SubscriptionValidation</code>. </p>
<p>The validation request will contain a code, which we need to echo back in
200-OK HTTP response. </p>
<p>Here is a small piece of code to do just that:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">if</span> (req.Headers.GetValues(<span class="hljs-string">"Aeg-Event-Type"</span>).FirstOrDefault() == <span class="hljs-string">"SubscriptionValidation"</span>)
{
    <span class="hljs-keyword">var</span> code = events[<span class="hljs-number">0</span>].Data[<span class="hljs-string">"validationCode"</span>];
    <span class="hljs-keyword">return</span> req.CreateResponse(HttpStatusCode.OK,
        <span class="hljs-keyword">new</span> { validationResponse = code });
}
</code></pre>
<p>The function is ready!</p>
<h2 id="create-a-custom-event-grid-topic">Create a Custom Event Grid Topic</h2>
<p>To test it out, go to the portal and create a custom Event Grid topic.
Then click on Add Event Subscription button, give it a name and copy paste
the function URL (including key) to Subscriber Endpoint field:</p>
<p><img src="https://mikhail.io/2017/10/azure-function-triggered-by-azure-event-grid//function-url.png" alt="Azure Function URL"></p>
<p><img src="https://mikhail.io/2017/10/azure-function-triggered-by-azure-event-grid//event-subscription.png" alt="Event Grid Subscription"></p>
<p>Creating a subscription will immediately trigger a validation request to
your function, so you should see one invocation in the logs.</p>
<h2 id="send-custom-events">Send Custom Events</h2>
<p>Now, go to your favorite HTTP client (curl, Postman, etc) and send a sample
event to check how the whole setup works:</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-keyword">POST</span> <span class="hljs-string">/api/events</span> HTTP/1.1
<span class="hljs-attribute">Host</span>: &lt;your-eventgrid-topic&gt;.westus2-1.eventgrid.azure.net
<span class="hljs-attribute">aeg-sas-key</span>: &lt;key&gt;
<span class="hljs-attribute">Content-Type</span>: application/json

<span class="json">[{
  <span class="hljs-attr">"id"</span>: <span class="hljs-string">"001"</span>,
  <span class="hljs-attr">"eventType"</span>: <span class="hljs-string">"MyHelloWorld"</span>,
  <span class="hljs-attr">"subject"</span>: <span class="hljs-string">"Hello World!"</span>,
  <span class="hljs-attr">"eventTime"</span>: <span class="hljs-string">"2017-10-05T08:53:07"</span>,
  <span class="hljs-attr">"data"</span>: {
    <span class="hljs-attr">"hello"</span>: <span class="hljs-string">"world"</span>
  }
}]
</span></code></pre>
<p>Obviously, adjust the endpoint and key based on the data from the portal.</p>
<p>You should get a 200-OK back and then see your event in Azure Function 
invocation logs.</p>
<p>Have fun!</p>
]]></content>
    </entry>
    
    <entry>
        <title>Wanted: Effectively-Once Processing in Azure</title>
        <link href="https://mikhail.io/2017/09/wanted-effectively-once-processing-in-azure/"/>
        <updated>2017-09-25T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-09-25,/2017/09/wanted-effectively-once-processing-in-azure/</id>
        <content type="html"><![CDATA[<p><em>This experimental post is a question. The question
is too broad for StackOverflow, so I&#39;m posting it here. Please engage in the
comments section, or forward the link to subject experts.</em></p>
<p>TL;DR: Are there any known patterns / tools / frameworks to provide 
scalable, stateful, effectively-once, end-to-end processing of messages, 
to be hosted in Azure, preferably on PaaS-level of service?</p>
<h2 id="motivational-example">Motivational Example</h2>
<p>Let&#39;s say we are making a TODO app. There is a constant flow of requests
to create a TODO in the system. Each request contains just two fields:
a title and a project ID which TODO should belong to. Here is the definition:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">TodoRequest</span> </span>= {
  ProjectId: int
  Title: string
}
</code></pre>
<p>Now, we want to process the request and assign each TODO an identifier,
which should be an auto-incremented integer. Numeration is unique per project,
so each TODO must have its own combination of <code>ProjectId</code> and <code>Id</code>:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Todo</span> </span>= {
  ProjectId: int
  Id: int
  Title: string
}
</code></pre>
<p>Now, instead of relying on some database sequences, I want to describe this
transformation as a function. The function has the type <code>(TodoRequest, int) -&gt;
(Todo, int)</code>, i.e. it transforms a tuple of a request and current per-project
state (last generated ID) to a tuple of a TODO and post-processing state:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> create (request: TodoRequest, state: int) =
  <span class="hljs-keyword">let</span> nextId = state + <span class="hljs-number">1</span>
  <span class="hljs-keyword">let</span> todo = {
    ProjectId = request.ProjectId
    Id = nextId
    Title = request.Title
  }
  todo, nextId
</code></pre>
<p>This is an extremely simple function, and I can use it to great success to
process local, non-durable data.</p>
<p>But if I need to make a reliable distributed application out of it, I need
to take care of lots of things:</p>
<ol>
<li><p>No request should be lost. I need to persist all the requests into 
a durable storage in case of processor crash. </p>
</li>
<li><p>Similarly, I need to persist TODO&#39;s too. Presumably, some downstream 
logic will use the persisted data later on in TODO&#39;s lifecycle.</p>
</li>
<li><p>The state (the counter) must be durable too. In case of crash of processing
function, I want to be able to restart processing after recovery. </p>
</li>
<li><p>Processing of the requests should be sequential per project ID. Otherwise
I might get a clash of ID&#39;s in case two requests belonging to the same 
project are processed concurrently.</p>
</li>
<li><p>I still want requests to different projects to be processed in parallel,
to make sure the system scales up with the growth of project count.</p>
</li>
<li><p>There must be no holes or duplicates in TODO numbering per project, even
in face of system failures. In worst case, I agree to tolerate a duplicated
entry in the output log, but it must be exactly the same entry (i.e. two 
entries with same project id, id and title).</p>
</li>
<li><p>The system should tolerate a permanent failure of any single hardware
dependency and automatically fail-over within reasonable time.</p>
</li>
</ol>
<p>It&#39;s not feasible to meet all of those requirements without relying on some
battle-tested distributed services or frameworks.</p>
<p>Which options do I know of?</p>
<h2 id="transactions">Transactions</h2>
<p>Traditionally, this kind of requirements were solved by using transactions
in something like SQL Server. If I store requests, TODO&#39;s and current ID per
project in the same relational database, I can make each processing step a
single atomic transaction. </p>
<p>This addresses all the concerns, as long as we can stay inside the single 
database. That&#39;s probably a viable option for the TODO app, but less of so
if I convert my toy example to some real applications like IoT data 
processing.</p>
<p>Can we do the same for distributed systems at scale?</p>
<h2 id="azure-event-hubs">Azure Event Hubs</h2>
<p>Since I touched IoT space, the logical choice would be to store our entries
in Azure Event Hubs. That works for many criteria, but I don&#39;t see any available
approach to make such processing consistent in the face of failures.</p>
<p>When processing is done, we need to store 3 pieces: generated TODO event,
current processing offset and current ID. Event goes to another event hub,
processing offset is stored in Blob Storage and ID can be saved to something
like Table Storage. </p>
<p>But there&#39;s no way to store those 3 pieces atomically. Whichever order we 
choose, we are bound to get anomalies in some specific failure modes.</p>
<h2 id="azure-functions">Azure Functions</h2>
<p>Azure Functions don&#39;t solve those problems. But I want to mention this
Function-as-a-Service offering because they provide an ideal programming
model for my use case.</p>
<p>I need to take just one step from my domain function to Azure Function: 
to define bindings for e.g. Event Hubs and Table Storage.</p>
<p>However, reliability guarantees will stay poor. I won&#39;t get neither sequential
processing per Event Hub partition key, nor atomic state commit.</p>
<h2 id="azure-service-fabric">Azure Service Fabric</h2>
<p>Service Fabric sounds like a good candidate service for reliable processing. 
Unfortunately, I don&#39;t have much experience with it to judge.</p>
<p>Please leave a comment if you do.</p>
<h2 id="jvm-world">JVM World</h2>
<p>There are products in JVM world which claim to solve my problem perfectly.</p>
<p>Apache Kafka was the inspiration for Event Hubs log-based messaging. The recent
Kafka release provides effectively-once processing semantics as long as
data stay inside Kafka. Kafka does that with atomic publishing to multiple
topics, and state storage based on compacted topics.</p>
<p>Apache Flink has similar guarantees for its stream processing APIs.</p>
<p>Great, but how do I get such awesomeness in .NET code, and without installing 
expensive ZooKeeper-managed clusters?</p>
<h2 id="call-for-feedback">Call for Feedback</h2>
<p>Do you know a solution, product or service?</p>
<p>Have you developed effectively-once processing on .NET / Azure stack?</p>
<p>Are you in touch with somebody who works on such framework?</p>
<p>Please leave a comment, or ping me on Twitter.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Azure Functions: Are They Really Infinitely Scalable and Elastic?</title>
        <link href="https://mikhail.io/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic/"/>
        <updated>2017-08-31T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-08-31,/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic/</id>
        <content type="html"><![CDATA[<p><em>Updated results are available at 
<a href="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic/">Azure Functions Get More Scalable and Elastic</a>.</em></p>
<p>Automatic elastic scaling is a built-in feature of Serverless computing
paradigm. One doesn&#39;t have to provision servers anymore, they just need to
write code that will be provisioned on as many servers as needed based on the
actual load. That&#39;s the theory.</p>
<p>In particular, Azure Functions can be hosted on the Consumption plan:</p>
<blockquote>
<p>The Consumption plan automatically allocates compute power when your 
code is running, scales out as necessary to handle load, and then scales 
down when code is not running.</p>
</blockquote>
<p>In this post I will run a simple stress test to get a feel of how such
automatic allocation works in practice and what kind of characteristics 
we can rely on.</p>
<h2 id="setup">Setup</h2>
<p>Here are the parameters that I chose for my test of today:</p>
<ul>
<li>Azure Function written in C# and hosted on Consumption plan</li>
<li>Triggered by Azure Storage Queue binding</li>
<li>Workload is strictly CPU-bound, no I/O is executed</li>
</ul>
<p>Specifically, each queue item represents one password that I need to hash.
Each function call performs 12-round <a href="https://en.wikipedia.org/wiki/Bcrypt">Bcrypt</a>
hashing. Bcrypt is a slow algorithm recommended for
password hashing, because it makes potential hash collision attacks really 
hard and costly.</p>
<p>My function is based on <a href="https://github.com/BcryptNet/bcrypt.net">Bcrypt.Net</a>
implementation, and it&#39;s extremely simple:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Run</span>(<span class="hljs-params">[QueueTrigger(<span class="hljs-string">"bcrypt-password"</span></span>)] <span class="hljs-keyword">string</span> password)
</span>{
    BCrypt.Net.BCrypt.HashPassword(password, <span class="hljs-number">12</span>);
}
</code></pre>
<p>It turns out that a single execution of this function takes approximately
1 second on an instance of Consumption plan, and consumes 100% CPU during
that second.</p>
<p>Now, the challenge is simple. I send 100,000 passwords
to the queue and see how long it will take to hash them, and also how the
autoscaling will behave. I will run it two times, with different pace of
sending messages to the queue.</p>
<p>That sounds like a perfect job for a Function App on Consumption plan:</p>
<ul>
<li>Needs to scale based on load</li>
<li>CPU intensive - easy to see how busy each server is</li>
<li>Queue-based - easy to see the incoming vs outgoing rate</li>
</ul>
<p>Let&#39;s see how it went.</p>
<h2 id="experiment-1-steady-load">Experiment 1: Steady Load</h2>
<p>In my first run, I was sending messages at constant rate. 100,000 messages
were sent within 2 hours, without spikes or drops in the pace.</p>
<p>Sounds like an easy job for autoscaling facilities. But here is the actual 
chart of data processing:</p>
<p><img src="https://mikhail.io/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//FunctionAppScaling.png" alt="Function App Scaling"></p>
<p>The horizontal axis is time in minutes since the first message came in.</p>
<p>The orange line shows the queue backlog - the amount of messages sitting in
the queue at a given moment.</p>
<p>The blue area represents the amount of instances (virtual servers) allocated
to the function by Azure runtime (see the numbers at the right side).</p>
<p>We can divide the whole process into 3 logical segments, approximately 
40 minutes each:</p>
<p><strong>Laging behind</strong>. Runtime starts with 0 instances, and immediately switches
to 1 when the first message comes in. However it&#39;s reluctant to add any more
servers for the next 20 (!) minutes. The scaling heuristic is probably based
on the past history for this queue/function, and it wasn&#39;t busy at all during
the hours before.</p>
<p>After 20 minutes, the runtime starts adding more instances: it goes up to 2, 
then jumps to 4, then reaches 5 at minute 40. The CPU is constantly at 
100% and the queue backlog grows linearly.</p>
<p><strong>Rapid scale up</strong>. After minute 40, it looks like the runtime realizes 
that it needs more power. Much more power! The growth speeds up real quick
and by minute 54 the backlog stops growing, even though the messages are still
coming in. But there are now 21 instances working, which is enough to
finally match and beat the rate of incoming messages.</p>
<p>The runtime doesn&#39;t stop growing though. CPU&#39;s are still at 100%, and the backlog
is still very high, so the scaling goes up and up. The amount of instances
reaches astonishing 55, at which point all the backlog is processed and
there are no messages in the queue.</p>
<p><strong>Searching for balance</strong>. When queue is almost empty and CPU drops below
100% for the first time, the runtime decides to scale down. It does that quickly
and aggressively, switching from 55 to 21 instances in just 2 minutes.</p>
<p>From there it keeps slowly reducing the number of instances until the backlog 
starts growing again. The runtime allows the backlog to grow a bit, but
then figures out a balanced number of servers (17) to keep the backlog flat 
at around 2,000 messages. </p>
<p>It stays at 17 until the producer stops sending new messages. The backlog 
goes to 0, and the amount of instances gradually drops to 0 within 10 minutes.</p>
<p>The second chart from the same experiment looks very similar, but it shows
different metrics:</p>
<p><img src="https://mikhail.io/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//FunctionAppDelay.png" alt="Function App Delay"></p>
<p>The gray line is the delay in minutes since the currently processed message
got enqueued (message &quot;age&quot;, in-queue latency). The blue line is the 
total processing rate, measured in messages per minute.</p>
<p>Due to perfect scalability and stability of my function, both charts are almost
exactly the same. I&#39;ve put it here so that you could see that the slowest
message spent more than 40 minutes sitting inside the queue.</p>
<h2 id="experiment-2-spiky-load">Experiment 2: Spiky Load</h2>
<p>With the second run, I tried to emulate a spiky load profile. I was sending
my 100,000 messages throughout 6 hours at lower pace than during the first
run. But sometimes the producer switched to fast mode and sent a bigger bunch
of messages in just several minutes. Here is the actual chart of incoming
message rate:</p>
<p><img src="https://mikhail.io/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//SpikyLoad.png" alt="Spiky Load"></p>
<p>It&#39;s easy to imagine some service which has a usage pattern like that, when
spikes of the events happen from time to time, or in rush hours.</p>
<p>This is how the Function App managed to process the messages:</p>
<p><img src="https://mikhail.io/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//SpikyLoadProcessing.png" alt="Spiky Load Processing Result"></p>
<p>The green line still shows the amount of incoming messages per minute. The 
blue line denotes how many messages were actually processed at that minute.
And the orange bars are queue backlogs - the amount of messages pending.</p>
<p>Here are several observations:</p>
<ul>
<li><p>Obviously, processing latency is way too far from real time. There is
constantly quite a significant backlog in the queue, and processing delay
reaches 20 minutes at peak.</p>
</li>
<li><p>It took the runtime 2 hours to clean the backlog for the first time. Even
without any spikes during the first hour, the autoscaling algorithm needs
time to get up to speed.</p>
</li>
<li><p>Function App runtime is able to scale up quite fast (look at the reaction
on the fourth spike), but it&#39;s not really willing to do that most of the time.</p>
</li>
<li><p>The growth of the backlog after minute 280 is purely caused by wrong
decision of runtime. While the load is completely steady, the runtime
decided to shut down most workers after 20 minutes of empty backlog, and could
not recover for the next hour.</p>
</li>
</ul>
<h2 id="conclusions">Conclusions</h2>
<p>I tried to get a feeling about the ability of Azure Functions to scale
on demand, adapting to the workload. The function under test was purely CPU-bound,
and for that I can give two main conclusions:</p>
<ul>
<li><p>Function Apps are able to scale to high amount of instances running at the
same time, and to eventually process large parallel jobs (at least up to 55
instances).</p>
</li>
<li><p>Significant processing delays are to be expected for heavy loads. Function
App runtime has quite some inertia, and the resulting processing latency can
easily go up to tens of minutes.</p>
</li>
</ul>
<p>If you know how these results can be improved, or why they are less than 
optimal, please leave a comment or contact me directly.</p>
<p>I look forward to conducting more tests in the future!</p>
]]></content>
    </entry>
    
</feed>