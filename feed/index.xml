<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <title>Mikhail Shilkov</title>
    <link href="https://mikhail.io/feed/" rel="self"/>
    <link href="https://mikhail.io"/>
    <updated>2017-07-17T20:51:17.450Z</updated>
    <id>https://mikhail.io/</id>
    <author>
        <name>Mikhail Shilkov</name>
        <email></email>
    </author>

    
    <entry>
        <title>Custom Autoscaling of Azure App Service with a Function App</title>
        <link href="https://mikhail.io/2017/07/custom-auto-scaling-in-azure/"/>
        <updated>2017-07-17T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-07-17,/2017/07/custom-auto-scaling-in-azure/</id>
        <content type="html"><![CDATA[<p>The power of cloud computing comes from its elasticity and ability to adapt to changing
load. Most Azure services can be scaled up or down manually: by human interaction in the
portal, or by running a command or a script.</p>
<p>Some services in Azure also support Autoscaling, i.e. they may change the resource 
allocation dynamically, based on predefined rules and current operational metrics.</p>
<p>Azure App Service is one example of such service: it supports 
<a href="https://docs.microsoft.com/en-us/azure/monitoring-and-diagnostics/insights-how-to-scale#scaling-based-on-a-pre-set-metric">Scaling based on a pre-set metric</a>.
This is a powerful option that enables website or webjobs to react on varying load,
e.g. based on CPU utilization.</p>
<p>At the same time, the flexibility of the built-in autoscaling is somewhat
limited:</p>
<ul>
<li><p>Only a handful of metrics is supported: for instance, Service Bus Queues 
are supported as metric source, while Service Bus Subscriptions are not;</p>
</li>
<li><p>It&#39;s not possible to combine several metrics in one rule: e.g. scale down only if
several queues are empty at the same time, not just one of them;</p>
</li>
<li><p>Thresholds are the same for any number of instances: I can&#39;t define
a scale down rule threshold to be 60% for 8 instances but 30% for 2 instances;</p>
</li>
<li><p>The minimum time of reaction is limited to 5 minutes.</p>
</li>
</ul>
<p>Other services, like SQL Database and Cosmos DB, don&#39;t have the built-in autoscaling
functionality at all.</p>
<p>This post starts the series of articles about custom implementation 
of autoscaling. The implementation will be based on Azure Functions as building 
blocks of scaling workflows.</p>
<h2 id="goal">Goal</h2>
<p>To keep the task very specific for now, I want the following from my first 
custom autoscaling implementation:</p>
<ul>
<li><p>Be able to scale the amount of instances up and down in a given App Service 
Plan;</p>
</li>
<li><p>Do so based on the given Service Bus Subscription backlog (amount of messages 
pending to be processed);</p>
</li>
<li><p>Scale up, if the average backlog during any 10 minutes is above a threshold;</p>
</li>
<li><p>Scale down, if the maximum backlog during any 10 minutes is below another 
(lower) threshold;</p>
</li>
<li><p>After scaling up or down, take a cooldown period of 10 minutes;</p>
</li>
<li><p>Have a log of scaling decisions and numbers behind;</p>
</li>
<li><p>Scaling rules should be extensible to allow more complex calculation later 
on.</p>
</li>
</ul>
<h2 id="architecture">Architecture</h2>
<p>I decided that the scaling rules should be written in a general-purpose programming language
(C# for this post), instead of just picking from a limited list of configurations.</p>
<p>I chose Azure Functions as the mechanism to host and run this logic in Azure cloud. </p>
<p>Here is a diagram of Functions that I ended up creating:</p>
<p><img src="https://mikhail.io/2017/07/custom-auto-scaling-in-azure//AutoscalingArchitecture.png" alt="Autoscaling Architecture"></p>
<p>The components of my autoscaling app are:</p>
<ul>
<li><p><strong>Metric Collector</strong> function is based on Timer trigger: it fires every minute and collects
the subscription backlog metric from a given Service Bus Subscription;</p>
</li>
<li><p>Collector then sends this metric to the <strong>Metrics</strong> storage queue;</p>
</li>
<li><p><strong>Scaling Logic</strong> function pulls the metric from the queue. It maintains the 
metric values for 10 minutes, calculates average/maximum value, and if they hit 
thresholds - issues a command to scale App Service Plan up or down;</p>
</li>
<li><p>The command is sent to <strong>Actions</strong> storage queue;</p>
</li>
<li><p><strong>Scaler</strong> function receives the commands from the queue and executes 
the re-scaling action on App Service Plan using Azure Management SDK.</p>
</li>
</ul>
<p>The implementation of this workflow is discussed below. I am using Visual Studio 2017 Version 15.3 
Preview 4.0 to author pre-compiled Azure Functions with nice built-in tooling.</p>
<h2 id="metric-collector">Metric Collector</h2>
<p>First, let&#39;s define <code>MetricValue</code> class, which simply holds time and value:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">MetricValue</span>
{
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">MetricValue</span><span class="hljs-params">(DateTime time, <span class="hljs-keyword">int</span> <span class="hljs-keyword">value</span>)</span>
    </span>{
        <span class="hljs-keyword">this</span>.Time = time;
        <span class="hljs-keyword">this</span>.Value = <span class="hljs-keyword">value</span>;
    }

    <span class="hljs-keyword">public</span> DateTime Time { <span class="hljs-keyword">get</span>; }

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">int</span> Value { <span class="hljs-keyword">get</span>; }
}
</code></pre>
<p>and <code>Metric</code> class which extends the value with resource name (e.g. App Service
Plan name) and measured parameter name:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Metric</span>
{
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">Metric</span><span class="hljs-params">(<span class="hljs-keyword">string</span> resourceName, <span class="hljs-keyword">string</span> name, MetricValue <span class="hljs-keyword">value</span>)</span>
    </span>{
        <span class="hljs-keyword">this</span>.ResourceName = resourceName;
        <span class="hljs-keyword">this</span>.Name = name;
        <span class="hljs-keyword">this</span>.Value = <span class="hljs-keyword">value</span>;
    }

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> ResourceName { <span class="hljs-keyword">get</span>; }

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Name { <span class="hljs-keyword">get</span>; }

    <span class="hljs-keyword">public</span> MetricValue Value { <span class="hljs-keyword">get</span>; }
}
</code></pre>
<p>The function definition has two associated bindings: timer trigger (runs every
minute) and return binding to the storage queue:</p>
<pre class="highlight"><code class="hljs cs">[FunctionName(<span class="hljs-string">"MetricCollector"</span>)]
[<span class="hljs-keyword">return</span>: Queue(<span class="hljs-string">"Metrics"</span>)]
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Metric <span class="hljs-title">MetricCollector</span><span class="hljs-params">([TimerTrigger(<span class="hljs-string">"0 */1 * * * *"</span>)</span>] TimerInfo myTimer, TraceWriter log)
</span>{
    <span class="hljs-keyword">var</span> connectionString = Environment.GetEnvironmentVariable(<span class="hljs-string">"ServiceBusConnection"</span>);
    <span class="hljs-keyword">var</span> topic = Environment.GetEnvironmentVariable(<span class="hljs-string">"Topic"</span>);
    <span class="hljs-keyword">var</span> subscription = Environment.GetEnvironmentVariable(<span class="hljs-string">"Subscription"</span>);

    <span class="hljs-keyword">var</span> nsmgr = NamespaceManager.CreateFromConnectionString(connectionString);
    <span class="hljs-keyword">var</span> subscriptionClient = nsmgr.GetSubscription(topic, subscription);
    <span class="hljs-keyword">var</span> backlog = subscriptionClient.MessageCountDetails.ActiveMessageCount;

    log.Info($<span class="hljs-string">"Collector: Current metric value is {backlog}"</span>);

    <span class="hljs-keyword">var</span> resource = Environment.GetEnvironmentVariable(<span class="hljs-string">"ResourceToScale"</span>);
    <span class="hljs-keyword">var</span> <span class="hljs-keyword">value</span> = <span class="hljs-keyword">new</span> MetricValue(DateTime.Now, (<span class="hljs-keyword">int</span>)backlog);
    <span class="hljs-function"><span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> <span class="hljs-title">Metric</span><span class="hljs-params">(resource, $<span class="hljs-string">"{topic}-{subscription}-backlog"</span>, <span class="hljs-keyword">value</span>)</span></span>;
}
</code></pre>
<p>The function executes the following steps:</p>
<ul>
<li>Reads configuration value for Service Bus parameters;</li>
<li>Connects to Service Bus and retrieves <code>ActiveMessageCount</code> for the given 
subscription;</li>
<li>Logs the value for tracing and debugging;</li>
<li>Returns the metric value mentioning which resource it&#39;s intended for.</li>
</ul>
<h2 id="scaling-logic">Scaling Logic</h2>
<p>The core of autoscaling implementation resides in <code>ScalingLogic</code> function. </p>
<p>The function defines 4 (oh my!) bindings:</p>
<ul>
<li>Queue trigger to react on messages from the collector;</li>
<li>Output queue binding to send commands with action to execute;</li>
<li>Combination of input and output bindings to the same row in Table Storage to 
keep the state in between function calls.</li>
</ul>
<p>The bindings are illustrated on the following picture:</p>
<p><img src="https://mikhail.io/2017/07/custom-auto-scaling-in-azure//ScalingLogicBindings.png" alt="Binding of Scaling Logic Function"></p>
<p>And here is the corresponding Function signature:</p>
<pre class="highlight"><code class="hljs cs">[FunctionName(<span class="hljs-string">"ScalingLogic"</span>)]
[<span class="hljs-keyword">return</span>: Queue(<span class="hljs-string">"Actions"</span>)]
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> ScaleAction <span class="hljs-title">ScalingLogic</span><span class="hljs-params">(
    [QueueTrigger(<span class="hljs-string">"Metrics"</span>)</span>] Metric metric, 
    [<span class="hljs-title">Table</span><span class="hljs-params">(<span class="hljs-string">"Scaling"</span>, <span class="hljs-string">"{ResourceName}"</span>, <span class="hljs-string">"{Name}"</span>)</span>] ScalingStateEntity stateEntity, 
    [<span class="hljs-title">Table</span><span class="hljs-params">(<span class="hljs-string">"Scaling"</span>, <span class="hljs-string">"{ResourceName}"</span>, <span class="hljs-string">"{Name}"</span>)</span>] <span class="hljs-keyword">out</span> ScalingStateEntity newStateEntity,
    TraceWriter log)
</span></code></pre>
<p>Table storage is partitioned per scalable resource, and state is stored per metric;
thus multiple resources and metrics are supported out of the box.</p>
<p>The function implementation is relatively complex, so I&#39;ll describe it in parts.</p>
<p><code>ScaleAction</code> is a simple message class:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">enum</span> ScaleActionType
{
    Up,
    Down
}

<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">ScaleAction</span>
{
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ScaleAction</span><span class="hljs-params">(<span class="hljs-keyword">string</span> resourceName, ScaleActionType type)</span>
    </span>{
        <span class="hljs-keyword">this</span>.ResourceName = resourceName;
        <span class="hljs-keyword">this</span>.Type = type;
    }

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> ResourceName { <span class="hljs-keyword">get</span>; }

    <span class="hljs-keyword">public</span> ScaleActionType Type { <span class="hljs-keyword">get</span>; }
}
</code></pre>
<p>Table Storage only allows primitive types for its columns, like strings. 
So I had to create a separate Table Storage entity class:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">ScalingStateEntity</span> : <span class="hljs-title">TableEntity</span>
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> SerializedState { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}
</code></pre>
<p>which stores serialized state, from the state class itself:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">ScalingState</span>
{
    <span class="hljs-keyword">public</span> List&lt;MetricValue&gt; History { <span class="hljs-keyword">get</span>; } = <span class="hljs-keyword">new</span> List&lt;MetricValue&gt;();

    <span class="hljs-keyword">public</span> DateTime LastScalingActionTime { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; } = DateTime.MinValue;
}
</code></pre>
<p>Now let&#39;s look at the function body. It consists of four blocks. </p>
<p>The first block retrieves the previous values of the metric and logs it too:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-comment">// 1. Deserialize state</span>
<span class="hljs-keyword">var</span> state = stateEntity?.SerializedState != <span class="hljs-keyword">null</span> 
    ? JsonConvert.DeserializeObject&lt;ScalingState&gt;(stateEntity.SerializedState) 
    : <span class="hljs-keyword">new</span> ScalingState();
<span class="hljs-keyword">var</span> history = state.History;
log.Info($<span class="hljs-string">"Scaling logic: Received {metric.Name}, previous state is {string.Join("</span>, <span class="hljs-string">", history)}"</span>);
</code></pre>
<p>The second block adds the current metric value and removes all metrics which are
not in the target period of 10 minutes anymore:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-comment">// 2. Add current metric value, remove old values</span>
history.Add(metric.Value);
history.RemoveAll(e =&gt; e.Time &lt; metric.Value.Time.Substract(period));
</code></pre>
<p>Now, the actual logic finally kicks in and produces the scaling action if average
or maximum value is above or below respective thresholds. For my implementation I also
chose to apply this rule after 5th data point. Cooldown period is also respected:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-comment">// 3. Compare the aggregates to thresholds, produce scaling action if needed</span>
ScaleAction action = <span class="hljs-keyword">null</span>;
<span class="hljs-keyword">if</span> (history.Count &gt;= <span class="hljs-number">5</span>
    &amp;&amp; DateTime.Now - state.LastScalingActionTime &gt; cooldownPeriod)
{
    <span class="hljs-keyword">var</span> average = (<span class="hljs-keyword">int</span>)history.Average(e =&gt; e.Value);
    <span class="hljs-keyword">var</span> maximum = (<span class="hljs-keyword">int</span>)history.Max(e =&gt; e.Value);
    <span class="hljs-keyword">if</span> (average &gt; thresholdUp)
    {
        log.Info($<span class="hljs-string">"Scaling logic: Value {average} is too high, scaling {metric.ResourceName} up..."</span>);
        state.LastScalingActionTime = DateTime.Now;
        action = <span class="hljs-keyword">new</span> ScaleAction(metric.ResourceName, ScaleActionType.Up);
    }
    <span class="hljs-function"><span class="hljs-keyword">else</span> <span class="hljs-title">if</span> <span class="hljs-params">(maximum &lt; thresholdDown)</span>
    </span>{
        log.Info($<span class="hljs-string">"Scaling logic: Value {maximum} is low, scaling {metric.ResourceName} down..."</span>);
        state.LastScalingActionTime = DateTime.Now;
        action = <span class="hljs-keyword">new</span> ScaleAction(metric.ResourceName, ScaleActionType.Down);
    }
}
</code></pre>
<p>Finally, the state is serialized back to table entity and action is returned: </p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-comment">// 4. Serialize the state back and return the action</span>
newStateEntity = stateEntity != <span class="hljs-keyword">null</span> 
    ? stateEntity 
    : <span class="hljs-keyword">new</span> ScalingStateEntity { PartitionKey = metric.ResourceName, RowKey = metric.Name };
newStateEntity.SerializedState = JsonConvert.SerializeObject(state);
<span class="hljs-keyword">return</span> action;
</code></pre>
<p>Note, that if no scaling action is warranted, the function simply returns <code>null</code> and no message 
gets sent to the output queue.</p>
<h2 id="scaler">Scaler</h2>
<p>The last function of the workflow is called <code>Scaler</code>: it listens for scaling commands and executes them.
I am using Azure Management Fluent SDK to scale the App Service Plan capacity:</p>
<pre class="highlight"><code class="hljs cs">[FunctionName(<span class="hljs-string">"Scaler"</span>)]
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Scaler</span><span class="hljs-params">([QueueTrigger(<span class="hljs-string">"Actions"</span>)</span>] ScaleAction action, TraceWriter log)
</span>{
    <span class="hljs-keyword">var</span> secrets = Environment.GetEnvironmentVariable(<span class="hljs-string">"ServicePrincipal"</span>).Split(<span class="hljs-string">','</span>);
    <span class="hljs-keyword">var</span> credentials = SdkContext.AzureCredentialsFactory
        .FromServicePrincipal(secrets[<span class="hljs-number">0</span>], secrets[<span class="hljs-number">1</span>], secrets[<span class="hljs-number">2</span>], AzureEnvironment.AzureGlobalCloud);
    <span class="hljs-keyword">var</span> azure = Azure.Configure()
        .Authenticate(credentials)
        .WithDefaultSubscription();

    <span class="hljs-keyword">var</span> plan = azure.AppServices
        .AppServicePlans
        .List()
        .First(p =&gt; p.Name.Contains(action.ResourceName));

    <span class="hljs-keyword">var</span> newCapacity = action.Type == ScaleActionType.Down ? plan.Capacity - <span class="hljs-number">1</span> : plan.Capacity + <span class="hljs-number">1</span>;
    log.Info($<span class="hljs-string">"Scaler: Switching {action.ResourceName} from {plan.Capacity} {action.Type} to {newCapacity}"</span>);

    plan.Update()
        .WithCapacity(newCapacity)
        .Apply();
}
</code></pre>
<p>The functionality is pretty straightforward. Here are some links where you can read more about 
<a href="https://docs.microsoft.com/en-us/dotnet/azure/dotnet-sdk-azure-authenticate?view=azure-dotnet#a-namemgmt-authaazure-management-libraries-for-net-authentication">Authentication in Azure Management libraries</a> 
and <a href="https://github.com/Azure-Samples/app-service-dotnet-scale-web-apps">Managing Web App with Fluent SDK</a>.</p>
<h2 id="conclusion-and-further-steps">Conclusion and Further Steps</h2>
<p>This was quite a lot of code for a single blog post, but most of it was
fairly straightforward. You can find the full implemenation in 
<a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/customautoscaling/servicebussubscription-to-appserviceplan/MetricCollector.cs">my github</a>.</p>
<p>Overall, I&#39;ve established an application based on Azure Functions, which
watches the predefined metrics and scales the specified resource up and down
based on target metric values.</p>
<p>The current example works only for the combination of Service Bus Subscription
and App Service Plan, but it is clear how to extend it to more scenarios.</p>
<p>The flexibility of such autoscaling solution exceeds the built-in functionality
that is available in Azure Portal.</p>
<p>The most complex part of my Autoscaling application is the Scaling Logic
function. In the next article of the series, I will refactor it to use
<a href="https://azure.github.io/azure-functions-durable-extension/index.html">Durable Functions</a> - 
the upcoming Orchestration framework for Function Apps.</p>
<p>Stay tuned, and happy scaling!</p>
]]></content>
    </entry>
    
    <entry>
        <title>Sending Large Batches to Azure Service Bus</title>
        <link href="https://mikhail.io/2017/07/sending-large-batches-to-azure-service-bus/"/>
        <updated>2017-07-04T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-07-04,/2017/07/sending-large-batches-to-azure-service-bus/</id>
        <content type="html"><![CDATA[<p>Azure Service Bus client supports sending messages in batches (<code>SendBatch</code>
and <code>SendBatchAsync</code> methods of <code>QueueClient</code> and <code>TopicClient</code>). However,
the size of a single batch must stay below 256k bytes, otherwise the whole
batch will get rejected.</p>
<p>How do we make sure that the batch-to-be-sent is going to fit? The rest 
of this article will try to answer this seemingly simple question.</p>
<h2 id="problem-statement">Problem Statement</h2>
<p>Given a list of messages of arbitrary type <code>T</code>, we want to send them to Service
Bus in batches. The amount of batches should be close to minimal, but
obviously each one of them must satisfy the restriction of 256k max size.</p>
<p>So, we want to implement a method with the following signature:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> Task SendBigBatchAsync&lt;T&gt;(IEnumerable&lt;T&gt; messages);
</code></pre>
<p>which would work for collections of any size.</p>
<p>To limit the scope, I will restrict the article to the following assumptions:</p>
<ul>
<li><p>Each individual message is less than 256k serialized. If that wasn&#39;t true,
we&#39;d have to put the body into external blob storage first, and then send
the reference. It&#39;s not directly related to the topic of discussion.</p>
</li>
<li><p>I&#39;ll use <code>public BrokeredMessage(object serializableObject)</code> constructor.
Custom serialization could be used, but again, it&#39;s not related to batching,
so I&#39;ll ignore it.</p>
</li>
<li><p>We won&#39;t care about transactions, i.e. if connectivity dies in the middle
of sending the big batch, we might end up with partially sent batch.</p>
</li>
</ul>
<h2 id="messages-of-known-size">Messages of Known Size</h2>
<p>Let&#39;s start with a simple use case: the size of each message is known to us. 
It&#39;s defined by hypothetical <code>Func&lt;T, long&gt; getSize</code> function. Here is a 
helpful extension method that will split an arbitrary collection based on
a metric function and maximum chunk size:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> List&lt;List&lt;T&gt;&gt; ChunkBy&lt;T&gt;(<span class="hljs-keyword">this</span> IEnumerable&lt;T&gt; source, Func&lt;T, <span class="hljs-keyword">long</span>&gt; metric, <span class="hljs-keyword">long</span> maxChunkSize)
{
    <span class="hljs-keyword">return</span> source
        .Aggregate(
            <span class="hljs-keyword">new</span>
            {
                Sum = <span class="hljs-number">0</span>L,
                Current = (List&lt;T&gt;)<span class="hljs-keyword">null</span>,
                Result = <span class="hljs-keyword">new</span> List&lt;List&lt;T&gt;&gt;()
            },
            (agg, item) =&gt;
            {
                <span class="hljs-keyword">var</span> <span class="hljs-keyword">value</span> = metric(item);
                <span class="hljs-keyword">if</span> (agg.Current == <span class="hljs-keyword">null</span> || agg.Sum + <span class="hljs-keyword">value</span> &gt; maxChunkSize)
                {
                    <span class="hljs-keyword">var</span> current = <span class="hljs-keyword">new</span> List&lt;T&gt; { item };
                    agg.Result.Add(current);
                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> { Sum = <span class="hljs-keyword">value</span>, Current = current, agg.Result };
                }

                agg.Current.Add(item);
                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> { Sum = agg.Sum + <span class="hljs-keyword">value</span>, agg.Current, agg.Result };
            })
        .Result;
}
</code></pre>
<p>Now, the implementation of <code>SendBigBatchAsync</code> is simple:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">async</span> Task <span class="hljs-title">SendBigBatchAsync</span><span class="hljs-params">(IEnumerable&lt;T&gt; messages, Func&lt;T, <span class="hljs-keyword">long</span>&gt; getSize)</span>
</span>{
    <span class="hljs-keyword">var</span> chunks = messages.ChunkBy(getSize, MaxServiceBusMessage);
    <span class="hljs-keyword">foreach</span> (<span class="hljs-keyword">var</span> chunk <span class="hljs-keyword">in</span> chunks)
    {
        <span class="hljs-keyword">var</span> brokeredMessages = chunk.Select(m =&gt; <span class="hljs-keyword">new</span> BrokeredMessage(m));
        <span class="hljs-keyword">await</span> client.SendBatchAsync(brokeredMessages);
    }
}

<span class="hljs-keyword">private</span> <span class="hljs-keyword">const</span> <span class="hljs-keyword">long</span> MaxServiceBusMessage = <span class="hljs-number">256000</span>;
<span class="hljs-keyword">private</span> <span class="hljs-keyword">readonly</span> QueueClient client;
</code></pre>
<p>Note that I do <code>await</code> for each chunk sequentially to preserve message ordering.
Another thing to notice is that we lost all-or-nothing guarantee: we might
be able to send the first chunk, and then get an exception from subsequent
parts. Some sort of retry mechanism is probably needed.</p>
<h2 id="brokeredmessage-size">BrokeredMessage.Size</h2>
<p>OK, how do we determine the size of each message? How do we implement 
<code>getSize</code> function? </p>
<p><code>BrokeredMessage</code> class exposes <code>Size</code> property, so it might be tempting to
rewrite our method the following way:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">async</span> Task SendBigBatchAsync&lt;T&gt;(IEnumerable&lt;T&gt; messages)
{
    <span class="hljs-keyword">var</span> brokeredMessages = messages.Select(m =&gt; <span class="hljs-keyword">new</span> BrokeredMessage(m));
    <span class="hljs-keyword">var</span> chunks = brokeredMessages.ChunkBy(bm =&gt; bm.Size, MaxServiceBusMessage);
    <span class="hljs-keyword">foreach</span> (<span class="hljs-keyword">var</span> chunk <span class="hljs-keyword">in</span> chunks)
    {
        <span class="hljs-keyword">await</span> client.SendBatchAsync(chunk);
    }
}
</code></pre>
<p>Unfortunately, this won&#39;t work properly. A quote from documentation:</p>
<blockquote>
<p>The value of Size is only accurate after the BrokeredMessage 
instance is sent or received.</p>
</blockquote>
<p>My experiments show that <code>Size</code> of a draft message returns the size of 
the message body, ignoring headers. If the message bodies are large, and
each chunk has just a handful of them, the code might work ok-ish. </p>
<p>But it will significantly underestimate the size of large batches of messages
with small payload.</p>
<p>So, for the rest of this article I&#39;ll try to adjust the calculation for headers.</p>
<h2 id="fixed-header-size">Fixed Header Size</h2>
<p>It could be that the header size of each message is always the same.
Quite often people will set the same headers for all their messages,
or set no custom headers at all. </p>
<p>In this case, you might just measure this size once, and then put this
fixed value inside a configuration file.</p>
<p>Here is how you measure the headers of a <code>BrokeredMessage</code> message:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> sizeBefore = message.Size;
client.Send(message);
<span class="hljs-keyword">var</span> sizeAfter = message.Size;
<span class="hljs-keyword">var</span> headerSize = sizeAfter - sizeBefore;
</code></pre>
<p>Now you just need to adjust one line from the previous version of 
<code>SendBigBatchAsync</code> method</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> chunks = brokeredMessages.ChunkBy(bm =&gt; FixedHeaderSize + bm.Size, MaxServiceBusMessage);
</code></pre>
<p><code>FixedHeaderSize</code> might be simply hard-coded, or taken from configuration
per application.</p>
<h2 id="measuring-of-header-size-per-message">Measuring of Header Size per Message</h2>
<p>If the size of headers varies per message, you need a way to adjust batching
algorithm accordingly. </p>
<p>Unfortunately, I haven&#39;t found a straightforward way to accomplish that. It looks like
you&#39;d have to serialize the headers yourself, and then measure the size of
resulting binary. This is not a trivial operation to do correctly,
and also implies some performance penalty.</p>
<p>Sean Feldman <a href="https://weblogs.asp.net/sfeldman/asb-batching-brokered-messages">came up</a> 
with a way to <em>estimate</em> the size of headers. That might be a good way to go,
though the estimation tends to err on the safe side for messages with small
payload.</p>
<h2 id="heuristics-retry">Heuristics &amp; Retry</h2>
<p>The last possibility that I want to consider is actually allow yourself
violating the max size of the batch, but then handle the exception, retry
the send operation and adjust future calculations based on actual measured size
of the failed messages. The size is known after trying to <code>SendBatch</code>, even if
operation failed, so we can use this information.</p>
<p>Here is a sketch of how to do that in code:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-comment">// Sender is reused across requests</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">BatchSender</span>
{
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">readonly</span> QueueClient queueClient;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> batchSizeLimit = <span class="hljs-number">262000</span>;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> headerSizeEstimate = <span class="hljs-number">54</span>; <span class="hljs-comment">// start with the smallest header possible</span>

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">BatchSender</span><span class="hljs-params">(QueueClient queueClient)</span>
    </span>{
        <span class="hljs-keyword">this</span>.queueClient = queueClient;
    }

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">async</span> Task SendBigBatchAsync&lt;T&gt;(IEnumerable&lt;T&gt; messages)
    {
        <span class="hljs-keyword">var</span> packets = (<span class="hljs-keyword">from</span> m <span class="hljs-keyword">in</span> messages
                     <span class="hljs-keyword">let</span> bm = <span class="hljs-keyword">new</span> BrokeredMessage(m)
                     <span class="hljs-keyword">select</span> <span class="hljs-keyword">new</span> { Source = m, Brokered = bm, BodySize = bm.Size }).ToList();
        <span class="hljs-keyword">var</span> chunks = packets.ChunkBy(p =&gt; <span class="hljs-keyword">this</span>.headerSizeEstimate + p.Brokered.Size, <span class="hljs-keyword">this</span>.batchSizeLimit);
        <span class="hljs-keyword">foreach</span> (<span class="hljs-keyword">var</span> chunk <span class="hljs-keyword">in</span> chunks)
        {
            <span class="hljs-keyword">try</span>
            {
                <span class="hljs-keyword">await</span> <span class="hljs-keyword">this</span>.queueClient.SendBatchAsync(chunk.Select(p =&gt; p.Brokered));
            }
            <span class="hljs-keyword">catch</span> (MessageSizeExceededException)
            {
                <span class="hljs-keyword">var</span> maxHeader = packets.Max(p =&gt; p.Brokered.Size - p.BodySize);
                <span class="hljs-keyword">if</span> (maxHeader &gt; <span class="hljs-keyword">this</span>.headerSizeEstimate)
                {
                    <span class="hljs-comment">// If failed messages had bigger headers, remember this header size </span>
                    <span class="hljs-comment">// as max observed and use it in future calculations</span>
                    <span class="hljs-keyword">this</span>.headerSizeEstimate = maxHeader;
                }
                <span class="hljs-keyword">else</span>
                {
                    <span class="hljs-comment">// Reduce max batch size to 95% of current value</span>
                    <span class="hljs-keyword">this</span>.batchSizeLimit = (<span class="hljs-keyword">long</span>)(<span class="hljs-keyword">this</span>.batchSizeLimit * <span class="hljs-number">.95</span>);
                }

                <span class="hljs-comment">// Re-send the failed chunk</span>
                <span class="hljs-keyword">await</span> <span class="hljs-keyword">this</span>.SendBigBatchAsync(packets.Select(p =&gt; p.Source));
            }

        }
    }
}
</code></pre>
<p>The code example is quite involved, here is what actually happens:</p>
<ol>
<li><p>Create a brokered message for each message object, but also save the
corresponding source message. This is critical to be able to re-send items:
there&#39;s no way to send the same <code>BrokeredMessage</code> instance twice.</p>
</li>
<li><p>Also save the body size of the brokered message. We&#39;ll use it for retry
calculation.</p>
</li>
<li><p>Start with some guess of header size estimate. I start with 54 bytes, 
which seems to be the minimal header size possible.</p>
</li>
<li><p>Split the batch into chunks the same way we did before.</p>
</li>
<li><p>Try sending chunks one by one.</p>
</li>
<li><p>If send operation fails with <code>MessageSizeExceededException</code>, iterate
through failed items and find out the actual header size of the message.</p>
</li>
<li><p>If that actual size is bigger than our known estimate, increase the estimate
to the newly observed value. Retry sending the chunk (not the whole batch) with
this new setting.</p>
</li>
<li><p>If the header is small, but message size is still too big - reduce the 
allowed total size of the chunk. Retry again.</p>
</li>
</ol>
<p>The combination of checks of steps 7 and 8 should make the mechanism reliable
and self-adopting to message header payloads.</p>
<p>Since we reuse the sender between send operations, the size parameters will
also converge quite quickly and no more retries will be needed. Thus the 
performance overhead should be minimal.</p>
<h2 id="conclusion">Conclusion</h2>
<p>It seems like there is no &quot;one size fits all&quot; solution for this problem at 
the moment. The best implementation might depend on your messaging 
requirements.</p>
<p>But if you have the silver bullet solution, please leave a comment under
this post and answer <a href="https://stackoverflow.com/questions/44779707/split-batch-of-messages-to-be-sent-to-azure-service-bus">my StackOverflow question</a>!</p>
<p>Otherwise, let&#39;s hope that the new 
<a href="https://github.com/azure/azure-service-bus-dotnet">.NET Standard-compatible Service Bus client</a>
will solve this issue for us. Track <a href="https://github.com/Azure/azure-service-bus-dotnet/issues/109">this github issue</a>
for status updates.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Finding Lost Events in Azure Application Insights</title>
        <link href="https://mikhail.io/2017/06/finding-lost-events-in-azure-application-insights/"/>
        <updated>2017-06-07T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-06-07,/2017/06/finding-lost-events-in-azure-application-insights/</id>
        <content type="html"><![CDATA[<p>One of the ways we use Azure Application Insights is tracking custom
application-specific events. For instance, every time a data point from an
IoT device comes in, we log an AppInsights event. Then we are able to
aggregate the data and plot charts to derive trends and detect possible 
anomalies.</p>
<p>And recently we found such anomaly, which looked like this:</p>
<p><img src="https://mikhail.io/2017/06/finding-lost-events-in-azure-application-insights//dashboard-chart.png" alt="Amount of Events on Dashboard Chart"></p>
<p>This is a chart from our Azure dashboard, which shows the total amount of
events of specific type received per day. </p>
<p>The first two &quot;hills&quot; are two weeks, so we can clearly see that we get more
events on business days compared to weekends.</p>
<p>But then something happened on May 20: we started getting much less events,
and the hill pattern disappeared, days looks much more alike.</p>
<p>We haven&#39;t noticed any other problems in the system, but the trend looked
quite bothering. Are we loosing data?</p>
<p>I headed towards Analytics console of Application Insights to dig deeper.
Here is the query that reproduces the problem:</p>
<pre class="highlight"><code class="hljs stylus">customEvents
| where name == <span class="hljs-string">"EventXReceived"</span>
| where timestamp &gt;= <span class="hljs-function"><span class="hljs-title">ago</span><span class="hljs-params">(<span class="hljs-number">22</span>d)</span></span>
| project PointCount = <span class="hljs-function"><span class="hljs-title">todouble</span><span class="hljs-params">(customMeasurements[<span class="hljs-string">"EventXReceived_Count"</span>])</span></span>, timestamp
| summarize EventXReceived = <span class="hljs-function"><span class="hljs-title">sum</span><span class="hljs-params">(PointCount)</span></span> by <span class="hljs-function"><span class="hljs-title">bin</span><span class="hljs-params">(timestamp, <span class="hljs-number">1</span>d)</span></span>
| render timechart
</code></pre><p>and I got the same chart as before:</p>
<p><img src="https://mikhail.io/2017/06/finding-lost-events-in-azure-application-insights//analytics1.png" alt="Trend on Application Insights Analytics"></p>
<p>I checked the history of our source code repository and deployments and I
figured out that we upgraded the version of Application Insights SDK from 
version 2.1 to version 2.3.</p>
<p>My guess at this point was that Application Insights started sampling our
data instead of sending all events to the server. After reading 
<a href="https://docs.microsoft.com/en-us/azure/application-insights/app-insights-sampling">Sampling in Application Insights</a>
article, I came up with the following query to see the sampling rate:</p>
<pre class="highlight"><code class="hljs stylus">customEvents
| where name == <span class="hljs-string">"EventXReceived"</span>
| where timestamp &gt;= <span class="hljs-function"><span class="hljs-title">ago</span><span class="hljs-params">(<span class="hljs-number">22</span>d)</span></span>
| summarize <span class="hljs-number">100</span>/<span class="hljs-function"><span class="hljs-title">avg</span><span class="hljs-params">(itemCount)</span></span> by <span class="hljs-function"><span class="hljs-title">bin</span><span class="hljs-params">(timestamp, <span class="hljs-number">1</span>d)</span></span> 
| render areachart
</code></pre><p>and the result is self-explanatory:</p>
<p><img src="https://mikhail.io/2017/06/finding-lost-events-in-azure-application-insights//sampling-rate.png" alt="Sampling Rate"></p>
<p>Clearly, the sampling rate dropped from 100% down to about 30% right when
the anomaly started. The sampling-adjusted query (note <code>itemCount</code> multiplication)</p>
<pre class="highlight"><code class="hljs 1c">customEvents
<span class="hljs-string">| where name == "</span>EventXReceived<span class="hljs-string">"</span>
<span class="hljs-string">| where timestamp &gt;= ago(22d)</span>
<span class="hljs-string">| project PointCount = todouble(customMeasurements["</span>EventXReceived_Count<span class="hljs-string">"]) * itemCount, timestamp</span>
<span class="hljs-string">| summarize EventXReceived = sum(PointCount) by bin(timestamp, 1d)</span>
<span class="hljs-string">| render timechart</span>
</code></pre><p>puts us back to the point when results make sense:</p>
<p><img src="https://mikhail.io/2017/06/finding-lost-events-in-azure-application-insights//analytics2.png" alt="Adjusted Trend on Application Insights Analytics"></p>
<p>The third week&#39;s Thursday was bank holiday in several European countries, so 
we got a drop there.</p>
<p>Should Azure dashboard items take sampling into account - to avoid
confusing people and to show more useful charts?</p>
]]></content>
    </entry>
    
    <entry>
        <title>Mikhail.io Upgraded to HTTPS and HTTP/2</title>
        <link href="https://mikhail.io/2017/06/mikhail-io-upgraded-to-https-and-http2/"/>
        <updated>2017-06-06T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-06-06,/2017/06/mikhail-io-upgraded-to-https-and-http2/</id>
        <content type="html"><![CDATA[<p>Starting today, this blog has switched to HTTPS secure protocol:</p>
<p><img src="https://mikhail.io/2017/06/mikhail-io-upgraded-to-https-and-http2//mikhailio-https.png" alt="HTTPS"></p>
<p>While there&#39;s not that much to secure on my blog, HTTPS is still considered
to be a good practice for any site in 2017. One of the benefits that we can
get from it is the usage of HTTP/2 protocol:</p>
<p><img src="https://mikhail.io/2017/06/mikhail-io-upgraded-to-https-and-http2//mikhailio-http2.png" alt="HTTP/2"></p>
<p>This should be beneficial to any reader which uses a modern browser!</p>
<p>Thanks to <a href="https://cloudflare.com">CloudFlare</a> for providing me with free
HTTPS and HTTP/2 support.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Reliable Consumer of Azure Event Hubs</title>
        <link href="https://mikhail.io/2017/05/reliable-consumer-of-azure-event-hubs/"/>
        <updated>2017-05-29T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-05-29,/2017/05/reliable-consumer-of-azure-event-hubs/</id>
        <content type="html"><![CDATA[<p><a href="https://azure.microsoft.com/en-us/services/event-hubs/">Azure Event Hubs</a> is
a log-based messaging system-as-a-service in Azure cloud. It&#39;s designed to be able to handle huge
amount of data, and naturally supports multiple consumers.</p>
<h2 id="event-hubs-and-service-bus">Event Hubs and Service Bus</h2>
<p>While Event Hubs are formally part of Azure Service Bus family of products,
in fact its model is quite different.</p>
<p>&quot;Traditional&quot; Service Bus service is organized around queues (subscriptions
are just queues with the topic being the source of messages). Each consumer 
can peek messages from the queue, do the required processing and then
complete the message to remove it from the queue, or abort the processing.
Abortion will leave the message at the queue, or will move it to the Dead Letter
Queue. Completion/abortion are granular per message; and the status of each
message is managed by the Service Bus broker.</p>
<p><img src="https://mikhail.io/2017/05/reliable-consumer-of-azure-event-hubs//service-bus-processors.png" alt="Service Bus Processors"></p>
<p>Event Hubs service is different. Each Hub represnts a log of messages.
Event producer appends data to the end of the log, and consumers can read this log,
but they can&#39;t remove or change the status of events there.</p>
<p>Each event has an offset associated with it. And the only operation that is
supported for consumers is &quot;give me some messages starting at the offset X&quot;.</p>
<p><img src="https://mikhail.io/2017/05/reliable-consumer-of-azure-event-hubs//event-hub-processors.png" alt="Event Hub Processors"></p>
<p>While this approach might seem simplistic, it actually  makes consumers 
more powerful:</p>
<ul>
<li><p>The messages do not disappear from the Hub after being processed for the
first time. So, if needed, the consumer can go back and re-process older
events again;</p>
</li>
<li><p>Multiple consumers are always supported, out of the box. They just read
the same log, after all;</p>
</li>
<li><p>Each consumer can go at its own pace, drop and resume processing whenever
needed, with no effect on other consumers.</p>
</li>
</ul>
<p>There are some disadvantages too:</p>
<ul>
<li><p>Consumers have to manage their own state of the processing progress, i.e.
they have to save the offset of the last processed event;</p>
</li>
<li><p>There is no way to mark any specific event as failed to be able to reprocess
it later. There&#39;s no notion of Dead Letter Queue either.</p>
</li>
</ul>
<h2 id="event-processor-host">Event Processor Host</h2>
<p>To overcome the first complication, Microsoft provides the consumer API called
<a href="https://github.com/Microsoft/azure-docs/blob/master/articles/event-hubs/event-hubs-programming-guide.md">EventProcessorHost</a>.
This API has an implementation of consumers based on checkpointing. All you
need to do is to provide a callback to process a batch of events, and then call
<code>CheckpointAsync</code> method, which saves the current offset of the last message
into Azure Blob Storage. If the consumer restarts at any point in time, it will
read the last checkpoint to find the current offset, and will then continue
processing from that point on.</p>
<p>It works great for some scenarios, but the event delivery/processing guarantees
are relatively low in this case:</p>
<ul>
<li><p>Any failures are ignored: there&#39;s no retry or Dead Letter Queue</p>
</li>
<li><p>There are no transactions between event hub checkpoints and the data sinks
that the processor works with (i.e. data stores where processed messages 
end up at)</p>
</li>
</ul>
<p>In this post I want to focus on a way to process events with higher consistency
requirements, in particular:</p>
<ul>
<li><p>Event Hub processor modifies data in a SQL Database, and such 
processing is transactional per batch of messages</p>
</li>
<li><p>Each event should be (successfully) processed exactly once</p>
</li>
<li><p>If event processing failed, it should be marked as failed and kept 
available to be reprocessed at later point in time</p>
</li>
</ul>
<p>While end-to-end exactly-once processing would require changes of the 
producers too, we will only focus on consumer side in this post.</p>
<h2 id="transactional-checkpoints-in-sql">Transactional Checkpoints in SQL</h2>
<p>If checkpoint information is stored in Azure Blobs, there is no obvious way to
implement distributed transactions between SQL Database and Azure Storage.</p>
<p>However, we can override the default checkpointing mechanism and 
implement our own checkpoints based on a SQL table. This way each 
checkpoint update can become part of a SQL transaction and be committed
or rolled back with normal guarantees provided by SQL Server.</p>
<p>Here is a table that I created to hold my checkpoints:</p>
<pre class="highlight"><code class="hljs sql"><span class="hljs-operator"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> EventHubCheckpoint (
  Topic <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  PartitionID <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  SequenceNumber <span class="hljs-built_in">bigint</span> <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  Offset <span class="hljs-built_in">varchar</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  <span class="hljs-keyword">CONSTRAINT</span> PK_EventHubCheckpoint <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> CLUSTERED (Topic, PartitionID)
)
</span></code></pre>
<p>For each topic and partition of Event Hubs, we store two values: sequence
number and offset, which together uniquely identify the consumer position.</p>
<p>Conveniently, Event Host Processor provides an extensibility point to
override the default checkpoint manager with a custom one. For that we
need to implement <code>ICheckpointManager</code> interface to work with our SQL
table.</p>
<p>The implementation mainly consists of 3 methods: <code>CreateCheckpointIfNotExistsAsync</code>,
<code>GetCheckpointAsync</code> and <code>UpdateCheckpointAsync</code>. The names are pretty
much self-explanatory, and my Dapper-based implementation is quite trivial.
You can find the code <a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/eventhubs-sqlcheckpoints/SQLCheckpointManager.cs">here</a>.</p>
<p>For now, I&#39;m ignoring the related topic of lease management and corresponding
interface <code>ILeaseManager</code>. It&#39;s quite a subject on its own; for the sake
of simplicity I&#39;ll assume we have just one consumer process per partition,
which makes proper lease manager redundand.</p>
<h2 id="dead-letter-queue">Dead Letter Queue</h2>
<p>Now, we want to be able to mark some messages as failed and to 
re-process them later. To make Dead Letters transactional, we need another
SQL table to hold the failed events:</p>
<pre class="highlight"><code class="hljs sql"><span class="hljs-operator"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> EventHubDeadLetter (
  Topic <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  PartitionID <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  SequenceNumber <span class="hljs-built_in">bigint</span> <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  Offset <span class="hljs-built_in">varchar</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  FailedAt datetime <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  Error <span class="hljs-keyword">nvarchar</span>(<span class="hljs-keyword">max</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  <span class="hljs-keyword">CONSTRAINT</span> PK_EventHubDeadLetter <span class="hljs-keyword">PRIMARY</span> <span class="hljs-keyword">KEY</span> CLUSTERED (Topic, PartitionID)
)
</span></code></pre>
<p>This table looks very similar to <code>EventHubCheckpoint</code> that I
defined above. That is because they are effectively storing pointers to
events in a hub. Dead Letters have two additional columns to store error
timestamp and text.</p>
<p>There is no need to store the message content, because failed events still
sit in the event hub anyway. You could still log it for diagnostics purpose - just make an extra
<code>varbinary</code> column.</p>
<p>There&#39;s no notion of dead letters in Event Hubs SDK, so I defined my own
interface <code>IDeadLetterManager</code> with a single <code>AddFailedEvents</code> method:</p>
<pre class="highlight"><code class="hljs undefined">public interface IDeadLetterManager
{
    Task AddFailedEvents(IEnumerable&lt;DeadLetter&lt;EventData&gt;&gt; deadLetters);
}

public class DeadLetter&lt;T&gt;
{
    public T Data { get; set; }
    public DateTime FailureTime { get; set; }
    public Exception Exception { get; set; }
}
</code></pre>
<p>Dapper-based implementation is trivial again, you can find the code 
<a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/eventhubs-sqlcheckpoints/SQLDeadLetterManager.cs">here</a>.</p>
<h2 id="putting-it-together-event-host">Putting It Together: Event Host</h2>
<p>My final solution is still using <code>EventHostProcessor</code>. I pass <code>SQLCheckpointManager</code> 
into its constructor, and then I implement <code>IEventProcessor</code>&#39;s 
<code>ProcessEventsAsync</code> method in the following way:</p>
<ol>
<li>Instantiate a list of items to store failed events</li>
<li>Start a SQL transaction</li>
<li>Loop through all the received events in the batch</li>
<li>Process each item inside a try-catch block</li>
<li>If exception happens, add the current event to the list of failed events</li>
<li>After all items are processed, save failed events to Dead Letter table</li>
<li>Update the checkpoint pointer</li>
<li>Commit the transaction</li>
</ol>
<p>The code block that illustrates this workflow:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">async</span> Task <span class="hljs-title">ProcessEventsAsync</span><span class="hljs-params">(
    PartitionContext context, 
    IEnumerable&lt;EventData&gt; eventDatas)</span>
</span>{
    <span class="hljs-comment">// 1. Instantiate a list of items to store failed events</span>
    <span class="hljs-keyword">var</span> failedItems = <span class="hljs-keyword">new</span> List&lt;DeadLetter&lt;EventData&gt;&gt;();

    <span class="hljs-comment">// 2. Start a SQL transaction</span>
    <span class="hljs-keyword">using</span> (<span class="hljs-keyword">var</span> scope = <span class="hljs-keyword">new</span> TransactionScope())
    {
        <span class="hljs-comment">// 3. Loop through all the received events in the batch</span>
        <span class="hljs-keyword">foreach</span> (<span class="hljs-keyword">var</span> eventData <span class="hljs-keyword">in</span> eventDatas)
        {
            <span class="hljs-keyword">try</span>
            {
                <span class="hljs-comment">// 4. Process each item inside a try-catch block</span>
                <span class="hljs-keyword">var</span> item = <span class="hljs-keyword">this</span>.Deserialize(eventData);
                <span class="hljs-keyword">await</span> <span class="hljs-keyword">this</span>.DoWork(item);
            }
            <span class="hljs-keyword">catch</span> (Exception ex)
            {
                <span class="hljs-comment">// 5. Add a failed event to the list</span>
                failedItems.Add(<span class="hljs-keyword">new</span> DeadLetter&lt;EventData&gt;(eventData, DateTime.UtcNow, ex));
            }
        }

        <span class="hljs-keyword">if</span> (failedItems.Any())
        {
            <span class="hljs-comment">// 6. Save failed items to Dead Letter table</span>
            <span class="hljs-keyword">await</span> <span class="hljs-keyword">this</span>.dlq.AddFailedEvents(failedItems);
        }

        <span class="hljs-comment">// 7. Update the checkpoint pointer</span>
        <span class="hljs-keyword">await</span> context.CheckpointAsync();

        <span class="hljs-comment">// 8. Commit the transaction</span>
        scope.Complete();
    }
}
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>My implementation of Event Hubs consumer consists of 3 parts: checkpoint 
manager that saves processing progress per partition into a SQL table;
dead letter manager that persists information about processing errors;
and an event host which uses both to provide transactional processing
of events.</p>
<p>The transaction scope is limited to SQL Server databases, but it might be
sufficient for many real world scenarios.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Why F# and Functional Programming Talk at .NET Development Nederland Meetup</title>
        <link href="https://mikhail.io/2017/05/why-fsharp-and-functional-programming-will-make-you-a-better-developer-talk/"/>
        <updated>2017-05-08T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-05-08,/2017/05/why-fsharp-and-functional-programming-will-make-you-a-better-developer-talk/</id>
        <content type="html"><![CDATA[<p>On May 8th 2017 I gave a talk at the
<a href="https://www.meetup.com/dotNET-Development-Nederland/">.NET Development Nederland</a>
group in Amsterdam.</p>
<p>Here are the slides for the people who were there and want to revisit
the covered topics.</p>
<h2 id="why-learn-f-and-functional-programming">Why Learn F# and Functional Programming</h2>
<p>Link to full-screen HTML slides: 
<a href="http://mikhail.io/talks/why-fsharp/">Why Learn F# and Functional Programming</a></p>
<p>Slides on SlideShare:</p>
<iframe src="//www.slideshare.net/slideshow/embed_code/key/iG9omDKb42ogTk" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> 
</iframe>

<p>Useful links:</p>
<p><a href="http://fsharpforfunandprofit.com">F# for Fun and Profit</a></p>
<p><a href="http://fsharp.org">F# Foundation</a></p>
<p><a href="https://www.manning.com/books/real-world-functional-programming">Real-World Functional Programming, With examples in F# and C# Book</a></p>
<p>Thanks for attending my talk! Feel free to post any feedback in the comments.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Visualizing Dependency Tree from DI Container</title>
        <link href="https://mikhail.io/2017/03/visualizing-dependency-tree-from-di-container/"/>
        <updated>2017-03-25T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-03-25,/2017/03/visualizing-dependency-tree-from-di-container/</id>
        <content type="html"><![CDATA[<p>So you are a C# developer. And you need to read the code and understand its
structure. Maybe you&#39;ve just joined the project, or it&#39;s your own code you
wrote 1 year ago. In any case, reading code is hard.</p>
<p>Luckily, some good thought was applied to this particular piece of code.
It&#39;s all broken down into small classes (they might even be SOLID!), and all 
the dependencies are injected via constructors. It looks like it&#39;s your
code indeed.</p>
<p>So, you figured out that the entry point for your current use case is the
class called <code>ThingService</code>. It&#39;s probably doing something with <code>Thing</code>&#39;s
and that&#39;s what you need. The signature of the class constructor looks 
like this:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ThingService</span><span class="hljs-params">(
    IGetThings readRepository,
    ISaveThing saveRepository,
    IParseAndValidateExcel&lt;Thing, <span class="hljs-keyword">string</span>&gt; fileParser,
    IThingChangeDetector thingChangeDetector,
    IMap&lt;Thing, ThingDTO&gt; thingToDtoMapper,
    IMap&lt;<span class="hljs-keyword">int</span>, ThingDTO, Thing&gt; dtoToThingMapper)</span>
</span></code></pre>
<p>OK, so we clearly have 6 dependencies here, and they are all interfaces.
We don&#39;t know where those interfaces are implemented, but hey - we&#39;ve got
the best tooling in the industry, so right click on <code>IGetThings</code>, then 
<code>Go To Implementation</code>.</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">DapperThingRepository</span><span class="hljs-params">(
    ICRUDAdapter adapter,
    IDatabaseConnectionFactory connectionFactory,
    IMap&lt;Thing, ThingRow&gt; thingRowMapper,
    IMap&lt;ThingRow, Thing&gt; thingMapper)</span>
</span></code></pre>
<p>Now we know that we get <code>Thing</code> from Dapper, so probably from a SQL database.
Let&#39;s go one level deeper and check where those Mappers are implemented.
Right click, <code>Go To Implementation</code>... But instead of navigating to another code
file you see</p>
<pre class="highlight"><code class="hljs mathematica"><span class="hljs-keyword">Find</span> <span class="hljs-keyword">Symbol</span> Result - <span class="hljs-number">28</span> matches found
</code></pre><p>Oh, right, looks like we use <code>IMap&lt;T, U&gt;</code> in more places. OK, we&#39;ll find the
right one later, let&#39;s first check the connection factory... 
Right click, <code>Go To Implementation</code>. Nah:</p>
<pre class="highlight"><code class="hljs nginx"><span class="hljs-title">The</span> symbol has <span class="hljs-built_in">no</span> implementation
</code></pre><p>What? But the application works! Ah, <code>IDatabaseConnectionFactory</code> comes
from an internal library, so most probably the implementation is also 
inside that library.</p>
<p>Clearly, navigation doesn&#39;t go that well so far.</p>
<h2 id="dependency-graph">Dependency Graph</h2>
<p>When code reading gets tricky, usually an image can boost the understanding.
The picture below actually shows the graph of class dependencies from our
example:</p>
<p><img src="https://mikhail.io/2017/03/visualizing-dependency-tree-from-di-container//class-dependency-graph.png" alt="Class Dependency Graph"></p>
<p>Each node is a class, each arrow is a dependency - an interface injected
into the constructor. </p>
<p>Just by looking at the picture for a minute of two you can start seeing some 
structure, and get at least the high-level opinion about the application
complexity and class relationships.</p>
<p>Picture is also a great way of communication. Once you understand the structure,
you can explain it to a colleague much easier with boxes and lines
on the screen in addition to a plain wall of code.</p>
<p>You can enrich such picture with comments at the time of writing and leave 
it to your future self or anyone who would read the code in 2 years time.</p>
<p>But now the question is - what&#39;s the easiest way to draw such dependency graph?</p>
<h2 id="di-container">DI Container</h2>
<p>The assumption of this post is that a dependency injection (DI) container
of some kind is used in the project. If so, chances are that you can get such
dependency graph from the container registrations.</p>
<p>My example is based on <a href="https://simpleinjector.org/">Simple Injector</a> DI 
container which is used by ourselves. So, further on I will explain how to
draw a dependency graph from Simple Injector container.</p>
<p>My guess is that any mature DI library will provide you with such possibility,
mostly because the dependency graphs are built internally by any container 
during its normal operations.</p>
<h2 id="implementation">Implementation</h2>
<p>The implementation idea of dependency graph visualization is quite simple, as
the biggest chunk of work is done by Simple Injector itself. Here are the steps:</p>
<ol>
<li><p>Run all your DI registrations as you do in the actual application. This will
initialize Container to the desired state.</p>
</li>
<li><p>Define which class should be the root of the dependency tree under study. 
You can refine later, but you need to start somewhere.</p>
</li>
<li><p>Call <code>GetRegistration</code> method of DI container for the selected type. An instance
of <code>InstanceProducer</code> type is returned.</p>
</li>
<li><p>Call <code>GetRelationships</code> method of the instance producer to retrieve all 
interface/class pairs that the given type depends on. Save each relation into
your output list.</p>
</li>
<li><p>Navigate through each dependency recursively to load further layers of the graph.
Basically, do the depth-first search and save all found relations.</p>
</li>
<li><p>Convert the list of found relations into <a href="https://en.wikipedia.org/wiki/Graphviz">GraphViz</a>
textual graph description.</p>
</li>
<li><p>Use a tool like <a href="http://www.webgraphviz.com/">WebGraphviz</a> do the actual
visualization by converting text to picture.</p>
</li>
</ol>
<p>There are several potential pitfalls on the way, like cyclic graphs, decorator
registrations etc. To help you avoid those I&#39;ve created a small library to automate 
steps 3 to 6 from the list above. See my 
<a href="https://github.com/mikhailshilkov/SimpleInjector.Visualization">SimpleInjector.Visualization github repo</a> 
and let me know if you find it useful.</p>
<h2 id="conclusion">Conclusion</h2>
<p>People are good at making sense of visual representations - use that skill to
improve understanding and communication within your development team.</p>
<p>Dependency injection practice requires a lot of ceremony to set it up and
running. Leverage this work for the best: check what kind of insights you
can get from that setup. Dependency graph visualization is one example of 
such leverage, but there might be other gems in there. </p>
<p>Just keep searching!</p>
]]></content>
    </entry>
    
    <entry>
        <title>Azure Functions as a Facade for Azure Monitoring</title>
        <link href="https://mikhail.io/2017/03/azure-functions-as-facade-for-azure-monitoring/"/>
        <updated>2017-03-16T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-03-16,/2017/03/azure-functions-as-facade-for-azure-monitoring/</id>
        <content type="html"><![CDATA[<p>Azure Functions are the Function-as-a-Service offering from Microsoft Azure cloud.
Basically, an Azure Function is a piece of code which gets executed by Azure
every time an event of some kind happens. The environment manages deployment,
event triggers and scaling for you. This approach is often reffered as 
Serverless.</p>
<p>In this post I will describe one use case for Azure Functions: we implemented
a number of functions as a proxy layer between our operations/monitoring 
tool and Azure metric APIs.</p>
<h2 id="problem">Problem</h2>
<p>Automated monitoring and alerting are crucial in order to ensure 24x7 smooth 
operations of our business-critical applications. We host applications both
on-premise and in Azure cloud, and we use a single set of tools for monitoring
across this hybrid environment.</p>
<p>Particularly, we use <a href="https://www.paessler.com/prtg">PRTG Network Monitor</a>
to collect all kinds of metrics about the health of our systems and produce
both real-time alerts and historic trends.</p>
<p>A unit of monitoring in PRTG is called &quot;sensor&quot;. Each sensor polls a specific
data source to retrieve the current value of a metric. The data source can
be a performance counter, a JSON value in HTTP response, a SQL query result
and so on.</p>
<p>The problem is that there is no PRTG sensor for Azure metrics out of the box.
It might be possible to implement a sensor with custom code, e.g. in PowerShell,
but it would be problematic in two ways (at least):</p>
<ol>
<li>The custom code sensors are cumbersome to develop and maintain.</li>
<li>We would have to put sensitive information like Azure API keys and 
connection strings to PRTG.</li>
</ol>
<h2 id="solution-overview">Solution Overview</h2>
<p>To overcome these problems we introduced an intermediate layer, as shown
on the following picture:</p>
<p><img src="https://mikhail.io/2017/03/azure-functions-as-facade-for-azure-monitoring//prtg-http-azure.png" alt="PRTG to HTTP to Azure"></p>
<p>We use PRTG <code>HTTP XML/REST</code> sensor type. This sensor polls a given HTTP endpoint,
parses the response as JSON and finds a predefined field. This field is then
used as the sensor value. It takes 30 seconds to setup such sensor in PRTG. </p>
<p>The HTTP endpoint is hosted inside Azure. It provides a facade for metric
data access. All the sensitive information needed to access Azure metrics 
API is stored inside Azure configuration itself. The implementation knows 
which Azure API to use to get a specific metric, and it hides those 
complications from the client code.</p>
<h2 id="azure-functions">Azure Functions</h2>
<p>We chose Azure Functions as the technology to implement and host such HTTP
facade.</p>
<p>The functions are very easy to create or modify. They are deployed independently
from any other code, so we can update them at any cadence. And no need to
provision any kind of servers anywhere - Azure will run the code for us.</p>
<p>Here is how the whole setup works:</p>
<p><img src="https://mikhail.io/2017/03/azure-functions-as-facade-for-azure-monitoring//prtg-azure-flow.png" alt="Retrieval of data from Azure to PRTG"></p>
<ol>
<li><p>Every X minutes (configured per sensor), PRTG makes an HTTP request 
to a predefined URL. The request includes an Access Key as a query parameter 
(the key is stored in sensor URL configuration). Each access key enables 
access to just one endpoint and is easily revokable.</p>
</li>
<li><p>For each Metric type there is an Azure Function listening for 
HTTP requests from PRTG. Azure authorizes requests that contain valid 
access keys.</p>
</li>
<li><p>Based on query parameters of the request, Azure Function retrieves a proper 
metric value from Azure management API. Depending on the metric type, this 
is accomplished with Azure .NET SDK or by sending a raw HTTP request to 
Azure REST API. </p>
</li>
<li><p>Azure Function parses the response from Azure API and converts it to 
just the value which is requested by PRTG. </p>
</li>
<li><p>The function returns a simple JSON object as HTTP response body. PRTG 
parses JSON, extracts the numeric value, and saves it into the sensor history.</p>
</li>
</ol>
<p>At the time of writing, we have 13 sensors served by 5 Azure Functions:</p>
<p><img src="https://mikhail.io/2017/03/azure-functions-as-facade-for-azure-monitoring//prtg-azure-services.png" alt="Map of PRTG sensors to Functions to Azure services"></p>
<p>I describe several functions below.</p>
<h2 id="service-bus-queue-size">Service Bus Queue Size</h2>
<p>The easiest function to implement is the one which gets the amount of 
messages in the backlog of a given Azure Service Bus queue. The 
<code>function.json</code> file configures input and output HTTP bindings, including
two parameters to derive from the URL: <code>account</code> (namespace) and queue <code>name</code>:</p>
<pre class="highlight"><code class="hljs json">{
  "<span class="hljs-attribute">bindings</span>": <span class="hljs-value">[
    {
      "<span class="hljs-attribute">authLevel</span>": <span class="hljs-value"><span class="hljs-string">"function"</span></span>,
      "<span class="hljs-attribute">name</span>": <span class="hljs-value"><span class="hljs-string">"req"</span></span>,
      "<span class="hljs-attribute">type</span>": <span class="hljs-value"><span class="hljs-string">"httpTrigger"</span></span>,
      "<span class="hljs-attribute">direction</span>": <span class="hljs-value"><span class="hljs-string">"in"</span></span>,
      "<span class="hljs-attribute">route</span>": <span class="hljs-value"><span class="hljs-string">"Queue/{account}/{name}"</span>
    </span>},
    {
      "<span class="hljs-attribute">name</span>": <span class="hljs-value"><span class="hljs-string">"$return"</span></span>,
      "<span class="hljs-attribute">type</span>": <span class="hljs-value"><span class="hljs-string">"http"</span></span>,
      "<span class="hljs-attribute">direction</span>": <span class="hljs-value"><span class="hljs-string">"out"</span>
    </span>}
  ]</span>,
  "<span class="hljs-attribute">disabled</span>": <span class="hljs-value"><span class="hljs-literal">false</span>
</span>}
</code></pre>
<p>The C# implementation uses standard Service Bus API and a connection string
from App Service configuration to retrieve the required data. And then returns
a dynamic object, which will be converted to JSON by Function App runtime.</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-preprocessor">#r "Microsoft.ServiceBus"</span>

<span class="hljs-keyword">using</span> System.Net;
<span class="hljs-keyword">using</span> Microsoft.ServiceBus;

<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">object</span> <span class="hljs-title">Run</span><span class="hljs-params">(HttpRequestMessage req, <span class="hljs-keyword">string</span> account, <span class="hljs-keyword">string</span> name)</span>
</span>{
    <span class="hljs-keyword">var</span> connectionString = Environment.GetEnvironmentVariable(<span class="hljs-string">"sb-"</span> + account);
    <span class="hljs-keyword">var</span> nsmgr = NamespaceManager.CreateFromConnectionString(connectionString);
    <span class="hljs-keyword">var</span> queue = nsmgr.GetQueue(name);
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> 
    {
        messageCount = queue.MessageCountDetails.ActiveMessageCount,
        dlq = queue.MessageCountDetails.DeadLetterMessageCount
    };
}
</code></pre>
<p>And that is all the code required to start monitoring the queues!</p>
<h2 id="service-bus-queue-statistics">Service Bus Queue Statistics</h2>
<p>In addition to queue backlog and dead letter queue size, we wanted to see
some queue statistics like amount of incoming and outgoing messages per
period of time. The corresponding API exists, but it&#39;s not that straightforward,
so I described the whole approach in a separate post: 
<a href="http://mikhail.io/2017/03/azure-service-bus-entity-metrics-dotnet-apis/">Azure Service Bus Entity Metrics .NET APIs</a>.</p>
<p>In my Azure Function I&#39;m using the NuGet package that I mentioned in the post.
This is accomplished by adding a <code>project.json</code> file:</p>
<pre class="highlight"><code class="hljs json">{
  "<span class="hljs-attribute">frameworks</span>": <span class="hljs-value">{
    "<span class="hljs-attribute">net46</span>":<span class="hljs-value">{
      "<span class="hljs-attribute">dependencies</span>": <span class="hljs-value">{
        "<span class="hljs-attribute">MikhailIo.ServiceBusEntityMetrics</span>": <span class="hljs-value"><span class="hljs-string">"0.1.2"</span>
      </span>}
    </span>}
   </span>}
</span>}
</code></pre>
<p>The <code>function.json</code> file is similar to the previous one, but with one added
parameter called <code>metric</code>. I won&#39;t repeat the whole file here.</p>
<p>The Function implementation loads a certificate from the store, calls 
metric API and returns the last metric value available:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">using</span> System.Linq;
<span class="hljs-keyword">using</span> System.Security.Cryptography.X509Certificates;
<span class="hljs-keyword">using</span> MikhailIo.ServiceBusEntityMetrics;

<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> DataPoint <span class="hljs-title">Run</span><span class="hljs-params">(HttpRequestMessage req, <span class="hljs-keyword">string</span> account, <span class="hljs-keyword">string</span> name, <span class="hljs-keyword">string</span> metric)</span>
</span>{
    <span class="hljs-keyword">var</span> subscription = Environment.GetEnvironmentVariable(<span class="hljs-string">"SubscriptionID"</span>);
    <span class="hljs-keyword">var</span> thumbprint = Environment.GetEnvironmentVariable(<span class="hljs-string">"WEBSITE_LOAD_CERTIFICATES"</span>);

    X509Store certStore = <span class="hljs-keyword">new</span> X509Store(StoreName.My, StoreLocation.CurrentUser);
    certStore.Open(OpenFlags.ReadOnly);

    X509Certificate2Collection certCollection = certStore.Certificates.Find(
        X509FindType.FindByThumbprint,
        thumbprint,
        <span class="hljs-keyword">false</span>);

    <span class="hljs-keyword">var</span> client = <span class="hljs-keyword">new</span> QueueStatistics(certCollection[<span class="hljs-number">0</span>], subscription, account, name);
    <span class="hljs-keyword">var</span> metrics = client.GetMetricSince(metric, DateTime.UtcNow.AddMinutes(-<span class="hljs-number">30</span>));
    <span class="hljs-keyword">return</span> metrics.LastOrDefault();
}
</code></pre>
<p>Don&#39;t forget to set <code>WEBSITE_LOAD_CERTIFICATES</code> setting to your certificate 
thumbprint, otherwise Function App won&#39;t load it.</p>
<h2 id="web-app-instance-count">Web App Instance Count</h2>
<p>We are using Azure Web Jobs to run background data processing, e.g. for all
queue message handlers. The jobs are hosted in Web Apps, and have auto-scaling
enabled. When the load on the system grows, Azure spins up additional 
instances to increase the overall throughput.</p>
<p>So, the next metric to be monitored is the amount of Web App instances running.</p>
<p>There is a REST endpoint to retrieve this information, but this time
authentication and authorization are implemented with Active Directory. I
created a helper class to wrap the authentication logic:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title">RestClient</span>
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;T&gt; Query&lt;T&gt;(<span class="hljs-keyword">string</span> url)
    {
        <span class="hljs-keyword">var</span> token = <span class="hljs-function"><span class="hljs-keyword">await</span> <span class="hljs-title">GetAuthorizationHeader</span><span class="hljs-params">()</span></span>;
        <span class="hljs-keyword">var</span> client = <span class="hljs-keyword">new</span> HttpClient();
        client.DefaultRequestHeaders.Authorization = <span class="hljs-keyword">new</span> AuthenticationHeaderValue(<span class="hljs-string">"Bearer"</span>, token);

        <span class="hljs-keyword">var</span> response = <span class="hljs-keyword">await</span> client.GetAsync(url);
        <span class="hljs-keyword">var</span> content = <span class="hljs-keyword">await</span> response.Content.ReadAsStringAsync();
        <span class="hljs-keyword">return</span> JsonConvert.DeserializeObject&lt;T&gt;(content);
    }

    <span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;<span class="hljs-keyword">string</span>&gt; <span class="hljs-title">GetAuthorizationHeader</span><span class="hljs-params">()</span>
    </span>{
        <span class="hljs-keyword">var</span> activeDirectoryID = Environment.GetEnvironmentVariable(<span class="hljs-string">"ActiveDirectoryID"</span>);
        <span class="hljs-keyword">var</span> applicationID = Environment.GetEnvironmentVariable(<span class="hljs-string">"ActiveDirectoryApplicationID"</span>);
        <span class="hljs-keyword">var</span> secret = Environment.GetEnvironmentVariable(<span class="hljs-string">"ActiveDirectorySecret"</span>);

        <span class="hljs-keyword">var</span> context = <span class="hljs-keyword">new</span> AuthenticationContext($<span class="hljs-string">"https://login.windows.net/{activeDirectoryID}"</span>);
        <span class="hljs-keyword">var</span> credential = <span class="hljs-keyword">new</span> ClientCredential(applicationID, secret);
        AuthenticationResult result = 
            <span class="hljs-keyword">await</span> context.AcquireTokenAsync(<span class="hljs-string">"https://management.core.windows.net/"</span>, credential);
        <span class="hljs-keyword">return</span> result.AccessToken;
    }
}
</code></pre>
<p>The function then uses this REST client to query Web App management API, 
converts JSON to strongly typed C# objects and extracts the amount of
instances into HTTP response:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Instance</span>
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> id { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> name { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}

<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Response</span>
{
    <span class="hljs-keyword">public</span> Instance[] <span class="hljs-keyword">value</span> { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}

<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;HttpResponseMessage&gt; <span class="hljs-title">Run</span><span class="hljs-params">(HttpRequestMessage req)</span>
</span>{
    <span class="hljs-keyword">var</span> subscription = Environment.GetEnvironmentVariable(<span class="hljs-string">"SubscriptionID"</span>);
    <span class="hljs-keyword">var</span> resourceGroup = Environment.GetEnvironmentVariable(<span class="hljs-string">"ResourceGroup"</span>);
    <span class="hljs-keyword">var</span> appService = Environment.GetEnvironmentVariable(<span class="hljs-string">"AppService"</span>);

    <span class="hljs-keyword">var</span> url = $<span class="hljs-string">"https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resourceGroup}"</span> +
              $<span class="hljs-string">"/providers/Microsoft.Web/sites/{appService}/instances?api-version=2015-08-01"</span>;
    <span class="hljs-keyword">var</span> response = <span class="hljs-keyword">await</span> RestClient.Query&lt;Response&gt;(url);

    <span class="hljs-keyword">return</span> req.CreateResponse(HttpStatusCode.OK, <span class="hljs-keyword">new</span>
    {
        instanceCount = response.<span class="hljs-keyword">value</span>.Length
    });
}
</code></pre>
<h2 id="users-online">Users Online</h2>
<p>The last example I want to share is related to Application Insights data.
For instance, we inject a small tracking snippet on our front-end page
and then Application Insights track all the page views and other user
activity.</p>
<p>We use the amount of users currently online as another metric for the
monitoring solution. The Application Insights API is currently in
preview, but at least it is nicely described at 
<a href="https://dev.applicationinsights.io/">dev.applicationinsights.io</a>. Be sure
to check out <a href="https://dev.applicationinsights.io/apiexplorer/metrics">API Explorer</a> too.</p>
<p>The following sample function returns the amount of users online:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">UsersCount</span>
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> unique { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}

<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Value</span>
{
    [JsonProperty(<span class="hljs-string">"users/count"</span>)]
    <span class="hljs-keyword">public</span> UsersCount UsersCount { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}

<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Response</span>
{
    <span class="hljs-keyword">public</span> Value <span class="hljs-keyword">value</span> { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}

<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;HttpResponseMessage&gt; <span class="hljs-title">Run</span><span class="hljs-params">(HttpRequestMessage req)</span>
</span>{
    <span class="hljs-keyword">var</span> appID = Environment.GetEnvironmentVariable(<span class="hljs-string">"ApplicationInsightsID"</span>);
    <span class="hljs-keyword">var</span> key = Environment.GetEnvironmentVariable(<span class="hljs-string">"ApplicationInsightsKey"</span>);

    <span class="hljs-keyword">var</span> client = <span class="hljs-keyword">new</span> HttpClient();
    client.DefaultRequestHeaders.Add(<span class="hljs-string">"x-api-key"</span>, key);
    <span class="hljs-keyword">var</span> url = $<span class="hljs-string">"https://api.applicationinsights.io/beta/apps/{appID}/metrics/users/count"</span>;

    <span class="hljs-keyword">var</span> response = <span class="hljs-keyword">await</span> client.GetAsync(url);
    <span class="hljs-keyword">var</span> content = <span class="hljs-keyword">await</span> response.Content.ReadAsStringAsync();
    <span class="hljs-keyword">var</span> r = JsonConvert.DeserializeObject&lt;Response&gt;(content);

    <span class="hljs-keyword">return</span> req.CreateResponse(HttpStatusCode.OK, <span class="hljs-keyword">new</span>
    {
        usersCount = r.<span class="hljs-keyword">value</span>.UsersCount.unique
    });
}
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>It seems that monitoring metrics retrieval is an ideal scenario to start
using Azure Functions. The Functions are very easy to create and modify,
they abstract away the details of hosting Web API endpoints, and at the same
time give you the full power of C# (or F#) and Azure.</p>
<p>And because we only call those functions about 1 time per minute,
they are free to run!</p>
]]></content>
    </entry>
    
    <entry>
        <title>Azure Service Bus Entity Metrics .NET APIs</title>
        <link href="https://mikhail.io/2017/03/azure-service-bus-entity-metrics-dotnet-apis/"/>
        <updated>2017-03-02T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-03-02,/2017/03/azure-service-bus-entity-metrics-dotnet-apis/</id>
        <content type="html"><![CDATA[<p>Azure Service Bus is a key component of many background processing applications
hosted in Azure,
so it definitely requires monitoring and alerting. My goal for our 
monitoring solution was to provide an API to retrieve the following parameters
for each Service Bus queue/topic in our application:</p>
<ul>
<li>Message count (backlog)</li>
<li>Dead letter queue count</li>
<li>Amount of Incoming messages per time period</li>
<li>Amount of Processed messages per time period</li>
</ul>
<p>The first two are easily retrieved from <code>QueueDescription</code> object (see 
<a href="https://msdn.microsoft.com/library/azure/hh780773.aspx">MSDN</a>):</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> nsmgr = NamespaceManager.CreateFromConnectionString(connectionString);
<span class="hljs-keyword">var</span> queue = nsmgr.GetQueue(name);
<span class="hljs-keyword">var</span> backlog = queue.MessageCountDetails.ActiveMessageCount;
<span class="hljs-keyword">var</span> dlq = q.MessageCountDetails.DeadLetterMessageCount;
</code></pre>
<p>The other two metrics are not readily available from the .NET SDK though.
There are some extra metrics described in
<a href="https://docs.microsoft.com/en-us/rest/api/servicebus/service-bus-entity-metrics-rest-apis">Service Bus Entity Metrics REST APIs</a>
but the docs are really brief, wague and lack any examples.</p>
<p>So the rest of this post will be a walkthrough of how to consume those 
REST API from your .NET code.</p>
<h2 id="management-certificate">Management Certificate</h2>
<p>The API authenticates the caller by its client certificate. This authentication
approach seems to be deprecated for Azure services, but for this particular
API it&#39;s still the way to go.</p>
<p>First, you need to obtain a certificate itself, which means:</p>
<ul>
<li>It&#39;s installed in certificate store on the machine where API call is made</li>
<li>You have a <code>.cer</code> file for it</li>
</ul>
<p>If you are calling API from your workstation, you may just 
<a href="https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-certs-create">Create a new self-signed certificate</a>.</p>
<p>I am calling API from Azure Function App, so I reused the certificate that we already
uploaded to Azure for SSL support.</p>
<p>Once you have the certificate, you have to 
<a href="https://docs.microsoft.com/en-us/azure/azure-api-management-certs">Upload it as a management certificate</a>
to <a href="https://manage.windowsazure.com">&quot;Classic&quot; Azure portal</a>. Yes, 
management certificates are not supported by the the new portal. If you don&#39;t
have access to the old portal, ask your system administrator to grant it.</p>
<p>Finally, here is a code sample to load the certificate in C# code:</p>
<pre class="highlight"><code class="hljs cs">X509Store store = <span class="hljs-keyword">new</span> X509Store(<span class="hljs-string">"My"</span>, StoreLocation.CurrentUser);
store.Open(OpenFlags.ReadOnly);
<span class="hljs-keyword">var</span> cert = store.Certificates.Find(
    X509FindType.FindBySubjectName, 
    <span class="hljs-string">"&lt;certificate name of yours&gt;"</span>, 
    <span class="hljs-keyword">false</span>)[<span class="hljs-number">0</span>];
</code></pre>
<h2 id="request-headers">Request Headers</h2>
<p>Here is a helper class which adds the specified certificate to each request 
and sets the appropriate headers too:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">internal</span> <span class="hljs-keyword">class</span> <span class="hljs-title">AzureManagementClient</span> : <span class="hljs-title">WebClient</span>
{
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">readonly</span> X509Certificate2 certificate;

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">AzureManagementClient</span><span class="hljs-params">(X509Certificate2 certificate)</span>
    </span>{
        <span class="hljs-keyword">this</span>.certificate = certificate;
    }

    <span class="hljs-function"><span class="hljs-keyword">protected</span> <span class="hljs-keyword">override</span> WebRequest <span class="hljs-title">GetWebRequest</span><span class="hljs-params">(Uri address)</span>
    </span>{
        <span class="hljs-keyword">var</span> request = (HttpWebRequest)<span class="hljs-keyword">base</span>.GetWebRequest(address);

        request.ClientCertificates.Add(<span class="hljs-keyword">this</span>.certificate);
        request.Headers.Add(<span class="hljs-string">"x-ms-version: 2013-10-01"</span>);
        request.Accept = <span class="hljs-string">"application/json"</span>;

        <span class="hljs-keyword">return</span> request;
    }
}
</code></pre>
<p>This code is mostly copied from the very useful 
<a href="https://cincycoder.wordpress.com/2015/11/18/azure-service-bus-entity-metrics-api/">post of Brian Starr</a>,
so thank you Brian.</p>
<h2 id="getting-the-list-of-metrics">Getting the List of Metrics</h2>
<p>To get the list of available metrics you will need 3 string parameters:</p>
<ul>
<li>Azure subscription ID</li>
<li>Service Bus namespace</li>
<li>Queue name</li>
</ul>
<p>The following picture shows all of them on Azure Portal screen:</p>
<p><img src="https://mikhail.io/2017/03/azure-service-bus-entity-metrics-dotnet-apis//servicebusparameters.png" alt="Service Bus Parameters"></p>
<p>Now, format the following request URL and query it using our azure client:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> client = <span class="hljs-keyword">new</span> AzureManagementClient(cert);
<span class="hljs-keyword">var</span> url = $<span class="hljs-string">"https://management.core.windows.net/{subscriptionId}"</span> +
          $<span class="hljs-string">"/services/servicebus/namespaces/{serviceBusNamespace}"</span> +
          $<span class="hljs-string">"/queues/{queueName}/Metrics"</span>;
<span class="hljs-keyword">var</span> result = client.DownloadString(url);
</code></pre>
<p>If you did everything correctly, you will get the list of supported metrics
in JSON. Congratulations, that&#39;s a major accomplishment :)</p>
<p>And here is a quick way to convert JSON to C# array:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Metric</span>
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Name { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Unit { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> PrimaryAggregation { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> DisplayName { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}
</code></pre>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> metrics = JsonConvert.DeserializeObject&lt;Metric[]&gt;(result);
</code></pre>
<h2 id="getting-the-metric-values">Getting the Metric Values</h2>
<p>Now, to get the metric values themselves, you will need some extra 
parameters:</p>
<ul>
<li>Metric name (take a value of <code>Name</code> properties from <code>Metric</code> class above)</li>
<li>Rollup period, or aggregation period: 5 minute, 1 hour, 1 day, or 1 week,
take the <code>Pxxx</code> code from <a href="https://docs.microsoft.com/en-us/rest/api/servicebus/supported-rollups">here</a></li>
<li>Start date/time (UTC) of the data period to query</li>
</ul>
<p>Here is the sample code:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> time = DateTime.UtcNow.AddHours(-<span class="hljs-number">1</span>).ToString(<span class="hljs-string">"s"</span>);

<span class="hljs-keyword">var</span> client = <span class="hljs-keyword">new</span> AzureManagementClient(cert);
<span class="hljs-keyword">var</span> url = $<span class="hljs-string">"https://management.core.windows.net/{subscriptionId}"</span> +
          $<span class="hljs-string">"/services/servicebus/namespaces/{serviceBusNamespace}"</span> +
          $<span class="hljs-string">"/queues/{queueName}/Metrics/{metric}"</span> +
          $<span class="hljs-string">"/Rollups/PT5M/Values?$filter=Timestamp%20ge%20datetime'{time}Z'"</span>;

<span class="hljs-keyword">var</span> result = client.DownloadString(url);
</code></pre>
<p>I am using <code>incoming</code> metric to get the amount of enqueued messages per period
and <code>outgoing</code> metric to get the amount of dequeued messages.</p>
<p>The strongly typed version is simple:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">DataPoint</span>
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Timestamp { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">long</span> Total { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}
</code></pre>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> data = JsonConvert.DeserializeObject&lt;DataPoint[]&gt;(result);
</code></pre>
<h2 id="working-example">Working Example</h2>
<p>I&#39;ve authored a small library which wraps the HTTP request into strongly
typed .NET classes. You can see it in
<a href="https://github.com/mikhailshilkov/ServiceBusEntityMetrics">my github repository</a>
or grab it from <a href="https://www.nuget.org/packages/MikhailIo.ServiceBusEntityMetrics/">NuGet</a>.</p>
]]></content>
    </entry>
    
    <entry>
        <title>Coding Puzzle in F#: Find the Number of Islands</title>
        <link href="https://mikhail.io/2017/02/coding-puzzle-in-fsharp-find-the-number-of-islands/"/>
        <updated>2017-02-01T00:00:00.000Z</updated>
        <id>tag:mikhail.io,2017-02-01,/2017/02/coding-puzzle-in-fsharp-find-the-number-of-islands/</id>
        <content type="html"><![CDATA[<p>Here&#39;s a programming puzzle. Given 2D matrix of 0&#39;s and 1&#39;s, find the number of islands. 
A group of connected 1&#39;s forms an island. For example, the below matrix contains 5 islands</p>
<pre class="highlight"><code class="hljs mathematica"><span class="hljs-keyword">Input</span> : mat = <span class="hljs-list">{{1, 1, 0, 0, 0}</span>,
               <span class="hljs-list">{0, 1, 0, 0, 1}</span>,
               <span class="hljs-list">{1, 0, 0, 1, 1}</span>,
               <span class="hljs-list">{0, 0, 0, 0, 0}</span>,
               <span class="hljs-list">{1, 0, 1, 0, 1}</span>}
Output : <span class="hljs-number">5</span>
</code></pre><p>A typical solution to this problem will be implemented in C++, Java or C# and will involve
a loop to iterate through the matrix, and another loop or recursion to traverse islands.
The traversal progress will be tracked in an auxiliary mutable array, denoting the visited
nodes. An example of such solution (and the definition of the problem above) can be
found <a href="http://www.geeksforgeeks.org/find-number-of-islands/">here</a>.</p>
<p>I want to give an example of solution done in F#, with generic immutable data structures
and pure functions.</p>
<h2 id="graph-traversal">Graph Traversal</h2>
<p>First of all, this puzzle is a variation of the standard problem: Counting number of 
connected components in a graph.</p>
<p><img src="https://mikhail.io/2017/02/coding-puzzle-in-fsharp-find-the-number-of-islands//islands.png" alt="Connected Graph Components"></p>
<p>I will start my implementation with a graph traversal implementation, and then we
will apply it to the 2D matrix at hand.</p>
<p>The graph is defined by the following type:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Graph</span>&lt;<span class="hljs-title">'a</span>&gt; </span>= {
  Nodes: seq&lt;<span class="hljs-attribute">'a</span>&gt;
  Neighbours: <span class="hljs-attribute">'a</span> -&gt; seq&lt;<span class="hljs-attribute">'a</span>&gt;
}
</code></pre>
<p>It is a record type with two fields: a sequence of all nodes, and a function to
get neighbour nodes for a given node. The type of the node is generic: I&#39;ll use
numbers for our example, but <code>Graph</code> type doesn&#39;t care much.</p>
<p>The traversal plan is the following:</p>
<ol>
<li><p>Go through the sequence of graph nodes.</p>
</li>
<li><p>Keep two accumulator data structures: the list of disjoint sub-graphs 
(sets of nodes connected to each other) and the set of visited nodes. 
Both are empty at the beginning.</p>
</li>
<li><p>If the current node is not in the visited set, recursively traverse all
neighbours to find the current connected component.</p>
</li>
<li><p>The connected component traversal is the Depth-First Search, each node
is added to both current set and total visited set.</p>
</li>
</ol>
<p>Let&#39;s start the implementation from inside out. The following recursive function
adds a node to the accumulated sets and calls itself for non-visited neighbours:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> <span class="hljs-keyword">rec</span> visitNode accumulator visited node =
  <span class="hljs-keyword">let</span> newAccumulator = Set.add node accumulator
  <span class="hljs-keyword">let</span> newVisited = Set.add node visited

  graph.Neighbours node
  |&gt; Seq.filter (<span class="hljs-keyword">fun</span> n -&gt; Set.contains n newVisited |&gt; not)
  |&gt; Seq.fold (<span class="hljs-keyword">fun</span> (acc, vis) n -&gt; visitNode acc vis n) (newAccumulator, newVisited)
</code></pre>
<p>The type of this function is <code>Set&lt;&#39;a&gt; -&gt; Set&lt;&#39;a&gt; -&gt; &#39;a -&gt; Set&lt;&#39;a&gt; * Set&lt;&#39;a&gt;</code>.</p>
<p>Step 3 is implemented with <code>visitComponent</code> function:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> visitComponent (sets, visited) node =
  <span class="hljs-keyword">if</span> Set.contains node visited 
  <span class="hljs-keyword">then</span> sets, visited
  <span class="hljs-keyword">else</span>
    <span class="hljs-keyword">let</span> newIsland, newVisited = visitNode Set.empty visited node
    newIsland :: sets, newVisited
</code></pre>
<p>Now, the graph traversal is just a <code>fold</code> of graph nodes with <code>visitComponent</code> function.</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">module</span> Graph =
  <span class="hljs-keyword">let</span> findConnectedComponents graph = 
    graph.Nodes
    |&gt; Seq.fold visitComponent ([], Set.empty)
    |&gt; fst
</code></pre>
<p>This is the only public function of our graph API, available for the client 
applications. The <code>visitNode</code> and <code>visitComponent</code> are defined as local functions
underneath (and they close over the graph value).</p>
<h2 id="2d-matrix">2D Matrix</h2>
<p>Now, let&#39;s forget about the graphs for a second and model the 2D matrix of integers.
The type definition is simple, it&#39;s just an alias for the array:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Matrix2D</span> </span>= int[,]
</code></pre>
<p>Now, we need to be able to traverse the matrix, i.e. iterate through all elements and
find the neighbours of each element. </p>
<p>The implementation below is mostly busy validating the boundaries of the array. The
neighbours of a cell are up to 8 cells around it, diagonal elements included.</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">module</span> Matrix2D =
  <span class="hljs-keyword">let</span> allCells (mx: Matrix2D) = seq {
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> [<span class="hljs-number">0</span> .. Array2D.length1 mx - <span class="hljs-number">1</span>] <span class="hljs-keyword">do</span>
      <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> [<span class="hljs-number">0</span> .. Array2D.length2 mx - <span class="hljs-number">1</span>] -&gt; x, y
  }

  <span class="hljs-keyword">let</span> neighbours (mx: Matrix2D) (x,y) =
    Seq.crossproduct [x-<span class="hljs-number">1</span> .. x+<span class="hljs-number">1</span>] [y-<span class="hljs-number">1</span> .. y+<span class="hljs-number">1</span>]
    |&gt; Seq.filter (<span class="hljs-keyword">fun</span> (i, j) -&gt; i &gt;= <span class="hljs-number">0</span> &amp;&amp; j &gt;= <span class="hljs-number">0</span> 
                              &amp;&amp; i &lt; Array2D.length1 mx 
                              &amp;&amp; j &lt; Array2D.length2 mx)
    |&gt; Seq.filter (<span class="hljs-keyword">fun</span> (i, j) -&gt; i &lt;&gt; x || j &lt;&gt; y)
</code></pre>
<h2 id="putting-it-all-together">Putting It All Together</h2>
<p>Now we are all set to solve the puzzle. Here is our input array:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> mat = array2D
            [| [|<span class="hljs-number">1</span>; <span class="hljs-number">1</span>; <span class="hljs-number">0</span>; <span class="hljs-number">0</span>; <span class="hljs-number">0</span>|];
               [|<span class="hljs-number">0</span>; <span class="hljs-number">1</span>; <span class="hljs-number">0</span>; <span class="hljs-number">0</span>; <span class="hljs-number">1</span>|];
               [|<span class="hljs-number">1</span>; <span class="hljs-number">0</span>; <span class="hljs-number">0</span>; <span class="hljs-number">1</span>; <span class="hljs-number">1</span>|];
               [|<span class="hljs-number">0</span>; <span class="hljs-number">0</span>; <span class="hljs-number">0</span>; <span class="hljs-number">0</span>; <span class="hljs-number">0</span>|];
               [|<span class="hljs-number">1</span>; <span class="hljs-number">0</span>; <span class="hljs-number">1</span>; <span class="hljs-number">0</span>; <span class="hljs-number">1</span>|]
            |]
</code></pre>
<p>We need a function to define if a given cell is a piece of an island:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> isNode (x, y) = mat.[x, y] = <span class="hljs-number">1</span>
</code></pre>
<p>And here is the essence of the solution - our graph definition. Both <code>Nodes</code>
and <code>Neightbours</code> are matrix cells filtered to contain 1&#39;s. </p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> graph = {
  Nodes = Matrix2D.allCells mat |&gt; Seq.filter isNode
  Neighbours = Matrix2D.neighbours mat &gt;&gt; Seq.filter isNode
}
</code></pre>
<p>The result is calculated with one-liner:</p>
<pre class="highlight"><code class="hljs fs">graph |&gt; Graph.findConnectedComponents |&gt; List.length
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>The implementation above represents my attempt to solve in a functional way
the puzzle which is normally solved in imperative style. I took a step
back and tried to model the underlying concepts with separate data structures.
The types and functions might be reused for similar problems in the same
domain space.</p>
<p>While not a rocket science, the Connected Islands puzzle is a good exercise
and provides a nice example of functional concepts, which I&#39;m planning to
use while discussing FP and F#.</p>
<p>The full code can be found in <a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/ConnectedIslands.fs">my github</a>.</p>
]]></content>
    </entry>
    
</feed>