<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#">
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>

    <meta name="description" content="Software development using .NET, C#, SQL, Javascript and related technologies" />

    <title>Mikhail Shilkov</title>
    <meta name="author" content="Mikhail Shilkov">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="twitter:card" content="summary_large_image"></meta>
    <meta name="twitter:creator" content="@MikhailShilkov"></meta>
    <meta name="twitter:title" content="Mikhail Shilkov"></meta>

    <meta property="og:type" content="article" />
    <meta property="og:title" content="Mikhail Shilkov" />
    <meta property="og:url" content="https://mikhail.io/7/index.html" />




    <link href="/feed/" rel="alternate" title="mikhail.io" type="application/atom+xml">
    <link href="/favicon.ico?v=2" rel="shortcut icon">

    <!-- Bootstrap -->
    <link href="/vendor/prism.css" rel="stylesheet" media="screen">
    <link href="/styles/site.css" rel="stylesheet" media="screen">

    <meta name="generator" content="DocPad v6.80.6" />
    
</head>
<body>

<div class="navbar navbar-default navbar-static-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">
                <span class="text-primary">Mikhail Shilkov</span><br />
                <span class="elevator-pitch">Serverless, Azure, FP, F# and more</span>
            </a>
        </div>
        <div class="collapse navbar-collapse navbar-right">
            <ul class="nav navbar-nav">
                <!--<li><a href="/">Blog</a></li>-->
                
                    <li><a href="/tags/">Topics</a></li>
                
                    <li><a href="/archives/">Archives</a></li>
                
                    <li><a href="/talks/">Talks</a></li>
                
                    <li><a href="/about/">About</a></li>
                
                <li class="hidden-xs">
                    <a href="/feed/" class="rss"><span class="icon icon-feed"></span></a>
                    <a href="https://www.linkedin.com/in/mikhailshilkov" class="linkedin"><span class="icon icon-linkedin"></span></a>
                    <a href="https://twitter.com/mikhailshilkov" class="twitter"><span class="icon icon-twitter"></span></a>
                    <a href="https://github.com/mikhailshilkov" class="github"><span class="icon icon-github"></span></a>
                </li>
            </ul>
            <form class="navbar-form navbar-right hidden-xs" role="search" action="https://google.com/search"
                  method="get">
                <div class="form-group">
                    <input type="search" name="q" class="form-control" placeholder="Search">
                    <input type="hidden" name="q" value="site:mikhail.io">
                </div>
            </form>
        </div>
    </div>
</div>
<div class="container">
    
    <article class="post">
    <div class="post-date">Mar 25th, 2017</div>
    
    <h1><a href='/2017/03/visualizing-dependency-tree-from-di-container/'>Visualizing Dependency Tree from DI Container</a></h1>
    

    

    <div class="post-content">
        <p>So you are a C# developer. And you need to read the code and understand its
structure. Maybe you&#39;ve just joined the project, or it&#39;s your own code you
wrote 1 year ago. In any case, reading code is hard.</p>
<p>Luckily, some good thought was applied to this particular piece of code.
It&#39;s all broken down into small classes (they might even be SOLID!), and all 
the dependencies are injected via constructors. It looks like it&#39;s your
code indeed.</p>
<p>So, you figured out that the entry point for your current use case is the
class called <code>ThingService</code>. It&#39;s probably doing something with <code>Thing</code>&#39;s
and that&#39;s what you need. The signature of the class constructor looks 
like this:</p>
<pre><code class="language-csharp">public ThingService(
    IGetThings readRepository,
    ISaveThing saveRepository,
    IParseAndValidateExcel&lt;Thing, string&gt; fileParser,
    IThingChangeDetector thingChangeDetector,
    IMap&lt;Thing, ThingDTO&gt; thingToDtoMapper,
    IMap&lt;int, ThingDTO, Thing&gt; dtoToThingMapper)</code></pre>
<p>OK, so we clearly have 6 dependencies here, and they are all interfaces.
We don&#39;t know where those interfaces are implemented, but hey - we&#39;ve got
the best tooling in the industry, so right click on <code>IGetThings</code>, then 
<code>Go To Implementation</code>.</p>
<pre><code class="language-csharp">public DapperThingRepository(
    ICRUDAdapter adapter,
    IDatabaseConnectionFactory connectionFactory,
    IMap&lt;Thing, ThingRow&gt; thingRowMapper,
    IMap&lt;ThingRow, Thing&gt; thingMapper)</code></pre>
<p>Now we know that we get <code>Thing</code> from Dapper, so probably from a SQL database.
Let&#39;s go one level deeper and check where those Mappers are implemented.
Right click, <code>Go To Implementation</code>... But instead of navigating to another code
file you see</p>
<pre><code>Find Symbol Result - 28 matches found</code></pre><p>Oh, right, looks like we use <code>IMap&lt;T, U&gt;</code> in more places. OK, we&#39;ll find the
right one later, let&#39;s first check the connection factory... 
Right click, <code>Go To Implementation</code>. Nah:</p>
<pre><code>The symbol has no implementation</code></pre><p>What? But the application works! Ah, <code>IDatabaseConnectionFactory</code> comes
from an internal library, so most probably the implementation is also 
inside that library.</p>
<p>Clearly, navigation doesn&#39;t go that well so far.</p>
<h2 id="dependency-graph">Dependency Graph</h2>
<p>When code reading gets tricky, usually an image can boost the understanding.
The picture below actually shows the graph of class dependencies from our
example:</p>
<p><img src="/2017/03/visualizing-dependency-tree-from-di-container//class-dependency-graph.png" alt="Class Dependency Graph"></p>
<p>Each node is a class, each arrow is a dependency - an interface injected
into the constructor. </p>
<p>Just by looking at the picture for a minute of two you can start seeing some 
structure, and get at least the high-level opinion about the application
complexity and class relationships.</p>
<p>Picture is also a great way of communication. Once you understand the structure,
you can explain it to a colleague much easier with boxes and lines
on the screen in addition to a plain wall of code.</p>
<p>You can enrich such picture with comments at the time of writing and leave 
it to your future self or anyone who would read the code in 2 years time.</p>
<p>But now the question is - what&#39;s the easiest way to draw such dependency graph?</p>
<h2 id="di-container">DI Container</h2>
<p>The assumption of this post is that a dependency injection (DI) container
of some kind is used in the project. If so, chances are that you can get such
dependency graph from the container registrations.</p>
<p>My example is based on <a href="https://simpleinjector.org/">Simple Injector</a> DI 
container which is used by ourselves. So, further on I will explain how to
draw a dependency graph from Simple Injector container.</p>
<p>My guess is that any mature DI library will provide you with such possibility,
mostly because the dependency graphs are built internally by any container 
during its normal operations.</p>
<h2 id="implementation">Implementation</h2>
<p>The implementation idea of dependency graph visualization is quite simple, as
the biggest chunk of work is done by Simple Injector itself. Here are the steps:</p>
<ol>
<li><p>Run all your DI registrations as you do in the actual application. This will
initialize Container to the desired state.</p>
</li>
<li><p>Define which class should be the root of the dependency tree under study. 
You can refine later, but you need to start somewhere.</p>
</li>
<li><p>Call <code>GetRegistration</code> method of DI container for the selected type. An instance
of <code>InstanceProducer</code> type is returned.</p>
</li>
<li><p>Call <code>GetRelationships</code> method of the instance producer to retrieve all 
interface/class pairs that the given type depends on. Save each relation into
your output list.</p>
</li>
<li><p>Navigate through each dependency recursively to load further layers of the graph.
Basically, do the depth-first search and save all found relations.</p>
</li>
<li><p>Convert the list of found relations into <a href="https://en.wikipedia.org/wiki/Graphviz">GraphViz</a>
textual graph description.</p>
</li>
<li><p>Use a tool like <a href="http://www.webgraphviz.com/">WebGraphviz</a> do the actual
visualization by converting text to picture.</p>
</li>
</ol>
<p>There are several potential pitfalls on the way, like cyclic graphs, decorator
registrations etc. To help you avoid those I&#39;ve created a small library to automate 
steps 3 to 6 from the list above. See my 
<a href="https://github.com/mikhailshilkov/SimpleInjector.Visualization">SimpleInjector.Visualization github repo</a> 
and let me know if you find it useful.</p>
<h2 id="conclusion">Conclusion</h2>
<p>People are good at making sense of visual representations - use that skill to
improve understanding and communication within your development team.</p>
<p>Dependency injection practice requires a lot of ceremony to set it up and
running. Leverage this work for the best: check what kind of insights you
can get from that setup. Dependency graph visualization is one example of 
such leverage, but there might be other gems in there. </p>
<p>Just keep searching!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/dependency-injection/'>Dependency Injection</a>, <a href='/tags/visualization/'>Visualization</a>, <a href='/tags/clean-code/'>Clean Code</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Mar 16th, 2017</div>
    
    <h1><a href='/2017/03/azure-functions-as-facade-for-azure-monitoring/'>Azure Functions as a Facade for Azure Monitoring</a></h1>
    

    

    <div class="post-content">
        <p>Azure Functions are the Function-as-a-Service offering from Microsoft Azure cloud.
Basically, an Azure Function is a piece of code which gets executed by Azure
every time an event of some kind happens. The environment manages deployment,
event triggers and scaling for you. This approach is often reffered as 
Serverless.</p>
<p>In this post I will describe one use case for Azure Functions: we implemented
a number of functions as a proxy layer between our operations/monitoring 
tool and Azure metric APIs.</p>
<h2 id="problem">Problem</h2>
<p>Automated monitoring and alerting are crucial in order to ensure 24x7 smooth 
operations of our business-critical applications. We host applications both
on-premise and in Azure cloud, and we use a single set of tools for monitoring
across this hybrid environment.</p>
<p>Particularly, we use <a href="https://www.paessler.com/prtg">PRTG Network Monitor</a>
to collect all kinds of metrics about the health of our systems and produce
both real-time alerts and historic trends.</p>
<p>A unit of monitoring in PRTG is called &quot;sensor&quot;. Each sensor polls a specific
data source to retrieve the current value of a metric. The data source can
be a performance counter, a JSON value in HTTP response, a SQL query result
and so on.</p>
<p>The problem is that there is no PRTG sensor for Azure metrics out of the box.
It might be possible to implement a sensor with custom code, e.g. in PowerShell,
but it would be problematic in two ways (at least):</p>
<ol>
<li>The custom code sensors are cumbersome to develop and maintain.</li>
<li>We would have to put sensitive information like Azure API keys and 
connection strings to PRTG.</li>
</ol>
<h2 id="solution-overview">Solution Overview</h2>
<p>To overcome these problems we introduced an intermediate layer, as shown
on the following picture:</p>
<p><img src="/2017/03/azure-functions-as-facade-for-azure-monitoring//prtg-http-azure.png" alt="PRTG to HTTP to Azure"></p>
<p>We use PRTG <code>HTTP XML/REST</code> sensor type. This sensor polls a given HTTP endpoint,
parses the response as JSON and finds a predefined field. This field is then
used as the sensor value. It takes 30 seconds to setup such sensor in PRTG. </p>
<p>The HTTP endpoint is hosted inside Azure. It provides a facade for metric
data access. All the sensitive information needed to access Azure metrics 
API is stored inside Azure configuration itself. The implementation knows 
which Azure API to use to get a specific metric, and it hides those 
complications from the client code.</p>
<h2 id="azure-functions">Azure Functions</h2>
<p>We chose Azure Functions as the technology to implement and host such HTTP
facade.</p>
<p>The functions are very easy to create or modify. They are deployed independently
from any other code, so we can update them at any cadence. And no need to
provision any kind of servers anywhere - Azure will run the code for us.</p>
<p>Here is how the whole setup works:</p>
<p><img src="/2017/03/azure-functions-as-facade-for-azure-monitoring//prtg-azure-flow.png" alt="Retrieval of data from Azure to PRTG"></p>
<ol>
<li><p>Every X minutes (configured per sensor), PRTG makes an HTTP request 
to a predefined URL. The request includes an Access Key as a query parameter 
(the key is stored in sensor URL configuration). Each access key enables 
access to just one endpoint and is easily revokable.</p>
</li>
<li><p>For each Metric type there is an Azure Function listening for 
HTTP requests from PRTG. Azure authorizes requests that contain valid 
access keys.</p>
</li>
<li><p>Based on query parameters of the request, Azure Function retrieves a proper 
metric value from Azure management API. Depending on the metric type, this 
is accomplished with Azure .NET SDK or by sending a raw HTTP request to 
Azure REST API. </p>
</li>
<li><p>Azure Function parses the response from Azure API and converts it to 
just the value which is requested by PRTG. </p>
</li>
<li><p>The function returns a simple JSON object as HTTP response body. PRTG 
parses JSON, extracts the numeric value, and saves it into the sensor history.</p>
</li>
</ol>
<p>At the time of writing, we have 13 sensors served by 5 Azure Functions:</p>
<p><img src="/2017/03/azure-functions-as-facade-for-azure-monitoring//prtg-azure-services.png" alt="Map of PRTG sensors to Functions to Azure services"></p>
<p>I describe several functions below.</p>
<h2 id="service-bus-queue-size">Service Bus Queue Size</h2>
<p>The easiest function to implement is the one which gets the amount of 
messages in the backlog of a given Azure Service Bus queue. The 
<code>function.json</code> file configures input and output HTTP bindings, including
two parameters to derive from the URL: <code>account</code> (namespace) and queue <code>name</code>:</p>
<pre><code class="language-json">{
  &quot;bindings&quot;: [
    {
      &quot;authLevel&quot;: &quot;function&quot;,
      &quot;name&quot;: &quot;req&quot;,
      &quot;type&quot;: &quot;httpTrigger&quot;,
      &quot;direction&quot;: &quot;in&quot;,
      &quot;route&quot;: &quot;Queue/{account}/{name}&quot;
    },
    {
      &quot;name&quot;: &quot;$return&quot;,
      &quot;type&quot;: &quot;http&quot;,
      &quot;direction&quot;: &quot;out&quot;
    }
  ],
  &quot;disabled&quot;: false
}</code></pre>
<p>The C# implementation uses standard Service Bus API and a connection string
from App Service configuration to retrieve the required data. And then returns
a dynamic object, which will be converted to JSON by Function App runtime.</p>
<pre><code class="language-csharp">#r &quot;Microsoft.ServiceBus&quot;

using System.Net;
using Microsoft.ServiceBus;

public static object Run(HttpRequestMessage req, string account, string name)
{
    var connectionString = Environment.GetEnvironmentVariable(&quot;sb-&quot; + account);
    var nsmgr = NamespaceManager.CreateFromConnectionString(connectionString);
    var queue = nsmgr.GetQueue(name);
    return new 
    {
        messageCount = queue.MessageCountDetails.ActiveMessageCount,
        dlq = queue.MessageCountDetails.DeadLetterMessageCount
    };
}</code></pre>
<p>And that is all the code required to start monitoring the queues!</p>
<h2 id="service-bus-queue-statistics">Service Bus Queue Statistics</h2>
<p>In addition to queue backlog and dead letter queue size, we wanted to see
some queue statistics like amount of incoming and outgoing messages per
period of time. The corresponding API exists, but it&#39;s not that straightforward,
so I described the whole approach in a separate post: 
<a href="https://mikhail.io/2017/03/azure-service-bus-entity-metrics-dotnet-apis/">Azure Service Bus Entity Metrics .NET APIs</a>.</p>
<p>In my Azure Function I&#39;m using the NuGet package that I mentioned in the post.
This is accomplished by adding a <code>project.json</code> file:</p>
<pre><code class="language-json">{
  &quot;frameworks&quot;: {
    &quot;net46&quot;:{
      &quot;dependencies&quot;: {
        &quot;MikhailIo.ServiceBusEntityMetrics&quot;: &quot;0.1.2&quot;
      }
    }
   }
}</code></pre>
<p>The <code>function.json</code> file is similar to the previous one, but with one added
parameter called <code>metric</code>. I won&#39;t repeat the whole file here.</p>
<p>The Function implementation loads a certificate from the store, calls 
metric API and returns the last metric value available:</p>
<pre><code class="language-csharp">using System.Linq;
using System.Security.Cryptography.X509Certificates;
using MikhailIo.ServiceBusEntityMetrics;

public static DataPoint Run(HttpRequestMessage req, string account, string name, string metric)
{
    var subscription = Environment.GetEnvironmentVariable(&quot;SubscriptionID&quot;);
    var thumbprint = Environment.GetEnvironmentVariable(&quot;WEBSITE_LOAD_CERTIFICATES&quot;);

    X509Store certStore = new X509Store(StoreName.My, StoreLocation.CurrentUser);
    certStore.Open(OpenFlags.ReadOnly);

    X509Certificate2Collection certCollection = certStore.Certificates.Find(
        X509FindType.FindByThumbprint,
        thumbprint,
        false);

    var client = new QueueStatistics(certCollection[0], subscription, account, name);
    var metrics = client.GetMetricSince(metric, DateTime.UtcNow.AddMinutes(-30));
    return metrics.LastOrDefault();
}</code></pre>
<p>Don&#39;t forget to set <code>WEBSITE_LOAD_CERTIFICATES</code> setting to your certificate 
thumbprint, otherwise Function App won&#39;t load it.</p>
<h2 id="web-app-instance-count">Web App Instance Count</h2>
<p>We are using Azure Web Jobs to run background data processing, e.g. for all
queue message handlers. The jobs are hosted in Web Apps, and have auto-scaling
enabled. When the load on the system grows, Azure spins up additional 
instances to increase the overall throughput.</p>
<p>So, the next metric to be monitored is the amount of Web App instances running.</p>
<p>There is a REST endpoint to retrieve this information, but this time
authentication and authorization are implemented with Active Directory. I
created a helper class to wrap the authentication logic:</p>
<pre><code class="language-csharp">public static class RestClient
{
    public static async Task&lt;T&gt; Query&lt;T&gt;(string url)
    {
        var token = await GetAuthorizationHeader();
        var client = new HttpClient();
        client.DefaultRequestHeaders.Authorization = new AuthenticationHeaderValue(&quot;Bearer&quot;, token);

        var response = await client.GetAsync(url);
        var content = await response.Content.ReadAsStringAsync();
        return JsonConvert.DeserializeObject&lt;T&gt;(content);
    }

    private static async Task&lt;string&gt; GetAuthorizationHeader()
    {
        var activeDirectoryID = Environment.GetEnvironmentVariable(&quot;ActiveDirectoryID&quot;);
        var applicationID = Environment.GetEnvironmentVariable(&quot;ActiveDirectoryApplicationID&quot;);
        var secret = Environment.GetEnvironmentVariable(&quot;ActiveDirectorySecret&quot;);

        var context = new AuthenticationContext($&quot;https://login.windows.net/{activeDirectoryID}&quot;);
        var credential = new ClientCredential(applicationID, secret);
        AuthenticationResult result = 
            await context.AcquireTokenAsync(&quot;https://management.core.windows.net/&quot;, credential);
        return result.AccessToken;
    }
}</code></pre>
<p>The function then uses this REST client to query Web App management API, 
converts JSON to strongly typed C# objects and extracts the amount of
instances into HTTP response:</p>
<pre><code class="language-csharp">public class Instance
{
    public string id { get; set; }
    public string name { get; set; }
}

public class Response
{
    public Instance[] value { get; set; }
}

public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequestMessage req)
{
    var subscription = Environment.GetEnvironmentVariable(&quot;SubscriptionID&quot;);
    var resourceGroup = Environment.GetEnvironmentVariable(&quot;ResourceGroup&quot;);
    var appService = Environment.GetEnvironmentVariable(&quot;AppService&quot;);

    var url = $&quot;https://management.azure.com/subscriptions/{subscription}/resourceGroups/{resourceGroup}&quot; +
              $&quot;/providers/Microsoft.Web/sites/{appService}/instances?api-version=2015-08-01&quot;;
    var response = await RestClient.Query&lt;Response&gt;(url);

    return req.CreateResponse(HttpStatusCode.OK, new
    {
        instanceCount = response.value.Length
    });
}</code></pre>
<p>Please follow <a href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-create-service-principal-portal#create-an-active-directory-application">this walkthrough</a>
to setup your application in Active Directory, assign required permissions and
get the proper keys.</p>
<h2 id="azure-health">Azure Health</h2>
<p>Azure has a service which reports the health of different services at any
given moment, as acknowledged by Microsoft.</p>
<p>The handy part is that you can provide your subscription ID and then only
services used by that subscription will be reported.</p>
<p>The exact usage of health service may depend on your use case, but the
following example shows how to retrieve the basic counts of services per
reported status.</p>
<pre><code class="language-csharp">public class ResourceProperties
{
    public string availabilityState { get; set; }
    public string summary { get; set; }
    public string detailedStatus { get; set; }
    public string reasonType { get; set; }
    public string occuredTime { get; set; }
    public string reasonChronicity { get; set; }
    public string reportedTime { get; set; }
}
public class Resource
{
    public string id { get; set; }
    public ResourceProperties properties { get; set; }
}

public class Response
{
    public Resource[] value { get; set; }
}

public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequestMessage req)
{
    var subscription = Environment.GetEnvironmentVariable(&quot;SubscriptionID&quot;);

    var url = $&quot;https://management.azure.com/subscriptions/{subscription}/providers/Microsoft.ResourceHealth/availabilityStatuses?api-version=2015-01-01&quot;;
    var r = await RestClient.Query&lt;Response&gt;(url);
    var available = r.value
        .Where(v =&gt; v.properties.availabilityState == &quot;Available&quot;)
        .Count();

    var unknown = r.value
        .Where(v =&gt; v.properties.availabilityState == &quot;Unknown&quot;)
        .Count();

    var other = r.value.Length - available - unknown;

    return req.CreateResponse(HttpStatusCode.OK, new
    {
        available = available,
        unknown = unknown,
        other = other,
        details = r.value
    });
}</code></pre>
<h2 id="users-online">Users Online</h2>
<p>The last example I want to share is related to Application Insights data.
For instance, we inject a small tracking snippet on our front-end page
and then Application Insights track all the page views and other user
activity.</p>
<p>We use the amount of users currently online as another metric for the
monitoring solution. The Application Insights API is currently in
preview, but at least it is nicely described at 
<a href="https://dev.applicationinsights.io/">dev.applicationinsights.io</a>. Be sure
to check out <a href="https://dev.applicationinsights.io/apiexplorer/metrics">API Explorer</a> too.</p>
<p>The following sample function returns the amount of users online:</p>
<pre><code class="language-csharp">public class UsersCount
{
    public long unique { get; set; }
}

public class Value
{
    [JsonProperty(&quot;users/count&quot;)]
    public UsersCount UsersCount { get; set; }
}

public class Response
{
    public Value value { get; set; }
}

public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequestMessage req)
{
    var appID = Environment.GetEnvironmentVariable(&quot;ApplicationInsightsID&quot;);
    var key = Environment.GetEnvironmentVariable(&quot;ApplicationInsightsKey&quot;);

    var client = new HttpClient();
    client.DefaultRequestHeaders.Add(&quot;x-api-key&quot;, key);
    var url = $&quot;https://api.applicationinsights.io/beta/apps/{appID}/metrics/users/count&quot;;

    var response = await client.GetAsync(url);
    var content = await response.Content.ReadAsStringAsync();
    var r = JsonConvert.DeserializeObject&lt;Response&gt;(content);

    return req.CreateResponse(HttpStatusCode.OK, new
    {
        usersCount = r.value.UsersCount.unique
    });
}</code></pre>
<h2 id="combine-several-metrics-in-one-sensor">Combine Several Metrics in One Sensor</h2>
<p>Thanks to suggestion from Luciano Lingnau, we have migrated our PRTG
sensors to <code>HTTP Data Advanced</code>. This sensor type allows bundling several 
related metrics into one sensor with multiple channels. PRTG is then
able to display all those channels on the single chart.</p>
<p>For instance, we use the following channels for Service Bus related
sensors:</p>
<ul>
<li>Active message count</li>
<li>Age of the oldest message sitting inside the queue</li>
<li>Dead letter message count</li>
<li>Incoming messages per 5 minutes</li>
<li>Outgoing messages per 5 minutes</li>
<li>Scheduled message count</li>
</ul>
<p>For each channel, we define units of measure, warning and error thresholds.</p>
<p><code>HTTP Data Advanced</code> expects a URL which returns JSON of the predefined format.
Here is a sample C# code to create a <code>dynamic</code> object which is then converted
to the proper JSON:</p>
<pre><code class="language-csharp">return new
{
    prtg = new
    {
        result = new[]
        {
            new
            {
                channel = &quot;ActiveMessageCount&quot;,
                value = messageCountDetails.ActiveMessageCount,
                unit = &quot;Count&quot;,
                customunit = (string)null,
                limitmaxwarning = (int?)null,
                limitmode = 0
            },
            new
            {
                channel = &quot;DeadLetterMessageCount&quot;,
                value = messageCountDetails.DeadLetterMessageCount,
                unit = &quot;Count&quot;,
                customunit = (string)null,
                limitmaxwarning = (int?)0,
                limitmode = 1
            },
            new
            {
                channel = &quot;OutgoingMessageCount&quot;,
                value = outgoing,
                unit = &quot;custom&quot;,
                customunit = &quot;#/5min&quot;,
                limitmaxwarning = (int?)null,
                limitmode = 0
            },
            new
            {
                channel = &quot;IncommingMessageCount&quot;,
                value = incoming,
                unit = &quot;custom&quot;,
                customunit = &quot;#/5min&quot;,
                limitmaxwarning = (int?)null,
                limitmode = 0
            },
            new
            {
                channel = &quot;ScheduledMessageCount&quot;,
                value = messageCountDetails.ScheduledMessageCount,
                unit = &quot;Count&quot;,
                customunit = (string)null,
                limitmaxwarning = (int?)null,
                limitmode = 0
            },
            new
            {
                channel = &quot;Age&quot;,
                value = age,
                unit = &quot;TimeSeconds&quot;,
                customunit = (string)null,
                limitmaxwarning = (int?)null,
                limitmode = 0
            } 
        }
    }
};
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>It seems that monitoring metrics retrieval is an ideal scenario to start
using Azure Functions. The Functions are very easy to create and modify,
they abstract away the details of hosting Web API endpoints, and at the same
time give you the full power of C# (or F#) and Azure.</p>
<p>And because we only call those functions about 1 time per minute,
they are free to run!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/metrics/'>Metrics</a>, <a href='/tags/monitoring/'>Monitoring</a>, <a href='/tags/prtg/'>PRTG</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Mar 2nd, 2017</div>
    
    <h1><a href='/2017/03/azure-service-bus-entity-metrics-dotnet-apis/'>Azure Service Bus Entity Metrics .NET APIs</a></h1>
    

    

    <div class="post-content">
        <p>Azure Service Bus is a key component of many background processing applications
hosted in Azure,
so it definitely requires monitoring and alerting. My goal for our 
monitoring solution was to provide an API to retrieve the following parameters
for each Service Bus queue/topic in our application:</p>
<ul>
<li>Message count (backlog)</li>
<li>Dead letter queue count</li>
<li>Amount of Incoming messages per time period</li>
<li>Amount of Processed messages per time period</li>
</ul>
<p>The first two are easily retrieved from <code>QueueDescription</code> object (see 
<a href="https://msdn.microsoft.com/library/azure/hh780773.aspx">MSDN</a>):</p>
<pre><code class="language-csharp">var nsmgr = NamespaceManager.CreateFromConnectionString(connectionString);
var queue = nsmgr.GetQueue(name);
var backlog = queue.MessageCountDetails.ActiveMessageCount;
var dlq = q.MessageCountDetails.DeadLetterMessageCount;</code></pre>
<p>The other two metrics are not readily available from the .NET SDK though.
There are some extra metrics described in
<a href="https://docs.microsoft.com/en-us/rest/api/servicebus/service-bus-entity-metrics-rest-apis">Service Bus Entity Metrics REST APIs</a>
but the docs are really brief, wague and lack any examples.</p>
<p>So the rest of this post will be a walkthrough of how to consume those 
REST API from your .NET code.</p>
<h2 id="management-certificate">Management Certificate</h2>
<p>The API authenticates the caller by its client certificate. This authentication
approach seems to be deprecated for Azure services, but for this particular
API it&#39;s still the way to go.</p>
<p>First, you need to obtain a certificate itself, which means:</p>
<ul>
<li>It&#39;s installed in certificate store on the machine where API call is made</li>
<li>You have a <code>.cer</code> file for it</li>
</ul>
<p>If you are calling API from your workstation, you may just 
<a href="https://docs.microsoft.com/en-us/azure/cloud-services/cloud-services-certs-create">Create a new self-signed certificate</a>.</p>
<p>I am calling API from Azure Function App, so I reused the certificate that we already
uploaded to Azure for SSL support.</p>
<p>Once you have the certificate, you have to 
<a href="https://docs.microsoft.com/en-us/azure/azure-api-management-certs">Upload it as a management certificate</a>
to <a href="https://manage.windowsazure.com">&quot;Classic&quot; Azure portal</a>. Yes, 
management certificates are not supported by the the new portal. If you don&#39;t
have access to the old portal, ask your system administrator to grant it.</p>
<p>Finally, here is a code sample to load the certificate in C# code:</p>
<pre><code class="language-csharp">X509Store store = new X509Store(&quot;My&quot;, StoreLocation.CurrentUser);
store.Open(OpenFlags.ReadOnly);
var cert = store.Certificates.Find(
    X509FindType.FindBySubjectName, 
    &quot;&lt;certificate name of yours&gt;&quot;, 
    false)[0];</code></pre>
<h2 id="request-headers">Request Headers</h2>
<p>Here is a helper class which adds the specified certificate to each request 
and sets the appropriate headers too:</p>
<pre><code class="language-csharp">internal class AzureManagementClient : WebClient
{
    private readonly X509Certificate2 certificate;

    public AzureManagementClient(X509Certificate2 certificate)
    {
        this.certificate = certificate;
    }

    protected override WebRequest GetWebRequest(Uri address)
    {
        var request = (HttpWebRequest)base.GetWebRequest(address);

        request.ClientCertificates.Add(this.certificate);
        request.Headers.Add(&quot;x-ms-version: 2013-10-01&quot;);
        request.Accept = &quot;application/json&quot;;

        return request;
    }
}</code></pre>
<p>This code is mostly copied from the very useful 
<a href="https://cincycoder.wordpress.com/2015/11/18/azure-service-bus-entity-metrics-api/">post of Brian Starr</a>,
so thank you Brian.</p>
<h2 id="getting-the-list-of-metrics">Getting the List of Metrics</h2>
<p>To get the list of available metrics you will need 3 string parameters:</p>
<ul>
<li>Azure subscription ID</li>
<li>Service Bus namespace</li>
<li>Queue name</li>
</ul>
<p>The following picture shows all of them on Azure Portal screen:</p>
<p><img src="/2017/03/azure-service-bus-entity-metrics-dotnet-apis//servicebusparameters.png" alt="Service Bus Parameters"></p>
<p>Now, format the following request URL and query it using our azure client:</p>
<pre><code class="language-csharp">var client = new AzureManagementClient(cert);
var url = $&quot;https://management.core.windows.net/{subscriptionId}&quot; +
          $&quot;/services/servicebus/namespaces/{serviceBusNamespace}&quot; +
          $&quot;/queues/{queueName}/Metrics&quot;;
var result = client.DownloadString(url);</code></pre>
<p>If you did everything correctly, you will get the list of supported metrics
in JSON. Congratulations, that&#39;s a major accomplishment :)</p>
<p>And here is a quick way to convert JSON to C# array:</p>
<pre><code class="language-csharp">public class Metric
{
    public string Name { get; set; }
    public string Unit { get; set; }
    public string PrimaryAggregation { get; set; }
    public string DisplayName { get; set; }
}</code></pre>
<pre><code class="language-csharp">var metrics = JsonConvert.DeserializeObject&lt;Metric[]&gt;(result);</code></pre>
<h2 id="getting-the-metric-values">Getting the Metric Values</h2>
<p>Now, to get the metric values themselves, you will need some extra 
parameters:</p>
<ul>
<li>Metric name (take a value of <code>Name</code> properties from <code>Metric</code> class above)</li>
<li>Rollup period, or aggregation period: 5 minute, 1 hour, 1 day, or 1 week,
take the <code>Pxxx</code> code from <a href="https://docs.microsoft.com/en-us/rest/api/servicebus/supported-rollups">here</a></li>
<li>Start date/time (UTC) of the data period to query</li>
</ul>
<p>Here is the sample code:</p>
<pre><code class="language-csharp">var time = DateTime.UtcNow.AddHours(-1).ToString(&quot;s&quot;);

var client = new AzureManagementClient(cert);
var url = $&quot;https://management.core.windows.net/{subscriptionId}&quot; +
          $&quot;/services/servicebus/namespaces/{serviceBusNamespace}&quot; +
          $&quot;/queues/{queueName}/Metrics/{metric}&quot; +
          $&quot;/Rollups/PT5M/Values?$filter=Timestamp%20ge%20datetime&#39;{time}Z&#39;&quot;;

var result = client.DownloadString(url);</code></pre>
<p>I am using <code>incoming</code> metric to get the amount of enqueued messages per period
and <code>outgoing</code> metric to get the amount of dequeued messages.</p>
<p>The strongly typed version is simple:</p>
<pre><code class="language-csharp">public class DataPoint
{
    public string Timestamp { get; set; }
    public long Total { get; set; }
}</code></pre>
<pre><code class="language-csharp">var data = JsonConvert.DeserializeObject&lt;DataPoint[]&gt;(result);</code></pre>
<h2 id="working-example">Working Example</h2>
<p>I&#39;ve authored a small library which wraps the HTTP request into strongly
typed .NET classes. You can see it in
<a href="https://github.com/mikhailshilkov/ServiceBusEntityMetrics">my github repository</a>
or grab it from <a href="https://www.nuget.org/packages/MikhailIo.ServiceBusEntityMetrics/">NuGet</a>.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-service-bus/'>Azure Service Bus</a>, <a href='/tags/metrics/'>Metrics</a>, <a href='/tags/monitoring/'>Monitoring</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Feb 1st, 2017</div>
    
    <h1><a href='/2017/02/coding-puzzle-in-fsharp-find-the-number-of-islands/'>Coding Puzzle in F#: Find the Number of Islands</a></h1>
    

    

    <div class="post-content">
        <p>Here&#39;s a programming puzzle. Given 2D matrix of 0&#39;s and 1&#39;s, find the number of islands. 
A group of connected 1&#39;s forms an island. For example, the below matrix contains 5 islands</p>
<pre><code>Input : mat = {{1, 1, 0, 0, 0},
               {0, 1, 0, 0, 1},
               {1, 0, 0, 1, 1},
               {0, 0, 0, 0, 0},
               {1, 0, 1, 0, 1}}
Output : 5</code></pre><p>A typical solution to this problem will be implemented in C++, Java or C# and will involve
a loop to iterate through the matrix, and another loop or recursion to traverse islands.
The traversal progress will be tracked in an auxiliary mutable array, denoting the visited
nodes. An example of such solution (and the definition of the problem above) can be
found <a href="http://www.geeksforgeeks.org/find-number-of-islands/">here</a>.</p>
<p>I want to give an example of solution done in F#, with generic immutable data structures
and pure functions.</p>
<h2 id="graph-traversal">Graph Traversal</h2>
<p>First of all, this puzzle is a variation of the standard problem: Counting number of 
connected components in a graph.</p>
<p><img src="/2017/02/coding-puzzle-in-fsharp-find-the-number-of-islands//islands.png" alt="Connected Graph Components"></p>
<p>I will start my implementation with a graph traversal implementation, and then we
will apply it to the 2D matrix at hand.</p>
<p>The graph is defined by the following type:</p>
<pre><code class="language-fsharp">type Graph&lt;&#39;a&gt; = {
  Nodes: seq&lt;&#39;a&gt;
  Neighbours: &#39;a -&gt; seq&lt;&#39;a&gt;
}</code></pre>
<p>It is a record type with two fields: a sequence of all nodes, and a function to
get neighbour nodes for a given node. The type of the node is generic: I&#39;ll use
numbers for our example, but <code>Graph</code> type doesn&#39;t care much.</p>
<p>The traversal plan is the following:</p>
<ol>
<li><p>Go through the sequence of graph nodes.</p>
</li>
<li><p>Keep two accumulator data structures: the list of disjoint sub-graphs 
(sets of nodes connected to each other) and the set of visited nodes. 
Both are empty at the beginning.</p>
</li>
<li><p>If the current node is not in the visited set, recursively traverse all
neighbours to find the current connected component.</p>
</li>
<li><p>The connected component traversal is the Depth-First Search, each node
is added to both current set and total visited set.</p>
</li>
</ol>
<p>Let&#39;s start the implementation from inside out. The following recursive function
adds a node to the accumulated sets and calls itself for non-visited neighbours:</p>
<pre><code class="language-fsharp">let rec visitNode accumulator visited node =
  let newAccumulator = Set.add node accumulator
  let newVisited = Set.add node visited

  graph.Neighbours node
  |&gt; Seq.filter (fun n -&gt; Set.contains n newVisited |&gt; not)
  |&gt; Seq.fold (fun (acc, vis) n -&gt; visitNode acc vis n) (newAccumulator, newVisited)</code></pre>
<p>The type of this function is <code>Set&lt;&#39;a&gt; -&gt; Set&lt;&#39;a&gt; -&gt; &#39;a -&gt; Set&lt;&#39;a&gt; * Set&lt;&#39;a&gt;</code>.</p>
<p>Step 3 is implemented with <code>visitComponent</code> function:</p>
<pre><code class="language-fsharp">let visitComponent (sets, visited) node =
  if Set.contains node visited 
  then sets, visited
  else
    let newIsland, newVisited = visitNode Set.empty visited node
    newIsland :: sets, newVisited</code></pre>
<p>Now, the graph traversal is just a <code>fold</code> of graph nodes with <code>visitComponent</code> function.</p>
<pre><code class="language-fsharp">module Graph =
  let findConnectedComponents graph = 
    graph.Nodes
    |&gt; Seq.fold visitComponent ([], Set.empty)
    |&gt; fst</code></pre>
<p>This is the only public function of our graph API, available for the client 
applications. The <code>visitNode</code> and <code>visitComponent</code> are defined as local functions
underneath (and they close over the graph value).</p>
<h2 id="2d-matrix">2D Matrix</h2>
<p>Now, let&#39;s forget about the graphs for a second and model the 2D matrix of integers.
The type definition is simple, it&#39;s just an alias for the array:</p>
<pre><code class="language-fsharp">type Matrix2D = int[,]</code></pre>
<p>Now, we need to be able to traverse the matrix, i.e. iterate through all elements and
find the neighbours of each element. </p>
<p>The implementation below is mostly busy validating the boundaries of the array. The
neighbours of a cell are up to 8 cells around it, diagonal elements included.</p>
<pre><code class="language-fsharp">module Matrix2D =
  let allCells (mx: Matrix2D) = seq {
    for x in [0 .. Array2D.length1 mx - 1] do
      for y in [0 .. Array2D.length2 mx - 1] -&gt; x, y
  }

  let neighbours (mx: Matrix2D) (x,y) =
    Seq.crossproduct [x-1 .. x+1] [y-1 .. y+1]
    |&gt; Seq.filter (fun (i, j) -&gt; i &gt;= 0 &amp;&amp; j &gt;= 0 
                              &amp;&amp; i &lt; Array2D.length1 mx 
                              &amp;&amp; j &lt; Array2D.length2 mx)
    |&gt; Seq.filter (fun (i, j) -&gt; i &lt;&gt; x || j &lt;&gt; y)</code></pre>
<h2 id="putting-it-all-together">Putting It All Together</h2>
<p>Now we are all set to solve the puzzle. Here is our input array:</p>
<pre><code class="language-fsharp">let mat = array2D
            [| [|1; 1; 0; 0; 0|];
               [|0; 1; 0; 0; 1|];
               [|1; 0; 0; 1; 1|];
               [|0; 0; 0; 0; 0|];
               [|1; 0; 1; 0; 1|]
            |]</code></pre>
<p>We need a function to define if a given cell is a piece of an island:</p>
<pre><code class="language-fsharp">let isNode (x, y) = mat.[x, y] = 1</code></pre>
<p>And here is the essence of the solution - our graph definition. Both <code>Nodes</code>
and <code>Neightbours</code> are matrix cells filtered to contain 1&#39;s. </p>
<pre><code class="language-fsharp">let graph = {
  Nodes = Matrix2D.allCells mat |&gt; Seq.filter isNode
  Neighbours = Matrix2D.neighbours mat &gt;&gt; Seq.filter isNode
}</code></pre>
<p>The result is calculated with one-liner:</p>
<pre><code class="language-fsharp">graph |&gt; Graph.findConnectedComponents |&gt; List.length</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>The implementation above represents my attempt to solve in a functional way
the puzzle which is normally solved in imperative style. I took a step
back and tried to model the underlying concepts with separate data structures.
The types and functions might be reused for similar problems in the same
domain space.</p>
<p>While not a rocket science, the Connected Islands puzzle is a good exercise
and provides a nice example of functional concepts, which I&#39;m planning to
use while discussing FP and F#.</p>
<p>The full code can be found in <a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/ConnectedIslands.fs">my github</a>.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/f#/'>F#</a>, <a href='/tags/programming-puzzles/'>Programming Puzzles</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Jan 29th, 2017</div>
    
    <h1><a href='/2017/01/event-sourcing-optimizing-neventstore-sql-read-performance/'>Event Sourcing: Optimizing NEventStore SQL read performance</a></h1>
    

    

    <div class="post-content">
        <p>In <a href="https://mikhail.io/2016/11/event-sourcing-and-io-complexity/">my previous post about Event Store read complexity</a> 
I described how the growth of reads from the event database might be 
quadratic in respect to amount of events per aggregate.</p>
<p>On the higher level, the conclusion was that the event sourced database should be optimized
for reads rather that writes, which is not always obvious from the definition
of the &quot;append-only store&quot;.</p>
<h2 id="neventstore">NEventStore</h2>
<p>In this post I want to look at 
<a href="https://github.com/NEventStore/NEventStore">NEventStore</a> on top of 
<a href="https://azure.microsoft.com/en-us/services/sql-database/">Azure SQL Database</a>
which is the combination we currently use for event sourcing in Azure-based
web application.</p>
<p>NEventStore library provides a C# abstraction over event store with multiple 
providers for several database backends. We use the
<a href="https://github.com/NEventStore/NEventStore.Persistence.SQL">Persistence.SQL provider</a>. 
When you initialize
it with a connection string to an empty database, the provider will go
on and create two tables with schema, indexes etc. The most important
table is <code>Commits</code> and it gets the following schema:</p>
<pre><code class="language-sql">CREATE TABLE dbo.Commits
(
  BucketId          varchar(40),
  StreamId          char(40),
  StreamRevision    int,
  Items             tinyint,
  CommitId          uniqueidentifier,
  CommitSequence    int,
  CheckpointNumber  bigint IDENTITY(1, 1),
  Payload           varbinary(max),
  CommitStamp       datetime2
)
GO
ALTER TABLE dbo.Commits 
ADD CONSTRAINT PK_Commits 
PRIMARY KEY CLUSTERED (CheckpointNumber)</code></pre>
<p>I removed several columns, most indexes and constraints to make the script
more readable.</p>
<p>The primary key is based upon <code>CheckpointNumber</code> - an <code>IDENTITY</code> column, which means 
the new events (commits) are appended to the end of the clustered index. 
Clearly, this is good for <code>INSERT</code> performance.</p>
<p>There is a number of secondary non-clustered indexes that are optimized
for rich API of NEventStore library, e.g. dispatching events to observers,
searching for streams, time-based queries etc.</p>
<h2 id="our-use-case">Our Use Case</h2>
<p>It turns out that we don&#39;t need those extended API provided by <code>NEventStore</code>.
Effectively, we only need two operations to be supported:</p>
<ul>
<li>Add a new event to a stream</li>
<li>Read all events of a stream</li>
</ul>
<p>Our experience of running production-like workloads showed that the read
operation performance suffers a lot when the size of a stream grows. Here
is a sample query plan for the read query with the default schema:</p>
<p><img src="/2017/01/event-sourcing-optimizing-neventstore-sql-read-performance//defaultqueryplan.png" alt="Query Plan with default primary key"></p>
<p>SQL Server uses non-clustered index to find all events of the given
steam, and then does key lookups, which might get very expensive for
large streams with hundreds or thousands of events.</p>
<h2 id="tuning-for-reads">Tuning for Reads</h2>
<p>After seeing this, I decided to re-think the primary index of the
<code>Commits</code> table. Here is what I came down to:</p>
<pre><code class="language-sql">ALTER TABLE dbo.Commits 
ADD CONSTRAINT PK_Commits 
PRIMARY KEY CLUSTERED (BucketId, StreamId, CommitSequence)</code></pre>
<p>Now, all the commits of one stream are physically located together in the
clustered index.</p>
<p>The change makes <code>INSERT</code>&#39;s less efficient. It&#39;s not a simple append to the 
end of the clustered index anymore.</p>
<p>But at this price, the reads just got much faster. Here is the plan for 
the same query over the new schema:</p>
<p><img src="/2017/01/event-sourcing-optimizing-neventstore-sql-read-performance//optimizedqueryplan.png" alt="Query Plan with the new primary key"></p>
<p>Simple, beautiful and fast!</p>
<h2 id="our-results">Our Results</h2>
<p>The results look great for us. We are able to run our 50 GB Commits table
on a 100-DTU SQL Database instance, with typical load of 10 to 25 percent.
The reads are still taking the biggest chunk of the load, with writes
being far behind.</p>
<p>The mileage may vary, so be sure to test your NEventStore schema versus
your workload.</p>
<h2 id="further-improvements">Further Improvements</h2>
<p>Here are some further steps that we might want to take to make <code>Commits</code>
table even faster:</p>
<ul>
<li><p>The table comes with 5 non-clustered indexes. One of them became our
clustered index. Two indexes are unique, so they might be useful for 
duplicate prevention (e.g. in concurrency scenarios). The remaining two
are non-unique, so they can probably be safely deleted unless we start
using other queries that they are intended for.</p>
</li>
<li><p>There are several columns which are not used in our implementation:
<code>StreamIdOriginal</code>, <code>Dispatched</code> and <code>Headers</code> to name a few. We could 
replace the table with a view of the same name, and always return defaults
for those columns in any <code>SELECT</code>, ignoring the values in any <code>INSERT</code>.</p>
</li>
</ul>
<p>But I expect these changes to have moderate impact on performance in contrast
to the primary key change discussed above.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/event-sourcing/'>Event Sourcing</a>, <a href='/tags/neventstore/'>NEventStore</a>, <a href='/tags/sql-server/'>SQL Server</a>, <a href='/tags/performance/'>Performance</a>
    </div>
    
</article>


<div class="page-nav">
    
    <a class="page-nav-newer" href="/6/index.html">&lt;&lt; Previous page</a>
    
    
    <a class="page-nav-older" href="/8/index.html">Next page &gt;&gt;</span></a>
    
</div>

<div id="me">
    <p itemscope itemtype="http://data-vocabulary.org/Person">
        <img src="/images/Headshot-Square.jpg" alt="Mikhail Shilkov" itemprop="photo" />
        I'm <b><span itemprop="name">Mikhail Shilkov</span></b>, a <span itemprop="title">software developer and architect</span>,
        a Microsoft Azure MVP, Russian expat living in the Netherlands. I am passionate about cloud technologies, 
        functional programming and the intersection of the two.
    </p>
    <p>
        <a href="https://www.linkedin.com/in/mikhailshilkov/">LinkedIn</a> &#8226;
        <a href="https://twitter.com/mikhailshilkov">@mikhailshilkov</a> &#8226;
        <a href="https://github.com/mikhailshilkov">GitHub</a> &#8226;
        <a href="https://stackoverflow.com/users/1171619/mikhail">Stack Overflow</a>
    </p>
</div>
</div>
<div class="container">
    <div class="navbar navbar-footer">
        <p class="navbar-center navbar-text">Content copyright &copy; 2018 Mikhail Shilkov</p>
    </div>
</div>



<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.pack.js"></script>
<script src="/vendor/prism.js"></script>
<script src="/site.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59218480-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>