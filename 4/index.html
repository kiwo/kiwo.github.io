<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#">
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>

    <meta name="description" content="Software development using .NET, C#, SQL, Javascript and related technologies" />

    <title>Mikhail Shilkov</title>
    <meta name="author" content="Mikhail Shilkov">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="twitter:card" content="summary"></meta>
    <meta name="twitter:creator" content="@MikhailShilkov"></meta>

    <meta property="og:type" content="article" />
    <meta property="og:title" content="Mikhail Shilkov" />
    <meta property="og:url" content="https://mikhail.io/4/" />



    <link href="/feed/" rel="alternate" title="mikhail.io" type="application/atom+xml">
    <link href="/favicon.ico?v=2" rel="shortcut icon">

    <!-- Bootstrap -->
    <link href="/styles/site.css" rel="stylesheet" media="screen">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/scripts/vendor/html5shiv.js"></script>
    <script src="/scripts/vendor/respond.min.js"></script>
    <![endif]-->

    <meta name="generator" content="DocPad v6.78.6" />
    
</head>
<body>

<div class="navbar navbar-default navbar-static-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">
                <span class="text-primary">Mikhail Shilkov</span><br />
                <span class="elevator-pitch">Serverless, Azure, FP, F# and more</span>
            </a>
        </div>
        <div class="collapse navbar-collapse navbar-right">
            <ul class="nav navbar-nav">
                <!--<li><a href="/">Blog</a></li>-->
                
                    <li><a href="/tags/">Topics</a></li>
                
                    <li><a href="/archives/">Archives</a></li>
                
                    <li><a href="/talks/">Talks</a></li>
                
                    <li><a href="/about/">About</a></li>
                
                <li class="hidden-xs">
                    <a href="/feed/" class="rss"><span class="icon icon-feed"></span></a>
                    <a href="https://www.linkedin.com/in/mikhailshilkov" class="linkedin"><span class="icon icon-linkedin"></span></a>
                    <a href="https://twitter.com/mikhailshilkov" class="twitter"><span class="icon icon-twitter"></span></a>
                    <a href="https://github.com/mikhailshilkov" class="github"><span class="icon icon-github"></span></a>
                </li>
            </ul>
            <form class="navbar-form navbar-right hidden-xs" role="search" action="https://google.com/search"
                  method="get">
                <div class="form-group">
                    <input type="search" name="q" class="form-control" placeholder="Search">
                    <input type="hidden" name="q" value="site:mikhail.io">
                </div>
            </form>
        </div>
    </div>
</div>
<div class="container">
    
    <article class="post">
    <div class="post-date">Jul 4th, 2017</div>
    
    <h1><a href='/2017/07/sending-large-batches-to-azure-service-bus/'>Sending Large Batches to Azure Service Bus</a></h1>
    
    <div class="post-content">
        <p>Azure Service Bus client supports sending messages in batches (<code>SendBatch</code>
and <code>SendBatchAsync</code> methods of <code>QueueClient</code> and <code>TopicClient</code>). However,
the size of a single batch must stay below 256k bytes, otherwise the whole
batch will get rejected.</p>
<p>How do we make sure that the batch-to-be-sent is going to fit? The rest 
of this article will try to answer this seemingly simple question.</p>
<h2 id="problem-statement">Problem Statement</h2>
<p>Given a list of messages of arbitrary type <code>T</code>, we want to send them to Service
Bus in batches. The amount of batches should be close to minimal, but
obviously each one of them must satisfy the restriction of 256k max size.</p>
<p>So, we want to implement a method with the following signature:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> Task SendBigBatchAsync&lt;T&gt;(IEnumerable&lt;T&gt; messages);
</code></pre>
<p>which would work for collections of any size.</p>
<p>To limit the scope, I will restrict the article to the following assumptions:</p>
<ul>
<li><p>Each individual message is less than 256k serialized. If that wasn&#39;t true,
we&#39;d have to put the body into external blob storage first, and then send
the reference. It&#39;s not directly related to the topic of discussion.</p>
</li>
<li><p>I&#39;ll use <code>public BrokeredMessage(object serializableObject)</code> constructor.
Custom serialization could be used, but again, it&#39;s not related to batching,
so I&#39;ll ignore it.</p>
</li>
<li><p>We won&#39;t care about transactions, i.e. if connectivity dies in the middle
of sending the big batch, we might end up with partially sent batch.</p>
</li>
</ul>
<h2 id="messages-of-known-size">Messages of Known Size</h2>
<p>Let&#39;s start with a simple use case: the size of each message is known to us. 
It&#39;s defined by hypothetical <code>Func&lt;T, long&gt; getSize</code> function. Here is a 
helpful extension method that will split an arbitrary collection based on
a metric function and maximum chunk size:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> List&lt;List&lt;T&gt;&gt; ChunkBy&lt;T&gt;(<span class="hljs-keyword">this</span> IEnumerable&lt;T&gt; source, Func&lt;T, <span class="hljs-keyword">long</span>&gt; metric, <span class="hljs-keyword">long</span> maxChunkSize)
{
    <span class="hljs-keyword">return</span> source
        .Aggregate(
            <span class="hljs-keyword">new</span>
            {
                Sum = <span class="hljs-number">0</span>L,
                Current = (List&lt;T&gt;)<span class="hljs-literal">null</span>,
                Result = <span class="hljs-keyword">new</span> List&lt;List&lt;T&gt;&gt;()
            },
            (agg, item) =&gt;
            {
                <span class="hljs-keyword">var</span> <span class="hljs-keyword">value</span> = metric(item);
                <span class="hljs-keyword">if</span> (agg.Current == <span class="hljs-literal">null</span> || agg.Sum + <span class="hljs-keyword">value</span> &gt; maxChunkSize)
                {
                    <span class="hljs-keyword">var</span> current = <span class="hljs-keyword">new</span> List&lt;T&gt; { item };
                    agg.Result.Add(current);
                    <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> { Sum = <span class="hljs-keyword">value</span>, Current = current, agg.Result };
                }

                agg.Current.Add(item);
                <span class="hljs-keyword">return</span> <span class="hljs-keyword">new</span> { Sum = agg.Sum + <span class="hljs-keyword">value</span>, agg.Current, agg.Result };
            })
        .Result;
}
</code></pre>
<p>Now, the implementation of <code>SendBigBatchAsync</code> is simple:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">async</span> Task <span class="hljs-title">SendBigBatchAsync</span>(<span class="hljs-params">IEnumerable&lt;T&gt; messages, Func&lt;T, <span class="hljs-keyword">long</span>&gt; getSize</span>)
</span>{
    <span class="hljs-keyword">var</span> chunks = messages.ChunkBy(getSize, MaxServiceBusMessage);
    <span class="hljs-keyword">foreach</span> (<span class="hljs-keyword">var</span> chunk <span class="hljs-keyword">in</span> chunks)
    {
        <span class="hljs-keyword">var</span> brokeredMessages = chunk.Select(m =&gt; <span class="hljs-keyword">new</span> BrokeredMessage(m));
        <span class="hljs-keyword">await</span> client.SendBatchAsync(brokeredMessages);
    }
}

<span class="hljs-keyword">private</span> <span class="hljs-keyword">const</span> <span class="hljs-keyword">long</span> MaxServiceBusMessage = <span class="hljs-number">256000</span>;
<span class="hljs-keyword">private</span> <span class="hljs-keyword">readonly</span> QueueClient client;
</code></pre>
<p>Note that I do <code>await</code> for each chunk sequentially to preserve message ordering.
Another thing to notice is that we lost all-or-nothing guarantee: we might
be able to send the first chunk, and then get an exception from subsequent
parts. Some sort of retry mechanism is probably needed.</p>
<h2 id="brokeredmessage-size">BrokeredMessage.Size</h2>
<p>OK, how do we determine the size of each message? How do we implement 
<code>getSize</code> function? </p>
<p><code>BrokeredMessage</code> class exposes <code>Size</code> property, so it might be tempting to
rewrite our method the following way:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">async</span> Task SendBigBatchAsync&lt;T&gt;(IEnumerable&lt;T&gt; messages)
{
    <span class="hljs-keyword">var</span> brokeredMessages = messages.Select(m =&gt; <span class="hljs-keyword">new</span> BrokeredMessage(m));
    <span class="hljs-keyword">var</span> chunks = brokeredMessages.ChunkBy(bm =&gt; bm.Size, MaxServiceBusMessage);
    <span class="hljs-keyword">foreach</span> (<span class="hljs-keyword">var</span> chunk <span class="hljs-keyword">in</span> chunks)
    {
        <span class="hljs-keyword">await</span> client.SendBatchAsync(chunk);
    }
}
</code></pre>
<p>Unfortunately, this won&#39;t work properly. A quote from documentation:</p>
<blockquote>
<p>The value of Size is only accurate after the BrokeredMessage 
instance is sent or received.</p>
</blockquote>
<p>My experiments show that <code>Size</code> of a draft message returns the size of 
the message body, ignoring headers. If the message bodies are large, and
each chunk has just a handful of them, the code might work ok-ish. </p>
<p>But it will significantly underestimate the size of large batches of messages
with small payload.</p>
<p>So, for the rest of this article I&#39;ll try to adjust the calculation for headers.</p>
<h2 id="fixed-header-size">Fixed Header Size</h2>
<p>It could be that the header size of each message is always the same.
Quite often people will set the same headers for all their messages,
or set no custom headers at all. </p>
<p>In this case, you might just measure this size once, and then put this
fixed value inside a configuration file.</p>
<p>Here is how you measure the headers of a <code>BrokeredMessage</code> message:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> sizeBefore = message.Size;
client.Send(message);
<span class="hljs-keyword">var</span> sizeAfter = message.Size;
<span class="hljs-keyword">var</span> headerSize = sizeAfter - sizeBefore;
</code></pre>
<p>Now you just need to adjust one line from the previous version of 
<code>SendBigBatchAsync</code> method</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> chunks = brokeredMessages.ChunkBy(bm =&gt; FixedHeaderSize + bm.Size, MaxServiceBusMessage);
</code></pre>
<p><code>FixedHeaderSize</code> might be simply hard-coded, or taken from configuration
per application.</p>
<h2 id="measuring-of-header-size-per-message">Measuring of Header Size per Message</h2>
<p>If the size of headers varies per message, you need a way to adjust batching
algorithm accordingly. </p>
<p>Unfortunately, I haven&#39;t found a straightforward way to accomplish that. It looks like
you&#39;d have to serialize the headers yourself, and then measure the size of
resulting binary. This is not a trivial operation to do correctly,
and also implies some performance penalty.</p>
<p>Sean Feldman <a href="https://weblogs.asp.net/sfeldman/asb-batching-brokered-messages">came up</a> 
with a way to <em>estimate</em> the size of headers. That might be a good way to go,
though the estimation tends to err on the safe side for messages with small
payload.</p>
<h2 id="heuristics-retry">Heuristics &amp; Retry</h2>
<p>The last possibility that I want to consider is actually allow yourself
violating the max size of the batch, but then handle the exception, retry
the send operation and adjust future calculations based on actual measured size
of the failed messages. The size is known after trying to <code>SendBatch</code>, even if
operation failed, so we can use this information.</p>
<p>Here is a sketch of how to do that in code:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-comment">// Sender is reused across requests</span>
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">BatchSender</span>
{
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">readonly</span> QueueClient queueClient;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> batchSizeLimit = <span class="hljs-number">262000</span>;
    <span class="hljs-keyword">private</span> <span class="hljs-keyword">long</span> headerSizeEstimate = <span class="hljs-number">54</span>; <span class="hljs-comment">// start with the smallest header possible</span>

    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">BatchSender</span>(<span class="hljs-params">QueueClient queueClient</span>)
    </span>{
        <span class="hljs-keyword">this</span>.queueClient = queueClient;
    }

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">async</span> Task SendBigBatchAsync&lt;T&gt;(IEnumerable&lt;T&gt; messages)
    {
        <span class="hljs-keyword">var</span> packets = (<span class="hljs-keyword">from</span> m <span class="hljs-keyword">in</span> messages
                     <span class="hljs-keyword">let</span> bm = <span class="hljs-keyword">new</span> BrokeredMessage(m)
                     <span class="hljs-keyword">select</span> <span class="hljs-keyword">new</span> { Source = m, Brokered = bm, BodySize = bm.Size }).ToList();
        <span class="hljs-keyword">var</span> chunks = packets.ChunkBy(p =&gt; <span class="hljs-keyword">this</span>.headerSizeEstimate + p.Brokered.Size, <span class="hljs-keyword">this</span>.batchSizeLimit);
        <span class="hljs-keyword">foreach</span> (<span class="hljs-keyword">var</span> chunk <span class="hljs-keyword">in</span> chunks)
        {
            <span class="hljs-keyword">try</span>
            {
                <span class="hljs-keyword">await</span> <span class="hljs-keyword">this</span>.queueClient.SendBatchAsync(chunk.Select(p =&gt; p.Brokered));
            }
            <span class="hljs-keyword">catch</span> (MessageSizeExceededException)
            {
                <span class="hljs-keyword">var</span> maxHeader = packets.Max(p =&gt; p.Brokered.Size - p.BodySize);
                <span class="hljs-keyword">if</span> (maxHeader &gt; <span class="hljs-keyword">this</span>.headerSizeEstimate)
                {
                    <span class="hljs-comment">// If failed messages had bigger headers, remember this header size </span>
                    <span class="hljs-comment">// as max observed and use it in future calculations</span>
                    <span class="hljs-keyword">this</span>.headerSizeEstimate = maxHeader;
                }
                <span class="hljs-keyword">else</span>
                {
                    <span class="hljs-comment">// Reduce max batch size to 95% of current value</span>
                    <span class="hljs-keyword">this</span>.batchSizeLimit = (<span class="hljs-keyword">long</span>)(<span class="hljs-keyword">this</span>.batchSizeLimit * <span class="hljs-number">.95</span>);
                }

                <span class="hljs-comment">// Re-send the failed chunk</span>
                <span class="hljs-keyword">await</span> <span class="hljs-keyword">this</span>.SendBigBatchAsync(packets.Select(p =&gt; p.Source));
            }

        }
    }
}
</code></pre>
<p>The code example is quite involved, here is what actually happens:</p>
<ol>
<li><p>Create a brokered message for each message object, but also save the
corresponding source message. This is critical to be able to re-send items:
there&#39;s no way to send the same <code>BrokeredMessage</code> instance twice.</p>
</li>
<li><p>Also save the body size of the brokered message. We&#39;ll use it for retry
calculation.</p>
</li>
<li><p>Start with some guess of header size estimate. I start with 54 bytes, 
which seems to be the minimal header size possible.</p>
</li>
<li><p>Split the batch into chunks the same way we did before.</p>
</li>
<li><p>Try sending chunks one by one.</p>
</li>
<li><p>If send operation fails with <code>MessageSizeExceededException</code>, iterate
through failed items and find out the actual header size of the message.</p>
</li>
<li><p>If that actual size is bigger than our known estimate, increase the estimate
to the newly observed value. Retry sending the chunk (not the whole batch) with
this new setting.</p>
</li>
<li><p>If the header is small, but message size is still too big - reduce the 
allowed total size of the chunk. Retry again.</p>
</li>
</ol>
<p>The combination of checks of steps 7 and 8 should make the mechanism reliable
and self-adopting to message header payloads.</p>
<p>Since we reuse the sender between send operations, the size parameters will
also converge quite quickly and no more retries will be needed. Thus the 
performance overhead should be minimal.</p>
<h2 id="conclusion">Conclusion</h2>
<p>It seems like there is no &quot;one size fits all&quot; solution for this problem at 
the moment. The best implementation might depend on your messaging 
requirements.</p>
<p>But if you have the silver bullet solution, please leave a comment under
this post and answer <a href="https://stackoverflow.com/questions/44779707/split-batch-of-messages-to-be-sent-to-azure-service-bus">my StackOverflow question</a>!</p>
<p>Otherwise, let&#39;s hope that the new 
<a href="https://github.com/azure/azure-service-bus-dotnet">.NET Standard-compatible Service Bus client</a>
will solve this issue for us. Track <a href="https://github.com/Azure/azure-service-bus-dotnet/issues/109">this github issue</a>
for status updates.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-service-bus/'>Azure Service Bus</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Jun 7th, 2017</div>
    
    <h1><a href='/2017/06/finding-lost-events-in-azure-application-insights/'>Finding Lost Events in Azure Application Insights</a></h1>
    
    <div class="post-content">
        <p>One of the ways we use Azure Application Insights is tracking custom
application-specific events. For instance, every time a data point from an
IoT device comes in, we log an AppInsights event. Then we are able to
aggregate the data and plot charts to derive trends and detect possible 
anomalies.</p>
<p>And recently we found such anomaly, which looked like this:</p>
<p><img src="/2017/06/finding-lost-events-in-azure-application-insights//dashboard-chart.png" alt="Amount of Events on Dashboard Chart"></p>
<p>This is a chart from our Azure dashboard, which shows the total amount of
events of specific type received per day. </p>
<p>The first two &quot;hills&quot; are two weeks, so we can clearly see that we get more
events on business days compared to weekends.</p>
<p>But then something happened on May 20: we started getting much less events,
and the hill pattern disappeared, days looks much more alike.</p>
<p>We haven&#39;t noticed any other problems in the system, but the trend looked
quite bothering. Are we loosing data?</p>
<p>I headed towards Analytics console of Application Insights to dig deeper.
Here is the query that reproduces the problem:</p>
<pre class="highlight"><code class="hljs coq">customEvents
| <span class="hljs-type">where</span> name == <span class="hljs-string">"EventXReceived"</span>
| <span class="hljs-type">where</span> timestamp &gt;= ago(<span class="hljs-number">22</span>d)
| <span class="hljs-type">project</span> PointCount = todouble(customMeasurements[<span class="hljs-string">"EventXReceived_Count"</span>]), timestamp
| <span class="hljs-type">summarize</span> EventXReceived = <span class="hljs-built_in">sum</span>(PointCount) <span class="hljs-built_in">by</span> bin(timestamp, <span class="hljs-number">1</span>d)
| <span class="hljs-type">render</span> timechart
</code></pre><p>and I got the same chart as before:</p>
<p><img src="/2017/06/finding-lost-events-in-azure-application-insights//analytics1.png" alt="Trend on Application Insights Analytics"></p>
<p>I checked the history of our source code repository and deployments and I
figured out that we upgraded the version of Application Insights SDK from 
version 2.1 to version 2.3.</p>
<p>My guess at this point was that Application Insights started sampling our
data instead of sending all events to the server. After reading 
<a href="https://docs.microsoft.com/en-us/azure/application-insights/app-insights-sampling">Sampling in Application Insights</a>
article, I came up with the following query to see the sampling rate:</p>
<pre class="highlight"><code class="hljs applescript">customEvents
| <span class="hljs-keyword">where</span> <span class="hljs-built_in">name</span> == <span class="hljs-string">"EventXReceived"</span>
| <span class="hljs-keyword">where</span> timestamp &gt;= ago(<span class="hljs-number">22</span>d)
| <span class="hljs-built_in">summarize</span> <span class="hljs-number">100</span>/avg(itemCount) <span class="hljs-keyword">by</span> bin(timestamp, <span class="hljs-number">1</span>d) 
| render areachart
</code></pre><p>and the result is self-explanatory:</p>
<p><img src="/2017/06/finding-lost-events-in-azure-application-insights//sampling-rate.png" alt="Sampling Rate"></p>
<p>Clearly, the sampling rate dropped from 100% down to about 30% right when
the anomaly started. The sampling-adjusted query (note <code>itemCount</code> multiplication)</p>
<pre class="highlight"><code class="hljs coq">customEvents
| <span class="hljs-type">where</span> name == <span class="hljs-string">"EventXReceived"</span>
| <span class="hljs-type">where</span> timestamp &gt;= ago(<span class="hljs-number">22</span>d)
| <span class="hljs-type">project</span> PointCount = todouble(customMeasurements[<span class="hljs-string">"EventXReceived_Count"</span>]) * itemCount, timestamp
| <span class="hljs-type">summarize</span> EventXReceived = <span class="hljs-built_in">sum</span>(PointCount) <span class="hljs-built_in">by</span> bin(timestamp, <span class="hljs-number">1</span>d)
| <span class="hljs-type">render</span> timechart
</code></pre><p>puts us back to the point when results make sense:</p>
<p><img src="/2017/06/finding-lost-events-in-azure-application-insights//analytics2.png" alt="Adjusted Trend on Application Insights Analytics"></p>
<p>The third week&#39;s Thursday was bank holiday in several European countries, so 
we got a drop there.</p>
<p>Should Azure dashboard items take sampling into account - to avoid
confusing people and to show more useful charts?</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/application-insights/'>Application Insights</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Jun 6th, 2017</div>
    
    <h1><a href='/2017/06/mikhail-io-upgraded-to-https-and-http2/'>Mikhail.io Upgraded to HTTPS and HTTP/2</a></h1>
    
    <div class="post-content">
        <p>Starting today, this blog has switched to HTTPS secure protocol:</p>
<p><img src="/2017/06/mikhail-io-upgraded-to-https-and-http2//mikhailio-https.png" alt="HTTPS"></p>
<p>While there&#39;s not that much to secure on my blog, HTTPS is still considered
to be a good practice for any site in 2017. One of the benefits that we can
get from it is the usage of HTTP/2 protocol:</p>
<p><img src="/2017/06/mikhail-io-upgraded-to-https-and-http2//mikhailio-http2.png" alt="HTTP/2"></p>
<p>This should be beneficial to any reader which uses a modern browser!</p>
<p>Thanks to <a href="https://cloudflare.com">CloudFlare</a> for providing me with free
HTTPS and HTTP/2 support.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/https/'>HTTPS</a>, <a href='/tags/http/2/'>HTTP/2</a>, <a href='/tags/cloudflare/'>CloudFlare</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">May 29th, 2017</div>
    
    <h1><a href='/2017/05/reliable-consumer-of-azure-event-hubs/'>Reliable Consumer of Azure Event Hubs</a></h1>
    
    <div class="post-content">
        <p><a href="https://azure.microsoft.com/en-us/services/event-hubs/">Azure Event Hubs</a> is
a log-based messaging system-as-a-service in Azure cloud. It&#39;s designed to be able to handle huge
amount of data, and naturally supports multiple consumers.</p>
<h2 id="event-hubs-and-service-bus">Event Hubs and Service Bus</h2>
<p>While Event Hubs are formally part of Azure Service Bus family of products,
in fact its model is quite different.</p>
<p>&quot;Traditional&quot; Service Bus service is organized around queues (subscriptions
are just queues with the topic being the source of messages). Each consumer 
can peek messages from the queue, do the required processing and then
complete the message to remove it from the queue, or abort the processing.
Abortion will leave the message at the queue, or will move it to the Dead Letter
Queue. Completion/abortion are granular per message; and the status of each
message is managed by the Service Bus broker.</p>
<p><img src="/2017/05/reliable-consumer-of-azure-event-hubs//service-bus-processors.png" alt="Service Bus Processors"></p>
<p>Event Hubs service is different. Each Hub represnts a log of messages.
Event producer appends data to the end of the log, and consumers can read this log,
but they can&#39;t remove or change the status of events there.</p>
<p>Each event has an offset associated with it. And the only operation that is
supported for consumers is &quot;give me some messages starting at the offset X&quot;.</p>
<p><img src="/2017/05/reliable-consumer-of-azure-event-hubs//event-hub-processors.png" alt="Event Hub Processors"></p>
<p>While this approach might seem simplistic, it actually  makes consumers 
more powerful:</p>
<ul>
<li><p>The messages do not disappear from the Hub after being processed for the
first time. So, if needed, the consumer can go back and re-process older
events again;</p>
</li>
<li><p>Multiple consumers are always supported, out of the box. They just read
the same log, after all;</p>
</li>
<li><p>Each consumer can go at its own pace, drop and resume processing whenever
needed, with no effect on other consumers.</p>
</li>
</ul>
<p>There are some disadvantages too:</p>
<ul>
<li><p>Consumers have to manage their own state of the processing progress, i.e.
they have to save the offset of the last processed event;</p>
</li>
<li><p>There is no way to mark any specific event as failed to be able to reprocess
it later. There&#39;s no notion of Dead Letter Queue either.</p>
</li>
</ul>
<h2 id="event-processor-host">Event Processor Host</h2>
<p>To overcome the first complication, Microsoft provides the consumer API called
<a href="https://github.com/Microsoft/azure-docs/blob/master/articles/event-hubs/event-hubs-programming-guide.md">EventProcessorHost</a>.
This API has an implementation of consumers based on checkpointing. All you
need to do is to provide a callback to process a batch of events, and then call
<code>CheckpointAsync</code> method, which saves the current offset of the last message
into Azure Blob Storage. If the consumer restarts at any point in time, it will
read the last checkpoint to find the current offset, and will then continue
processing from that point on.</p>
<p>It works great for some scenarios, but the event delivery/processing guarantees
are relatively low in this case:</p>
<ul>
<li><p>Any failures are ignored: there&#39;s no retry or Dead Letter Queue</p>
</li>
<li><p>There are no transactions between event hub checkpoints and the data sinks
that the processor works with (i.e. data stores where processed messages 
end up at)</p>
</li>
</ul>
<p>In this post I want to focus on a way to process events with higher consistency
requirements, in particular:</p>
<ul>
<li><p>Event Hub processor modifies data in a SQL Database, and such 
processing is transactional per batch of messages</p>
</li>
<li><p>Each event should be (successfully) processed exactly once</p>
</li>
<li><p>If event processing failed, it should be marked as failed and kept 
available to be reprocessed at later point in time</p>
</li>
</ul>
<p>While end-to-end exactly-once processing would require changes of the 
producers too, we will only focus on consumer side in this post.</p>
<h2 id="transactional-checkpoints-in-sql">Transactional Checkpoints in SQL</h2>
<p>If checkpoint information is stored in Azure Blobs, there is no obvious way to
implement distributed transactions between SQL Database and Azure Storage.</p>
<p>However, we can override the default checkpointing mechanism and 
implement our own checkpoints based on a SQL table. This way each 
checkpoint update can become part of a SQL transaction and be committed
or rolled back with normal guarantees provided by SQL Server.</p>
<p>Here is a table that I created to hold my checkpoints:</p>
<pre class="highlight"><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> EventHubCheckpoint (
  Topic <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  PartitionID <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  SequenceNumber <span class="hljs-built_in">bigint</span> <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  <span class="hljs-keyword">Offset</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  <span class="hljs-keyword">CONSTRAINT</span> PK_EventHubCheckpoint PRIMARY <span class="hljs-keyword">KEY</span> CLUSTERED (Topic, PartitionID)
)
</code></pre>
<p>For each topic and partition of Event Hubs, we store two values: sequence
number and offset, which together uniquely identify the consumer position.</p>
<p>Conveniently, Event Host Processor provides an extensibility point to
override the default checkpoint manager with a custom one. For that we
need to implement <code>ICheckpointManager</code> interface to work with our SQL
table.</p>
<p>The implementation mainly consists of 3 methods: <code>CreateCheckpointIfNotExistsAsync</code>,
<code>GetCheckpointAsync</code> and <code>UpdateCheckpointAsync</code>. The names are pretty
much self-explanatory, and my Dapper-based implementation is quite trivial.
You can find the code <a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/eventhubs-sqlcheckpoints/SQLCheckpointManager.cs">here</a>.</p>
<p>For now, I&#39;m ignoring the related topic of lease management and corresponding
interface <code>ILeaseManager</code>. It&#39;s quite a subject on its own; for the sake
of simplicity I&#39;ll assume we have just one consumer process per partition,
which makes proper lease manager redundand.</p>
<h2 id="dead-letter-queue">Dead Letter Queue</h2>
<p>Now, we want to be able to mark some messages as failed and to 
re-process them later. To make Dead Letters transactional, we need another
SQL table to hold the failed events:</p>
<pre class="highlight"><code class="hljs sql"><span class="hljs-keyword">CREATE</span> <span class="hljs-keyword">TABLE</span> EventHubDeadLetter (
  Topic <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  PartitionID <span class="hljs-built_in">varchar</span>(<span class="hljs-number">100</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  SequenceNumber <span class="hljs-built_in">bigint</span> <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  <span class="hljs-keyword">Offset</span> <span class="hljs-built_in">varchar</span>(<span class="hljs-number">20</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  FailedAt datetime <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  <span class="hljs-keyword">Error</span> <span class="hljs-keyword">nvarchar</span>(<span class="hljs-keyword">max</span>) <span class="hljs-keyword">NOT</span> <span class="hljs-literal">NULL</span>,
  <span class="hljs-keyword">CONSTRAINT</span> PK_EventHubDeadLetter PRIMARY <span class="hljs-keyword">KEY</span> CLUSTERED (Topic, PartitionID)
)
</code></pre>
<p>This table looks very similar to <code>EventHubCheckpoint</code> that I
defined above. That is because they are effectively storing pointers to
events in a hub. Dead Letters have two additional columns to store error
timestamp and text.</p>
<p>There is no need to store the message content, because failed events still
sit in the event hub anyway. You could still log it for diagnostics purpose - just make an extra
<code>varbinary</code> column.</p>
<p>There&#39;s no notion of dead letters in Event Hubs SDK, so I defined my own
interface <code>IDeadLetterManager</code> with a single <code>AddFailedEvents</code> method:</p>
<pre class="highlight"><code class="hljs undefined">public interface IDeadLetterManager
{
    Task AddFailedEvents(IEnumerable&lt;DeadLetter&lt;EventData&gt;&gt; deadLetters);
}

public class DeadLetter&lt;T&gt;
{
    public T Data { get; set; }
    public DateTime FailureTime { get; set; }
    public Exception Exception { get; set; }
}
</code></pre>
<p>Dapper-based implementation is trivial again, you can find the code 
<a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/eventhubs-sqlcheckpoints/SQLDeadLetterManager.cs">here</a>.</p>
<h2 id="putting-it-together-event-host">Putting It Together: Event Host</h2>
<p>My final solution is still using <code>EventHostProcessor</code>. I pass <code>SQLCheckpointManager</code> 
into its constructor, and then I implement <code>IEventProcessor</code>&#39;s 
<code>ProcessEventsAsync</code> method in the following way:</p>
<ol>
<li>Instantiate a list of items to store failed events</li>
<li>Start a SQL transaction</li>
<li>Loop through all the received events in the batch</li>
<li>Process each item inside a try-catch block</li>
<li>If exception happens, add the current event to the list of failed events</li>
<li>After all items are processed, save failed events to Dead Letter table</li>
<li>Update the checkpoint pointer</li>
<li>Commit the transaction</li>
</ol>
<p>The code block that illustrates this workflow:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">async</span> Task <span class="hljs-title">ProcessEventsAsync</span>(<span class="hljs-params">
    PartitionContext context, 
    IEnumerable&lt;EventData&gt; eventDatas</span>)
</span>{
    <span class="hljs-comment">// 1. Instantiate a list of items to store failed events</span>
    <span class="hljs-keyword">var</span> failedItems = <span class="hljs-keyword">new</span> List&lt;DeadLetter&lt;EventData&gt;&gt;();

    <span class="hljs-comment">// 2. Start a SQL transaction</span>
    <span class="hljs-keyword">using</span> (<span class="hljs-keyword">var</span> scope = <span class="hljs-keyword">new</span> TransactionScope())
    {
        <span class="hljs-comment">// 3. Loop through all the received events in the batch</span>
        <span class="hljs-keyword">foreach</span> (<span class="hljs-keyword">var</span> eventData <span class="hljs-keyword">in</span> eventDatas)
        {
            <span class="hljs-keyword">try</span>
            {
                <span class="hljs-comment">// 4. Process each item inside a try-catch block</span>
                <span class="hljs-keyword">var</span> item = <span class="hljs-keyword">this</span>.Deserialize(eventData);
                <span class="hljs-keyword">await</span> <span class="hljs-keyword">this</span>.DoWork(item);
            }
            <span class="hljs-keyword">catch</span> (Exception ex)
            {
                <span class="hljs-comment">// 5. Add a failed event to the list</span>
                failedItems.Add(<span class="hljs-keyword">new</span> DeadLetter&lt;EventData&gt;(eventData, DateTime.UtcNow, ex));
            }
        }

        <span class="hljs-keyword">if</span> (failedItems.Any())
        {
            <span class="hljs-comment">// 6. Save failed items to Dead Letter table</span>
            <span class="hljs-keyword">await</span> <span class="hljs-keyword">this</span>.dlq.AddFailedEvents(failedItems);
        }

        <span class="hljs-comment">// 7. Update the checkpoint pointer</span>
        <span class="hljs-keyword">await</span> context.CheckpointAsync();

        <span class="hljs-comment">// 8. Commit the transaction</span>
        scope.Complete();
    }
}
</code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>My implementation of Event Hubs consumer consists of 3 parts: checkpoint 
manager that saves processing progress per partition into a SQL table;
dead letter manager that persists information about processing errors;
and an event host which uses both to provide transactional processing
of events.</p>
<p>The transaction scope is limited to SQL Server databases, but it might be
sufficient for many real world scenarios.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-event-hubs/'>Azure Event Hubs</a>, <a href='/tags/azure-service-bus/'>Azure Service Bus</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">May 8th, 2017</div>
    
    <h1><a href='/2017/05/why-fsharp-and-functional-programming-will-make-you-a-better-developer-talk/'>Why F# and Functional Programming Talk at .NET Development Nederland Meetup</a></h1>
    
    <div class="post-content">
        <p>On May 8th 2017 I gave a talk at the
<a href="https://www.meetup.com/dotNET-Development-Nederland/">.NET Development Nederland</a>
group in Amsterdam.</p>
<p>Here are the slides for the people who were there and want to revisit
the covered topics.</p>
<h2 id="why-learn-f-and-functional-programming">Why Learn F# and Functional Programming</h2>
<p>Link to full-screen HTML slides: 
<a href="https://mikhail.io/talks/why-fsharp/">Why Learn F# and Functional Programming</a></p>
<p>Slides on SlideShare:</p>
<iframe src="//www.slideshare.net/slideshow/embed_code/key/iG9omDKb42ogTk" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> 
</iframe>

<p>Useful links:</p>
<p><a href="http://fsharpforfunandprofit.com">F# for Fun and Profit</a></p>
<p><a href="http://fsharp.org">F# Foundation</a></p>
<p><a href="https://www.manning.com/books/real-world-functional-programming">Real-World Functional Programming, With examples in F# and C# Book</a></p>
<p>Thanks for attending my talk! Feel free to post any feedback in the comments.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/talk/'>Talk</a>, <a href='/tags/meetup/'>Meetup</a>, <a href='/tags/functional-programming/'>Functional Programming</a>, <a href='/tags/f#/'>F#</a>, <a href='/tags/slides/'>Slides</a>
    </div>
    
</article>


<div class="page-nav">
    
    <a class="page-nav-newer" href="/3/">&lt;&lt; Previous page</a>
    
    
    <a class="page-nav-older" href="/5/">Next page &gt;&gt;</span></a>
    
</div>

<div id="me">
    <p itemscope itemtype="http://data-vocabulary.org/Person">
        <img src="/images/Headshot-Square.jpg" alt="Mikhail Shilkov" itemprop="photo" />
        I'm <b><span itemprop="name">Mikhail Shilkov</span></b>, a <span itemprop="title">software developer</span>. I enjoy F#, C#, Javascript and SQL development, reasoning about distributed systems, data processing pipelines, cloud and web apps. I blog about my experience on this website.
    </p>
    <p>
        <a href="https://www.linkedin.com/in/mikhailshilkov/">LinkedIn</a> &#8226;
        <a href="https://twitter.com/mikhailshilkov">@mikhailshilkov</a> &#8226;
        <a href="https://github.com/mikhailshilkov">GitHub</a> &#8226;
        <a href="https://stackoverflow.com/users/1171619/mikhail">Stack Overflow</a>
    </p>
</div>

</div>
<div class="container">
    <div class="navbar navbar-footer">
        <p class="navbar-center navbar-text">Content copyright &copy; 2018 Mikhail Shilkov</p>
    </div>
</div>



<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.pack.js"></script>
<script src="/vendor/highlight.pack.js"></script>
<script src="/site.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59218480-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>