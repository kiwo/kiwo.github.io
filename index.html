<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>

    <meta name="description" content="Software development using .NET, C#, SQL, Javascript and related technologies" />

    <title>Mikhail Shilkov</title>
    <meta name="author" content="Mikhail Shilkov">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/feed/" rel="alternate" title="mikhail.io" type="application/atom+xml">
    <link href="/favicon.ico?v=2" rel="shortcut icon">

    <!-- Bootstrap -->
    <link href="/styles/site.css" rel="stylesheet" media="screen">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/scripts/vendor/html5shiv.js"></script>
    <script src="/scripts/vendor/respond.min.js"></script>
    <![endif]-->

    <meta name="generator" content="DocPad v6.78.6" />
    
</head>
<body>

<div class="navbar navbar-default navbar-static-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">
                <span class="text-primary">Mikhail Shilkov</span><br />
                <span class="elevator-pitch">F#, C#, JS, SQL, Azure programmer</span>
            </a>
        </div>
        <div class="collapse navbar-collapse navbar-right">
            <ul class="nav navbar-nav">
                <!--<li><a href="/">Blog</a></li>-->
                
                    <li><a href="/tags/">Topics</a></li>
                
                    <li><a href="/archives/">Archives</a></li>
                
                    <li><a href="/talks/">Talks</a></li>
                
                    <li><a href="/about/">About</a></li>
                
                <li class="hidden-xs">
                    <a href="/feed/" class="rss"><span class="icon icon-feed"></span></a>
                    <a href="https://www.linkedin.com/in/mikhailshilkov" class="linkedin"><span class="icon icon-linkedin"></span></a>
                    <a href="https://twitter.com/mikhailshilkov" class="twitter"><span class="icon icon-twitter"></span></a>
                    <a href="https://github.com/mikhailshilkov" class="github"><span class="icon icon-github"></span></a>
                </li>
            </ul>
            <form class="navbar-form navbar-right hidden-xs" role="search" action="https://google.com/search"
                  method="get">
                <div class="form-group">
                    <input type="search" name="q" class="form-control" placeholder="Search">
                    <input type="hidden" name="q" value="site:mikhail.io">
                </div>
            </form>
        </div>
    </div>
</div>
<div class="container">
    
    <article class="post">
    <div class="post-date">May 18th, 2018</div>
    
    <h1><a href='/2018/05/azure-functions-cold-starts-beyond-first-load/'>Azure Functions: Cold Starts Beyond First Request</a></h1>
    
    <div class="post-content">
        <p>In my <a href="https://mikhail.io/2018/04/azure-functions-cold-starts-in-numbers/">previous article</a>
I&#39;ve explored the topic of Cold Starts in Azure Functions. Particularly, I&#39;ve measured the
cold start delays per language and runtime version.</p>
<p>I received some follow-up questions that I&#39;d like to explore in today&#39;s post:</p>
<ul>
<li>Can we avoid cold starts except the very first one by keeping the instance warm?</li>
<li>Given one warm instance, if two requests come at the same time, will one request hit 
a cold start because existing instance is busy with the other?</li>
<li>In general, does a cold start happen at scale-out when a new extra instance is provisioned?</li>
</ul>
<p>Again, we are only talking Consumption Plan here.</p>
<h2 id="theory">Theory</h2>
<p>Azure Functions are running on instances provided by Azure App Service. Each instance is
able to process several requests concurrently, which is different comparing to AWS Lambda.</p>
<p>Thus, the following <em>could</em> be true:</p>
<ul>
<li>If we issue at least 1 request every 20 minutes, the first instance should stay warm for
long time</li>
<li>Simultaneous requests don&#39;t cause cold start unless the existing instance gets too busy</li>
<li>When runtime decides to scale out and spin up a new instance, it could do so in the background,
still forwarding incoming requests to the existing warm instance(s). Once the new instance
is ready, it could be added to the pool without causing cold starts</li>
<li>If so, cold starts are mitigated beyond the very first execution</li>
</ul>
<p>Let&#39;s put this theory under test!</p>
<h2 id="keeping-always-warm">Keeping Always Warm</h2>
<p>I&#39;ve tested a Function App which consists of two Functions:</p>
<ul>
<li>HTTP Function under test</li>
<li>Timer Function which runs every 10 minutes and does nothing but logging 1 line of text</li>
</ul>
<p>I then measured the cold start statistics similar to all the tests from my previous article.</p>
<p>During 2 days I was issuing infrequent requests to the same app, most of them would normally
lead to a cold start. Interestingly, even though I was regularly firing the timer, Azure 
switched instances to serve my application 2 times during the test period:</p>
<p><img src="/2018/05/azure-functions-cold-starts-beyond-first-load//cold-starts-keep-warm.png" alt="Infrequent Requests to Azure Functions with &quot;Keep It Warm&quot; Timer"></p>
<p>I can see that most responses are fast, so timer &quot;warmer&quot; definitely helps.</p>
<p>The first request(s) to a new instance are slower than subsequent ones. Still, they are faster
than normal full cold start time, so it could be related to HTTP stack loading.</p>
<p>Anyway, keeping Functions warm seems a viable strategy.</p>
<h2 id="parallel-requests">Parallel Requests</h2>
<p>What happens when there is a warm instance, but it&#39;s already busy with processing another
request? Will the parallel request be delayed, or will it be processed by the same
warm instance?</p>
<p>I tested with a very lightweight function, which nevertheless takes some time to complete:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;HttpResponseMessage&gt; <span class="hljs-title">Delay500</span>(<span class="hljs-params">[HttpTrigger] HttpRequestMessage req</span>)
</span>{
    <span class="hljs-keyword">await</span> Task.Delay(<span class="hljs-number">500</span>);
    <span class="hljs-keyword">return</span> req.CreateResponse(HttpStatusCode.OK, <span class="hljs-string">"Done"</span>);
}
</code></pre>
<p>I believe it&#39;s an OK approximation for an IO-bound function.</p>
<p>The test client then issued 2 to 10 parallel requests to this function and measured the
response time for all requests.</p>
<p>It&#39;s not the easiest chart to understand in full, but note the following:</p>
<ul>
<li><p>Each group of bars are for requests sent at the same time. Then there goes a pause about
20 seconds before the next group of requests gets sent</p>
</li>
<li><p>The bars are colored by the instance which processed that request: same instance - same
color</p>
</li>
</ul>
<p><img src="/2018/05/azure-functions-cold-starts-beyond-first-load//cold-starts-during-simultaneous-requests.png" alt="Azure Functions Response Time to Batches of Simultaneous Requests"></p>
<p>Here are some observations from this experiment:</p>
<ul>
<li><p>Out of 64 requests, there were 11 cold starts</p>
</li>
<li><p>Same instance <em>can</em> process multiple simultaneous requests, e.g. one instance processed
7 out of 10 requests in the last batch</p>
</li>
<li><p>Nonetheless, Azure is eager to spin up new instances for multiple requests. In total
12 instances were created, which is even more than max amount of requests in any single
batch</p>
</li>
<li><p>Some of those instances were actually never reused (gray-ish bars in batched x2 and x3,
brown bar in x10)</p>
</li>
<li><p>The first request to each new instance pays the full cold start price. Runtime doesn&#39;t
provision them in background while reusing existing instances for received requests</p>
</li>
<li><p>If an instance handled more than one request at a time, response time invariably suffers,
even though the function is super lightweight (<code>Task.Delay</code>)</p>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Getting back to the experiment goals, there are several things that we learned.</p>
<p>For low-traffic apps with sporadic requests it makes sense to setup a &quot;warmer&quot; timer
function firing every 10 minutes or so to prevent the only instance from being recycled.</p>
<p>However, scale-out cold starts are real and I don&#39;t see any way to prevent them from
happening.</p>
<p>When multiple requests come in at the same time, we might expect some of them to hit
a new instance and get slowed down. The exact algorithm of instance reuse is not
entirely clear.</p>
<p>Same instance is capable of processing multiple requests in parallel, so there are
possibilities for optimization in terms of routing to warm instances during the
provisioning of cold ones. </p>
<p>If such optimizations happen, I&#39;ll be glad to re-run my tests and report any noticeable
improvements.</p>
<p>Stay tuned for more serverless perf goodness!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/serverless/'>Serverless</a>, <a href='/tags/performance/'>Performance</a>, <a href='/tags/cold-start/'>Cold Start</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Apr 24th, 2018</div>
    
    <h1><a href='/2018/04/azure-functions-cold-starts-in-numbers/'>Azure Functions: Cold Starts in Numbers</a></h1>
    
    <div class="post-content">
        <p>Auto-provisioning and auto-scalability are the killer features of Function-as-a-Service
cloud offerings, and Azure Functions in particular.</p>
<p>One drawback of such dynamic provisioning is a phenomenon called &quot;Cold Start&quot;. Basically,
applications that haven&#39;t been used for a while take longer to startup and to handle the
first request.</p>
<p>The problem is nicely described in 
<a href="https://blogs.msdn.microsoft.com/appserviceteam/2018/02/07/understanding-serverless-cold-start/">Understanding Serverless Cold Start</a>,
so I won&#39;t repeat it here. I&#39;ll just copy a picture from that article:</p>
<p><img src="/2018/04/azure-functions-cold-starts-in-numbers//coldstart.jpg" alt="Cold Start"></p>
<p>Based on the 4 actions which happen during a cold start, we may guess that the following factors
might affect the cold start duration:</p>
<ul>
<li>Language / execution runtime</li>
<li>Azure Functions runtime version</li>
<li>Application size including dependencies</li>
</ul>
<p>I ran several sample functions and tried to analyze the impact of these factors on cold start time.</p>
<h2 id="methodology">Methodology</h2>
<p>All tests were run against HTTP Functions, because that&#39;s where cold start matters the most.</p>
<p>All the functions were just returning &quot;Hello, World&quot; taking the &quot;World&quot; value from the query string.
Some functions were also loading extra dependencies, see below.</p>
<p>I did not rely on execution time reported by Azure. Instead, I measured end-to-end duration from
client perspective. All calls were made from within the same Azure region, so network latency should 
have minimal impact:</p>
<p><img src="/2018/04/azure-functions-cold-starts-in-numbers//test-setup.png" alt="Test Setup"></p>
<h2 id="when-does-cold-start-happen-">When Does Cold Start Happen?</h2>
<p>Obviously, cold start happens when the very first request comes in. After that request is processed,
the instance is kept alive in case subsequent requests arrive. But for how long?</p>
<p>The following chart gives the answer. It shows values of normalized request durations across
different languages and runtime versions (Y axis) depending on the time since the previous
request in minutes (X axis):</p>
<p><img src="/2018/04/azure-functions-cold-starts-in-numbers//coldstart-threshold.png" alt="Cold Start Threshold"></p>
<p>Clearly, an idle instance lives for 20 minutes and then gets recycled. All requests after 20 minutes
threshold hit another cold start.</p>
<h2 id="how-do-languages-compare-">How Do Languages Compare?</h2>
<p>I&#39;ll start with version 1 of Functions runtime, which is the production-ready GA version as of today.</p>
<p>I&#39;ve written Hello World HTTP function in all GA languages: C#, F# and Javascript, and I added Python
for comparison. C#/F# were executed both in the form of script, and as a precompiled .NET assembly.</p>
<p>The following chart shows some intuition about the cold start duration per language. The languages
are ordered based on mean response time, from lowest to highest. 65% of request
durations are inside the vertical bar (1-sigma interval) and 95% are inside the vertical line (2-sigma):</p>
<p><img src="/2018/04/azure-functions-cold-starts-in-numbers//coldstarts-v1.png" alt="Cold Start V1 per Language"></p>
<p>Somewhat surprisingly, precompiled .NET is exactly on par with Javascript. Javascript &quot;Hello World&quot; 
is really lightweight, so I expected it to win, but I was wrong.</p>
<p>C# Script is slower but somewhat comparable. F# Script presented a really negative surprise though: it&#39;s much
slower. It&#39;s even slower than experimental Python support where no performance optimization would
be expected at all!</p>
<h2 id="functions-runtime-v1-vs-v2">Functions Runtime: V1 vs V2</h2>
<p>Version 2 of Functions runtime is currently in preview and not suitable for production load. That
probably means they haven&#39;t done too much performance optimization, especially from cold start
standpoint.</p>
<p>Can we see this on the chart? We sure can:</p>
<p><img src="/2018/04/azure-functions-cold-starts-in-numbers//coldstarts-v2.png" alt="Cold Start V1 vs V2"></p>
<p>V2 is massively slower. The fastest cold starts are around 6 seconds, but the slowest can come
up to 40-50 seconds.</p>
<p>Javascript is again on-par with precompiled .NET. </p>
<p>Java is noticeably slower, even though the
deployment package is just 33kB, so I assume I didn&#39;t overblow it.</p>
<h2 id="does-size-matter-">Does Size Matter?</h2>
<p>OK, enough of Hello World. A real-life function might be more heavy, mainly because it would
depend on other third-party libraries.</p>
<p>To simulate such scenario, I&#39;ve measured cold starts for a .NET function with references to 
Entity Framework, Automapper, Polly and Serilog.</p>
<p>For Javascript I did the same, but referenced Bluebird, lodash and AWS SDK.</p>
<p>Here are the results:</p>
<p><img src="/2018/04/azure-functions-cold-starts-in-numbers//coldstarts-dependencies.png" alt="Cold Start Dependencies"></p>
<p>As expected, the dependencies slow the loading down. You should keep your Functions lean,
otherwise you will pay in seconds for every cold start.</p>
<p>An important note for Javascript developers: the above numbers are for Functions deployed
after <a href="https://github.com/Azure/azure-functions-pack"><code>Funcpack</code></a> preprocessor. The package
contained the single <code>js</code> file with Webpack-ed dependency tree. Without that, the mean
cold start time of the same function is 20 seconds!</p>
<h2 id="conclusions">Conclusions</h2>
<p>Here are some lessons learned from all the experiments above:</p>
<ul>
<li>Be prepared for 1-3 seconds cold starts even for the smallest Functions</li>
<li>Stay on V1 of runtime until V2 goes GA unless you don&#39;t care about perf</li>
<li>.NET precompiled and Javascript Functions have roughly same cold start time</li>
<li>Minimize the amount of dependencies, only bring what&#39;s needed</li>
</ul>
<p>Do you see anything weird or unexpected in my results? Do you need me to dig deeper on other aspects?
Please leave a comment below or ping me on twitter, and let&#39;s sort it all out.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/serverless/'>Serverless</a>, <a href='/tags/performance/'>Performance</a>, <a href='/tags/cold-start/'>Cold Start</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Apr 7th, 2018</div>
    
    <h1><a href='/2018/04/fsharp-exchange-2018/'>Awesome F# Exchange 2018</a></h1>
    
    <div class="post-content">
        <p>I&#39;m writing this post in the train to London Stensted, on my way back from F# Exchange 2018
conference.</p>
<p>F# Exchange is a yearly conference taking place in London, and 2018 edition was the first one
for me personally. I also had an honour to speak there about creating Azure Functions with
F#.</p>
<h2 id="impression">Impression</h2>
<p>F# is still relatively niche language, so the conference is not overcrowded, but that gives
it a special feeling of family gathering. There were 162 participants this year, and I have an
impression that every one of them is extremely friendly, enthusiastic and just plain awesome.</p>
<p>The conference itself had 2 tracks of 45-minute talks and 60-minute keynotes. Most talks were
of high quality, and the topics ranging from compiler internals to fun applications like 
music generation, car racing and map drawing.</p>
<p>Both Don Syme, the creator of F#, and Philip Carter, F# program manager, were there and gave
keynotes, but they were careful enough not to draw too much attention on Microsoft and let
the community speak loud.</p>
<h2 id="corridor-track">Corridor Track</h2>
<p>But the talks were just a part of the story. For me, the conference started in the evening
before the first day at the speakers drinks party, and only finished at 1 a.m. after the 
second day (the pubs in London are lovely).</p>
<p>I spoke to so many great people, I learnt a lot, and had fun too. I&#39;ve never seen so many
F# folks at the same place, and I guess there must be something about F# which attracts
the right kind of people to it.</p>
<p>And of course it&#39;s so much fun to meet face-to-face all those twitter, slack, github and 
Channel 9 persona&#39;s and to see that they are actually real people :)</p>
<h2 id="my-talk">My Talk</h2>
<p>The talk I gave was called &quot;Azure F#unctions&quot;. It was not a hard-core F# talk, but people
seemed to be genuinely interested in the topic.</p>
<p>A decent amount of attendees are already familiar with Azure Functions, and many either run 
them in production or plan to do so.</p>
<p>The reference version conflict problem is very well known and raises a lots of questions
or concerns. This even leads to workarounds like transpiling F# Functions to Javascript
with Fable. Yikes.</p>
<p>Durable Functions seem to be sparkling a lot of initial interest. I&#39;ll be definitely
spending more time to play with them, and maybe to make F# story more smooth.</p>
<p>Functions were mentioned in Philip&#39;s keynote as one of the important areas for F# 
application, which is cool. We should spend some extra effort to make the documentation
and onboarding story as smooth as possible.</p>
<h2 id="call-to-action">Call to Action</h2>
<p>Skills Matter is the company behind the conference. Carla, Nicole and others did a great
job preparing the event; everything went smooth, informal and fun.</p>
<p>The videos are already online at <a href="https://skillsmatter.com/conferences/9419-f-sharp-exchange-2018#skillscasts">Skillscasts</a> 
(requires free signup).</p>
<p><a href="https://skillsmatter.com/conferences/10869-f-sharp-exchange-2019">F# Exchange 2019</a> 
super early bird tickets are for sale now and until Monday April 9, go 
get one and join F# Exchange in London next year! </p>
<p>I&#39;m already missing you all.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/f#/'>F#</a>, <a href='/tags/f#-exchange/'>F# Exchange</a>, <a href='/tags/talk/'>Talk</a>, <a href='/tags/azure-functions/'>Azure Functions</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Feb 19th, 2018</div>
    
    <h1><a href='/2018/02/azure-durable-functions-in-fsharp/'>Azure Durable Functions in F#</a></h1>
    
    <div class="post-content">
        <p>Azure Functions are designed for stateless, fast-to-execute,
simple actions. Typically, they are triggered by an HTTP call or a queue message,
then they read something from the storage or database and return the result
to the caller or send it to another queue. All within several seconds at most.</p>
<p>However, there exists a preview of <a href="https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-overview">Durable Functions</a>,
an extension that lets you write stateful functions for long-running workflows.
Here is a picture of one possible workflow from the docs:</p>
<p><img src="/2018/02/azure-durable-functions-in-fsharp//fan-out-fan-in.png" alt="Fan-out Fan-in Workflow"></p>
<p>Such workflows might take arbitrary time to complete. Instead of blocking and
waiting for all that period, Durable Functions use the combination of
Storage Queues and Tables to do all the work asynchronously.</p>
<p>The code still <em>feels</em> like one continuous thing because it&#39;s programmed
as a single orchestrator function. So, it&#39;s easier for a human to reason 
about the functionality without the complexities of low-level communication.</p>
<p>I won&#39;t describe Durable Functions any further, just go read
<a href="https://docs.microsoft.com/en-us/azure/azure-functions/durable-functions-overview">documentation</a>,
it&#39;s nice and clean.</p>
<h2 id="language-support">Language Support</h2>
<p>As of February 2018, Durable Functions are still in preview. That also means
that language support is limited:</p>
<blockquote>
<p>Currently C# is the only supported language for Durable Functions. This 
includes orchestrator functions and activity functions. In the future, 
we will add support for all languages that Azure Functions supports.</p>
</blockquote>
<p>I was a bit disappointed that F# is not an option. But actually, since
Durable Functions support precompiled .NET assembly model, pretty much
anything doable in C# can be done in F# too.</p>
<p>The goal of this post is to show that you can write Durable Functions in F#.
I used precompiled .NET Standard 2.0 F# Function App running on 2.0 preview
runtime.</p>
<h2 id="orchestration-functions">Orchestration Functions</h2>
<p>The stateful workflows are Azure Functions with a special <code>OrchestrationTrigger</code>.
Since they are asynchronous, C# code is always based on <code>Task</code> and <code>async</code>-<code>await</code>.
Here is a simple example of orchestrator in C#:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;List&lt;<span class="hljs-keyword">string</span>&gt;&gt; Run([OrchestrationTrigger] DurableOrchestrationContext context)
{
    <span class="hljs-keyword">var</span> outputs = <span class="hljs-keyword">new</span> List&lt;<span class="hljs-keyword">string</span>&gt;();

    outputs.Add(<span class="hljs-keyword">await</span> context.CallActivityAsync&lt;<span class="hljs-keyword">string</span>&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Tokyo"</span>));
    outputs.Add(<span class="hljs-keyword">await</span> context.CallActivityAsync&lt;<span class="hljs-keyword">string</span>&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Seattle"</span>));
    outputs.Add(<span class="hljs-keyword">await</span> context.CallActivityAsync&lt;<span class="hljs-keyword">string</span>&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"London"</span>));

    <span class="hljs-comment">// returns ["Hello Tokyo!", "Hello Seattle!", "Hello London!"]</span>
    <span class="hljs-keyword">return</span> outputs;
}
</code></pre>
<p>F# has its own preferred way of doing asynchronous code based on <code>async</code>
computation expression. The direct refactoring could look something like</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> Run(<span class="hljs-meta">[&lt;OrchestrationTrigger&gt;]</span> context: DurableOrchestrationContext) = async {
  <span class="hljs-keyword">let!</span> hello1 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Tokyo"</span>)   |&gt; Async.AwaitTask
  <span class="hljs-keyword">let!</span> hello2 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Seattle"</span>) |&gt; Async.AwaitTask
  <span class="hljs-keyword">let!</span> hello3 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"London"</span>)  |&gt; Async.AwaitTask
  <span class="hljs-keyword">return</span> [hello1; hello2; hello3]
} |&gt; Async.StartAsTask
</code></pre>
<p>That would work for a normal HTTP trigger, but it blows up for the Orchestrator
trigger because multi-threading operations are not allowed:</p>
<blockquote>
<p>Orchestrator code must never initiate any async operation except by 
using the DurableOrchestrationContext API. The Durable Task Framework 
executes orchestrator code on a single thread and cannot interact with 
any other threads that could be scheduled by other async APIs.</p>
</blockquote>
<p>To solve this issue, we need to keep working with <code>Task</code> directly. This is
not very handy with standard F# libraries. So, I pulled an extra NuGet
package <code>TaskBuilder.fs</code> which provides a <code>task</code> computation expression.</p>
<p>The above function now looks very simple:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> Run(<span class="hljs-meta">[&lt;OrchestrationTrigger&gt;]</span> context: DurableOrchestrationContext) = task {
  <span class="hljs-keyword">let!</span> hello1 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Tokyo"</span>)
  <span class="hljs-keyword">let!</span> hello2 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"Seattle"</span>)
  <span class="hljs-keyword">let!</span> hello3 = context.CallActivityAsync&lt;string&gt;(<span class="hljs-string">"E1_SayHello"</span>, <span class="hljs-string">"London"</span>)
  <span class="hljs-keyword">return</span> [hello1; hello2; hello3]
}
</code></pre>
<p>And the best part is that it works just fine.</p>
<p><code>SayHello</code> function is Activity trigger based, and no special effort is required
to implement it in F#:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-meta">[&lt;FunctionName("E1_SayHello")&gt;]</span>
<span class="hljs-keyword">let</span> SayHello(<span class="hljs-meta">[&lt;ActivityTrigger&gt;]</span> name) =
  sprintf <span class="hljs-string">"Hello %s!"</span> name
</code></pre>
<h2 id="more-examples">More Examples</h2>
<p>Durable Functions repository comes with 
<a href="https://github.com/Azure/azure-functions-durable-extension/tree/master/samples/precompiled">a set of 4 samples</a>
implemented in C#. I took all of those samples and ported them over to F#.</p>
<p>You&#39;ve already seen the first <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/12-durable/HelloSequence.fs"><code>Hello Sequence</code> sample</a>
above: the orchestrator calls the activity function 3 times and combines the
results. As simple as it looks, the function will actually run 3 times for each
execution, saving state before each subsequent call.</p>
<p>The second <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/12-durable/BackupSiteContent.fs"><code>Backup Site Content</code> sample</a>
is using this persistence mechanism to run
a potentially slow workflow of copying all files from a given directory to
a backup location. It shows how multiple activities can be executed in
parallel:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> tasks = Array.map (<span class="hljs-keyword">fun</span> f -&gt; backupContext.CallActivityAsync&lt;int64&gt;(<span class="hljs-string">"E2_CopyFileToBlob"</span>, f)) files
<span class="hljs-keyword">let!</span> results = Task.WhenAll tasks
</code></pre>
<p>The third <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/12-durable/Counter.fs"><code>Counter</code> example</a>
demos a potentially infinite actor-like workflow, where state can exist and
evolve for indefinite period of time. The key API calls are based on
<code>OrchestrationContext</code>:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> counterState = counterContext.GetInput&lt;int&gt;()
<span class="hljs-keyword">let!</span> command = counterContext.WaitForExternalEvent&lt;string&gt;(<span class="hljs-string">"operation"</span>)
</code></pre>
<p>The final elaborate <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/12-durable/PhoneVerification.fs"><code>Phone Verification</code> workflow</a>
has several twists, like output binding for activity (<code>ICollector</code> is required
instead of C#&#39;s <code>out</code> parameter), third-party integration (Twilio to send SMSs),
recursive sub-function to loop through several attempts and context-based
timers for reliable timeout implementation.</p>
<p>So, if you happen to be an F# fan, you can still give Durable Functions a try.
Be sure to leave your feedback, so that the library could get even better 
before going GA.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/f#/'>F#</a>, <a href='/tags/durable-functions/'>Durable Functions</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Feb 6th, 2018</div>
    
    <h1><a href='/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server/'>Load Testing Azure SQL Database by Copying Traffic from Production SQL Server</a></h1>
    
    <div class="post-content">
        <p>Azure SQL Database is a managed service that provides low-maintenance SQL Server instances in the cloud.
You don&#39;t have to run and update VMs, or even take backups and setup failover clusters.
Microsoft will do administration for you, you just pay an hourly fee.</p>
<p>So, let&#39;s say you decide this value proposition is a good reason to migrate
away from your existing self-hosted SQL Server database running in production and replace
it with Azure SQL Database.</p>
<p>You do the functional testing and eventually everything works like charm. The next set of questions 
is going to be related to Database performance level:</p>
<ul>
<li>Which tier / how many DTU&#39;s should I provision?</li>
<li>How much will it cost?</li>
<li>Will it be able to handle my current production load?</li>
</ul>
<h2 id="dtus">DTUs</h2>
<p>Even if you collect all the specs of the hardware behind your existing SQL Server, you can&#39;t
directly use that knowledge to choose the right Azure SQL Database size.</p>
<p>The sizes are measured in Database Transaction Units (DTUs). These are abstract units
of measure which don&#39;t necessarily mean much on their own. Within a given tier
(Standard / Premium), doubling the DTU amount will double the max throughput.</p>
<p>That doesn&#39;t really help to plan for workload migrations.</p>
<p>There are some ways to estimate the DTU requirements by measuring metrics like CPU
and IOPS on your existing server. Have a look at <a href="http://dtucalculator.azurewebsites.net/">DTU Calculator</a>:
it consists of a data collector and an online converter from metric values to DTUs.</p>
<p>While useful as a first approximation, I&#39;m reluctant to provision Azure SQL Database 
size solely based on such estimates.</p>
<p>My answer to the problem is: Measure It!</p>
<h2 id="synthetic-tests">Synthetic Tests</h2>
<p>Go get a backup of your existing production database and Export / Import it into
Azure SQL Database. Pick the size based on your gut feel, run a load test, evaluate
the results, adjust the size, repeat.</p>
<p>If you know your workload really well, you can create a synthetic test:</p>
<ul>
<li>Create a script or scenario which resembles the real production load</li>
<li>Run it for a given period of time</li>
<li>Measure the DTU&#39;s consumed</li>
</ul>
<p>Unfortunately, I&#39;m yet to see a non-trivial database where I could manually create
such script and be reasonably sure that it reflects the reality. Most of the time
the load is consumer-driven, changes over time and heavily depends on exact query
parameter values.</p>
<p>Which brings me to the need of replaying <em>the actual production workload</em> on Azure
SQL Database.</p>
<h2 id="trace-and-replay">Trace and Replay</h2>
<p>SQL Server comes with a marvelous suite of tools refined over years of its existence.
It includes the tools to capture and replay the queries, so I started with those.</p>
<p>SQL Server Profiler has a trace template called <code>TSQL_Replay</code>:</p>
<blockquote>
<p>This template records information required to replay the trace. Use this template
to perform iterative turning, such as benchmark testing.</p>
</blockquote>
<p>This sounded like what I needed, so I ran the profiler with this template to save
a short trace.</p>
<p>Afterwards, it is possible to use the same SQL Server Profiler to replay the trace against
another target database. So the process looks like this:</p>
<p><img src="/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server//sql-trace-replay.png" alt="Replaying Traffic with SQL Server Profiler"></p>
<p>Unfortunately, this didn&#39;t go very well:</p>
<ul>
<li><p>Azure SQL Database is not supported by the tooling. The replay kind of runs, but
it throws lots of errors like reading from non-existent system tables, trying to
switch between databases and so on </p>
</li>
<li><p>Related or not to the previous item, but replay went terribly slow. It
seemed to slow down exponentially over time</p>
</li>
<li><p>The trace file itself was of huge size. Because the template tries to record pretty
much everything, tracing 5 minutes on production produced 10 GB of XML</p>
</li>
<li><p>Replay was not real-time: you first record, then you replay. This might not be a big
issue for many databases, but some of our queries have time parameter, and results would
change if I replay the trace 1 hour later</p>
</li>
</ul>
<p>Just to give you a rough idea, our production database-under-study is handling about
1000 RPC calls per second (mostly stored procedures).</p>
<h2 id="custom-trace-replay">Custom Trace &amp; Replay</h2>
<p>Since off-the-shelf solution didn&#39;t work for me, I decided to come up with my own
custom tool chain. Here is the idea:</p>
<p><img src="/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server//sql-trace-replay-event-hubs-functions.png" alt="Replaying Traffic with SQL Server Profiler"></p>
<p>There are two custom steps that I implemented:</p>
<ol>
<li><p>Run a console app which would host a custom trace server. The trace server
receives SQL commands and sends them to Azure Event Hubs in batches</p>
</li>
<li><p>Create an Azure Function application triggered by the Event Hub. Each function
call gets one SQL command to execute and runs it against Azure SQL database that
we are trying to load-test</p>
</li>
</ol>
<p>This setup worked remarkably well for me: I got the real-time replay of SQL commands
from production SQL Server to Azure SQL Database.</p>
<p>The rest of the article describes my setup so that you could reproduce it for your
workload.</p>
<h2 id="azure-sql-database">Azure SQL Database</h2>
<p>Ideally, you want your copy of the database to be as fresh as possible, so that the 
query plans and results match.</p>
<p>Some ideas to accomplish this are given in 
<a href="https://docs.microsoft.com/en-us/azure/sql-database/sql-database-cloud-migrate">SQL Server database migration to SQL Database in the cloud</a>.</p>
<p>Premium RS tier is great for testing, because it is much cheaper than Premium
tier, while it provides the same level of performance.</p>
<h2 id="event-hubs">Event Hubs</h2>
<p>I used Azure Event Hubs as messaging middleware between Trace Server and Replay 
Function App.</p>
<p>I started with Azure Storage Queues, but the server wasn&#39;t able to send messages
fast enough, mostly due to lack of batching.</p>
<p>Event Hubs match naturally my choice of Azure Functions: Functions have a built-in
trigger with dynamic scaling out of the box.</p>
<p>So, I just created a new Event Hub via the portal, with 32 partitions allocated.</p>
<h2 id="trace-definition-file">Trace Definition File</h2>
<p>In order to run a custom Trace Server, you still need a trace definition file.
The built-in template <code>TSQL_Replay</code> mentioned above could work, but
it&#39;s subscribed to way too many events and columns.</p>
<p>Instead, I produced my own trace template with minimal selection.
To do that, open SQL Server Profiler, then navigate to <code>File -&gt; Templates -&gt; New Template</code>,
give it a name and then on <code>Events Selection</code> tab exclude everything except
exactly the commands that you want to replay.</p>
<p>We use stored procedures for pretty much everything, so my selection looked
just like this:</p>
<p><img src="/2018/02/load-testing-azure-sql-database-by-copying-traffic-from-production-sql-server//sql-profiler-template.png" alt="SQL Profiler Template"></p>
<p>For the first few runs, I advise you to restrict the trace even further. Click
<code>Column Filters</code> button, select <code>TextData</code> there and set <strong>Like</strong> filter
to a single stored procedure, e.g. matching the pattern <code>%spProductList%</code>.</p>
<p>This way you can debug your whole replay chain without immediately overloading
any part of it with huge stream of commands.</p>
<p>Once done, save the <code>tdf</code> file to disk. An example of such trace definition file
can be found in <a href="https://github.com/mikhailshilkov/sql-trace-replay/tree/master/TDF">my github</a>.</p>
<h2 id="trace-server">Trace Server</h2>
<p>My trace server is a simple C# console application.</p>
<p>Create a new console app and reference a NuGet package <code>Microsoft.SqlServer.SqlManagementObjects</code>.
Mine is of version <code>140.17218.0</code> (latest as of today).</p>
<p>Unfortunately, this NuGet package is not fully self-contained. In order to run
a profiling session, you have to install SQL Server Profiler tool on the machine
where you want to run the trace server.</p>
<p>Chances are that you already have it there, but be sure to update to the matching
version: mine works with <code>17.4 / 14.0.17213.0</code> but refused to work with older 
versions.</p>
<p>Now we can implement our trace server as a console application. The main
method looks like this:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Main</span>(<span class="hljs-params"><span class="hljs-keyword">string</span>[] args</span>) <span class="hljs-comment">// args: &lt;db server name&gt; &lt;db name&gt; &lt;trace file&gt;</span>
</span>{
    <span class="hljs-comment">// 1. Run trace server</span>
    <span class="hljs-keyword">var</span> connectionInfo = <span class="hljs-keyword">new</span> SqlConnectionInfo(args[<span class="hljs-number">0</span>])
    {
        DatabaseName = args[<span class="hljs-number">1</span>],
        UseIntegratedSecurity = <span class="hljs-literal">true</span>
    };
    <span class="hljs-keyword">var</span> trace = <span class="hljs-keyword">new</span> TraceServer();
    trace.InitializeAsReader(connectionInfo, args[<span class="hljs-number">2</span>]);

    <span class="hljs-comment">// 2. Continuously read traces and send them to event hubs</span>
    <span class="hljs-keyword">var</span> tokenSource = <span class="hljs-keyword">new</span> CancellationTokenSource();
    <span class="hljs-keyword">var</span> readerTask = Task.Factory.StartNew(() =&gt; ReadTrace(trace, tokenSource.Token), tokenSource.Token);
    <span class="hljs-keyword">var</span> senderTask = Task.Factory.StartNew(() =&gt; SendToEventHubs(tokenSource.Token), tokenSource.Token);

    <span class="hljs-comment">// 3. Stop the trace</span>
    Console.WriteLine(<span class="hljs-string">"Press any key to stop..."</span>);
    Console.ReadKey();
    tokenSource.Cancel();
    Task.WaitAll(readerTask, senderTask);
}
</code></pre>
<p>The first block initializes SQL connection using command line arguments and integrated
security, and then starts the Trace Server.</p>
<p>Because of the large volume, I made trace reader and event sender to work on separate
threads. They talk to each other via a concurrent queue:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">readonly</span> ConcurrentQueue&lt;<span class="hljs-keyword">string</span>&gt; eventQueue = <span class="hljs-keyword">new</span> ConcurrentQueue&lt;<span class="hljs-keyword">string</span>&gt;();
</code></pre>
<p>Finally, when operator presses any key, the cancellation is requested and the reader and
sender get shut down.</p>
<p>Trace Reader task is a loop crunching though trace data and sending the SQL statements
(with some exclusions) to the concurrent in-memory queue:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">ReadTrace</span>(<span class="hljs-params">TraceServer trace, CancellationToken token</span>)
</span>{ 
    <span class="hljs-keyword">while</span> (trace.Read() &amp;&amp; !token.IsCancellationRequested)
    {
        <span class="hljs-keyword">var</span> eventClass = trace[<span class="hljs-string">"EventClass"</span>].ToString();
        <span class="hljs-keyword">if</span> (<span class="hljs-keyword">string</span>.Compare(eventClass, <span class="hljs-string">"RPC:Completed"</span>) == <span class="hljs-number">0</span>)
        {
            <span class="hljs-keyword">var</span> textData = trace[<span class="hljs-string">"TextData"</span>].ToString();
            <span class="hljs-keyword">if</span> (!textData.Contains(<span class="hljs-string">"sp_reset_connection"</span>)
                &amp;&amp; !textData.Contains(<span class="hljs-string">"sp_trace"</span>)
                &amp;&amp; !textData.Contains(<span class="hljs-string">"sqlagent"</span>))
            {
                eventQueue.Enqueue(textData);
            }
        }
    }

    trace.Stop();
    trace.Close();
}
</code></pre>
<p>Event Sender is dequeueing SQL commands from in-memory queue to collect batches of
events. As soon as a batch fills up, it gets dispatched to Event Hub:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">SendToEventHubs</span>(<span class="hljs-params">CancellationToken token</span>)
</span>{
    <span class="hljs-keyword">var</span> client = EventHubClient.CreateFromConnectionString(EventHubsConnectionString);
    <span class="hljs-keyword">var</span> batch = client.CreateBatch();
    <span class="hljs-keyword">while</span> (!token.IsCancellationRequested)
    {
        <span class="hljs-keyword">if</span> (!eventQueue.TryDequeue(<span class="hljs-keyword">out</span> <span class="hljs-keyword">string</span> sql))
        {
            Thread.Sleep(<span class="hljs-number">10</span>);
            <span class="hljs-keyword">continue</span>;
        }

        <span class="hljs-keyword">var</span> eventData = <span class="hljs-keyword">new</span> EventData(Encoding.UTF8.GetBytes(sql));
        <span class="hljs-keyword">if</span> (!batch.TryAdd(eventData) &amp;&amp; batch.Count &gt; <span class="hljs-number">0</span>)
        {
            client.SendAsync(batch.ToEnumerable())
                .ContinueWith(OnAsyncMethodFailed, token, TaskContinuationOptions.OnlyOnFaulted, TaskScheduler.Default);
            batch = client.CreateBatch();
            batch.TryAdd(eventData);
        }
    }
}
</code></pre>
<p>If your trace doesn&#39;t produce so many messages, you will probably want to periodically send out the batches
even before they get full, just to keep that process closer to real time.</p>
<p>Note that sender does not await <code>SendAsync</code> call. Instead, we only subscribe to failures via <code>OnAsyncMethodFailed</code>
callback to print it to console:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">OnMyAsyncMethodFailed</span>(<span class="hljs-params">Task task</span>)
</span>{
    Console.WriteLine(task.Exception?.ToString() ?? <span class="hljs-string">"null error"</span>);
}
</code></pre>
<p>And that concludes the implementation of the Trace Server. SQL commands now go to Event Hub, to be picked
up by Trace Replay.</p>
<h2 id="trace-replay-function-app">Trace Replay Function App</h2>
<p>To replay those traces against the target Azure SQL Database, I could make another console
application which would contain <code>EventProcessorHost</code> to receive and process SQL commands.</p>
<p>However, under high load a single machine might not be able to keep up with executing all
those commands in real time.</p>
<p>Instead, I decided to distribute such Replay App over multiple machines. To deploy a 
DDoS network, if you will :)</p>
<p>And I don&#39;t have to build, find, configure and synchronize all those servers myself, since we
are living in the world of serverless.</p>
<p><a href="https://azure.microsoft.com/en-us/services/functions/">Azure Functions</a> are the perfect tool for this job. Once you start the trace server,
Function App will start scaling up based on the amount of events in Event Hub, and will
expand until it catches up with the workload.</p>
<p>But as long as you don&#39;t run the trace server, it won&#39;t consume any servers and won&#39;t cost you
a dime. </p>
<p>Here is the implementation of Trace Replay Azure Function:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Replay</span>
{
    [<span class="hljs-meta">FunctionName(<span class="hljs-meta-string">"Replay"</span>)</span>]
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Run</span>(<span class="hljs-params">
        [EventHubTrigger(<span class="hljs-string">"sqltrace"</span>, Connection = <span class="hljs-string">"EventHubsConn"</span></span>)] <span class="hljs-keyword">string</span> sql,
        TraceWriter log)
    </span>{
        <span class="hljs-keyword">var</span> commandName = sql
            .Split(<span class="hljs-literal">null</span>)
            .SkipWhile(r =&gt; r != <span class="hljs-string">"exec"</span> &amp;&amp; r != <span class="hljs-string">"sp_executesql"</span>)
            .FirstOrDefault(r =&gt; !r.Contains(<span class="hljs-string">"exec"</span>)) ?? <span class="hljs-string">"&lt;empty&gt;"</span>;

        <span class="hljs-keyword">var</span> stopwatch = <span class="hljs-keyword">new</span> Stopwatch();
        stopwatch.Start();

        <span class="hljs-keyword">try</span>
        {
            <span class="hljs-keyword">using</span> (<span class="hljs-keyword">var</span> sqlConnection = <span class="hljs-keyword">new</span> SqlConnection(AzureSqlConnectionString))
            <span class="hljs-keyword">using</span> (<span class="hljs-keyword">var</span> cmd = <span class="hljs-keyword">new</span> SqlCommand())
            {
                sqlConnection.Open();

                cmd.CommandText = sql;
                cmd.CommandType = CommandType.Text;

                cmd.Connection = sqlConnection;

                <span class="hljs-keyword">int</span> count = <span class="hljs-number">0</span>;
                <span class="hljs-keyword">using</span> (<span class="hljs-keyword">var</span> reader = cmd.ExecuteReader())
                {
                    <span class="hljs-keyword">while</span> (reader.Read())
                    {
                        count++;
                    }
                }

                log.Info(<span class="hljs-string">$"Processed <span class="hljs-subst">{commandName}</span> in <span class="hljs-subst">{stopwatch.ElapsedMilliseconds}</span> ms with <span class="hljs-subst">{count}</span> rows"</span>);
            }
        }
        <span class="hljs-keyword">catch</span> (Exception ex)
        {
            log.Error(<span class="hljs-string">$"Error in <span class="hljs-subst">{commandName}</span> in <span class="hljs-subst">{stopwatch.ElapsedMilliseconds}</span> <span class="hljs-subst">{ex.Message}</span>"</span>);
            <span class="hljs-keyword">throw</span>;
        }
    }
}
</code></pre>
<p>It&#39;s super simple: the function gets a SQL statement, executes it with <code>SqlCommand</code> class and
logs the result with timing and returned row count. And that&#39;s everything required to start
bombarding my Azure SQL Database.</p>
<h2 id="evaluating-results">Evaluating Results</h2>
<p>The purpose of this whole exercise was to evaluate whether a provisioned DTU level
is enough to stand the load comparable to existing production.</p>
<p>So, after I ran the test, I could browse through the DTU usage chart in Azure portal to
get overall usage statistics.</p>
<p>I&#39;ve also spent quite some time analyzing the usage breakdown as reported by <code>sp_BlitzCache</code>
from <a href="https://github.com/BrentOzarULTD/SQL-Server-First-Responder-Kit">Responder Kit</a>. 
Please note that it&#39;s not officially supported for Azure SQL Database, but it seems to work 
reasonably well.</p>
<p>Be sure to re-run your experiments multiple times, at different days and time intervals.</p>
<p>The full code sample can be found in <a href="https://github.com/mikhailshilkov/sql-trace-replay/tree/master/TDF">my github</a>.</p>
<p>I hope Azure SQL Database will perform to your expectations and within your budget. But
hope is not a good strategy, so go ahead and try it out!</p>
<p>Happy DDoS-ing!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-sql-database/'>Azure SQL Database</a>, <a href='/tags/performance/'>Performance</a>, <a href='/tags/scalability/'>Scalability</a>, <a href='/tags/azure-event-hubs/'>Azure Event Hubs</a>, <a href='/tags/azure-functions/'>Azure Functions</a>
    </div>
    
</article>


<div class="page-nav">
    
    
    <a class="page-nav-older" href="/2/">Previous page <span class="icon icon-arrow-right-2"></span></a>
    
</div>

<div id="me">
    <p itemscope itemtype="http://data-vocabulary.org/Person">
        <img src="/images/Headshot-Square.jpg" alt="Mikhail Shilkov" itemprop="photo" />
        I'm <b><span itemprop="name">Mikhail Shilkov</span></b>, a <span itemprop="title">software developer</span>. I enjoy F#, C#, Javascript and SQL development, reasoning about distributed systems, data processing pipelines, cloud and web apps. I blog about my experience on this website.
    </p>
    <p>
        <a href="https://www.linkedin.com/in/mikhailshilkov/">LinkedIn</a> &#8226;
        <a href="https://twitter.com/mikhailshilkov">@mikhailshilkov</a> &#8226;
        <a href="https://github.com/mikhailshilkov">GitHub</a> &#8226;
        <a href="https://stackoverflow.com/users/1171619/mikhail">Stack Overflow</a>
    </p>
</div>

</div>
<div class="container">
    <div class="navbar navbar-footer">
        <p class="navbar-center navbar-text">Content copyright &copy; 2017 Mikhail Shilkov</p>
    </div>
</div>



<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.pack.js"></script>
<script src="/vendor/highlight.pack.js"></script>
<script src="/site.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59218480-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>