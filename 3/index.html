<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#">
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>

    <meta name="description" content="Software development using .NET, C#, SQL, Javascript and related technologies" />

    <title>Mikhail Shilkov</title>
    <meta name="author" content="Mikhail Shilkov">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <meta name="twitter:card" content="summary"></meta>
    <meta name="twitter:creator" content="@MikhailShilkov"></meta>

    <meta property="og:type" content="article" />
    <meta property="og:title" content="Mikhail Shilkov" />
    <meta property="og:url" content="https://mikhail.io/3/" />



    <link href="/feed/" rel="alternate" title="mikhail.io" type="application/atom+xml">
    <link href="/favicon.ico?v=2" rel="shortcut icon">

    <!-- Bootstrap -->
    <link href="/styles/site.css" rel="stylesheet" media="screen">
    <link href="/vendor/prism.css" rel="stylesheet" media="screen">

    <meta name="generator" content="DocPad v6.78.6" />
    
</head>
<body>

<div class="navbar navbar-default navbar-static-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">
                <span class="text-primary">Mikhail Shilkov</span><br />
                <span class="elevator-pitch">Serverless, Azure, FP, F# and more</span>
            </a>
        </div>
        <div class="collapse navbar-collapse navbar-right">
            <ul class="nav navbar-nav">
                <!--<li><a href="/">Blog</a></li>-->
                
                    <li><a href="/tags/">Topics</a></li>
                
                    <li><a href="/archives/">Archives</a></li>
                
                    <li><a href="/talks/">Talks</a></li>
                
                    <li><a href="/about/">About</a></li>
                
                <li class="hidden-xs">
                    <a href="/feed/" class="rss"><span class="icon icon-feed"></span></a>
                    <a href="https://www.linkedin.com/in/mikhailshilkov" class="linkedin"><span class="icon icon-linkedin"></span></a>
                    <a href="https://twitter.com/mikhailshilkov" class="twitter"><span class="icon icon-twitter"></span></a>
                    <a href="https://github.com/mikhailshilkov" class="github"><span class="icon icon-github"></span></a>
                </li>
            </ul>
            <form class="navbar-form navbar-right hidden-xs" role="search" action="https://google.com/search"
                  method="get">
                <div class="form-group">
                    <input type="search" name="q" class="form-control" placeholder="Search">
                    <input type="hidden" name="q" value="site:mikhail.io">
                </div>
            </form>
        </div>
    </div>
</div>
<div class="container">
    
    <article class="post">
    <div class="post-date">Dec 3rd, 2017</div>
    
    <h1><a href='/2017/12/precompiled-azure-functions-in-fsharp/'>Precompiled Azure Functions in F#</a></h1>
    
    <div class="post-content">
        <p><em>This post is giving a start to 
<a href="https://sergeytihon.com/2017/10/22/f-advent-calendar-in-english-2017/">F# Advent Calendar in English 2017</a>. 
Please follow the calendar for all the great posts to come.</em></p>
<p>Azure Functions is a &quot;serverless&quot; cloud offering from Microsoft. It
allows you to run your custom code as response to events in the cloud. 
Functions are very easy to
start with; and you only pay per execution - with free allowance sufficient
for any proof-of-concept, hobby project or even low-usage production loads.
And when you need more, Azure will scale your project up automatically.</p>
<p>F# is one of the officially supported languages for Azure Functions.
Originally, F# support started with F# Script files (authored directly
in Azure portal or copied from local editor), so you can find many articles
online to get started, e.g.
<a href="http://brandewinder.com/2017/02/11/fsharp-azure-function-from-the-ground-up-part-1/">Creating an Azure Function in F# from the ground up</a> and
<a href="http://brandewinder.com/2017/03/06/fsharp-azure-function-from-the-ground-up-part-2/">Part 2</a>
by Mathias Brandewinder.</p>
<p>However, I find script-based model a bit limited. In today&#39;s article I
will focus on creating Azure Functions as precompiled .NET libraries.
Along the way, I&#39;ll use cross-platform tools like .NET Core and VS Code,
and I&#39;ll show how to integrate Functions with some popular tools
like Suave and Paket.</p>
<h2 id="create-a-project">Create a Project</h2>
<p>You can follow this walkthrough on Windows or Mac, just make sure that
you have <code>.NET Core 2</code> and <code>Node.js 8.x</code> with <code>npm</code> installed. My editor of
choice is Visual Studio Code with Ionide plugin.</p>
<p>I&#39;ll show you how to create a new F# Function App from scratch. If you want to
jump to runnable project, you can get it from 
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/6-precompiled-timer">my github</a>.</p>
<p>We start with creating a new F# library project for .NET Standard 2. Run
in your command line:</p>
<pre><code class="lang-sh">dotnet new classlib --language F# --name HelloFunctions
</code></pre>
<p>This command creates a folder with two files: <code>HelloFunctions.fsproj</code> project
file and <code>Library.fs</code> source code file.</p>
<p>Now, add a reference to Azure Functions NuGet package:</p>
<pre><code class="lang-sh">dotnet add package Microsoft.NET.Sdk.Functions
</code></pre>
<h2 id="define-a-function">Define a Function</h2>
<p>Open <code>Library.fs</code> code file and change it to the following code:</p>
<pre><code class="lang-fsharp">namespace HelloFunctions

open System
open Microsoft.Azure.WebJobs
open Microsoft.Azure.WebJobs.Host

module Say =
  let private daysUntil (d: DateTime) =
    (d - DateTime.Now).TotalDays |&gt; int

  let hello (timer: TimerInfo, log: TraceWriter) =
    let christmas = new DateTime(2017, 12, 25)

    daysUntil christmas
    |&gt; sprintf &quot;%d days until Christmas&quot;
    |&gt; log.Info
</code></pre>
<p>We defined a function <code>hello</code> which should be triggered by Functions runtime
based on time intervals. Every time the function is called, we log how many
days we still need to wait before Christmas 2017.</p>
<p>To convert this simple F# function to an Azure Function, create a folder called
<code>Hello</code> (or choose any other name) next to the project file and add 
<code>function.json</code> file in there:</p>
<pre><code class="lang-json">{
  &quot;bindings&quot;: [
    {
      &quot;name&quot;: &quot;timer&quot;,
      &quot;type&quot;: &quot;timerTrigger&quot;,
      &quot;schedule&quot;: &quot;0 * * * * *&quot;
    }
  ],
  &quot;scriptFile&quot;: &quot;../bin/HelloFunctions.dll&quot;,
  &quot;entryPoint&quot;: &quot;HelloFunctions.Say.hello&quot;
}
</code></pre>
<p>We defined that:</p>
<ul>
<li>Our function is triggered by timer</li>
<li>It runs every minute at 0 seconds</li>
<li>The entry point is our <code>hello</code> function in the compiled assembly</li>
</ul>
<h2 id="prepare-local-runtime">Prepare Local Runtime</h2>
<p>There are a couple more configuration files needed to be able to
run the Function App locally. <code>host.json</code> defines hosting parameters; empty
file will do for now:</p>
<pre><code class="lang-json">{
}
</code></pre>
<p>Most triggers need to connect to a Storage Account. For examples, timer
trigger uses it to hold leases to define which running instance will 
actually execute the action every minute. Copy a connection string to your 
Storage Account (local Storage emulator is fine too) and put it into 
<code>local.settings.json</code> file:</p>
<pre><code class="lang-json">{
  &quot;IsEncrypted&quot;: false,
  &quot;Values&quot;: {
    &quot;AzureWebJobsStorage&quot;: &quot;...your connection string...&quot;
  }
}
</code></pre>
<p>Note that this file is only used for local development and is not published
to Azure by default.</p>
<p>Finally, we need to modify <code>fsproj</code> file to make the build tool copy those
files into <code>bin</code> folder. Add the following section in there:</p>
<pre><code class="lang-xml">&lt;ItemGroup&gt;
  &lt;Content Include=&quot;Hello\function.json&quot;&gt;
    &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
  &lt;/Content&gt;
  &lt;Content Include=&quot;host.json&quot;&gt;
    &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
  &lt;/Content&gt;
  &lt;Content Include=&quot;local.settings.json&quot;&gt;
    &lt;CopyToOutputDirectory&gt;PreserveNewest&lt;/CopyToOutputDirectory&gt;
  &lt;/Content&gt;
&lt;/ItemGroup&gt;
</code></pre>
<h2 id="run-app-locally">Run App Locally</h2>
<p>The first step is to build and publish our Function App with <code>dotnet</code>
commands:</p>
<pre><code class="lang-sh">dotnet build
dotnet publish
</code></pre>
<p>The first line produces the dll file and the second line copies it
and all of its dependencies to <code>publish</code> folder.</p>
<p>The nice thing about Azure Functions is that you can easily run them
locally on a development machine. Execute the following command to 
install the runtime and all the required libraries:</p>
<pre><code class="lang-sh">npm install -g azure-functions-core-tools@core
</code></pre>
<p>This will add a <code>func</code> CLI to your system which is the tool to
use for all Function related operations.</p>
<p>Navigate to <code>bin\Debug\netstandard2.0\publish</code> folder and run <code>func start</code> 
from there. You should see that your app is now running, and your timer
function is scheduled for execution:</p>
<p><img src="/2017/12/precompiled-azure-functions-in-fsharp/./funcstart.png" alt="Function App Start"></p>
<p>Once the next minute comes, the timer will trigger and you will see
messages in the log:</p>
<p><img src="/2017/12/precompiled-azure-functions-in-fsharp/./funcran.png" alt="Timer Trigger Working"></p>
<h2 id="integrate-into-vs-code-">Integrate into VS Code </h2>
<p>You are free to use full Visual Studio or any editor to develop Function
Apps in F#. I&#39;ve been mostly using VS Code for this purpose, and I believe
it&#39;s quite popular among F# community.</p>
<p>If you use VS Code, be sure to setup the tasks that you can use from within
the editor. I usually have at least 3 tasks: &quot;build&quot; (<code>dotnet build</code>),
&quot;publish&quot; (<code>dotnet publish</code>) and &quot;run&quot; (<code>func start --script-root bin\\debug\\netstandard2.0\\publish</code>),
with shortcuts configured to all of them.</p>
<p>You can find an example of <code>tasks.json</code> file
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/blob/master/6-precompiled-timer/.vscode/tasks.json">here</a>.</p>
<p>Also, check out <a href="https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-azurefunctions">Azure Functions Extension</a>.</p>
<h2 id="deploy-to-azure">Deploy to Azure</h2>
<p>You can deploy the exact same application binaries to Azure. Start by 
creating an empty Function App in the portal, or via Azure CLI (<code>func</code> CLI
does not support that).</p>
<p>Then run the following command to deploy your precompiled function to
this app:</p>
<pre><code class="lang-sh">func azure functionapp publish &lt;FunctionAppName&gt;
</code></pre>
<p>At the first run, it will verify your Azure credentials.</p>
<p>In real-life production scenarios your workflow is probably going to be
similar to this:</p>
<ul>
<li>Change Function App code</li>
<li>Run it locally to test the change</li>
<li>Push the code changes to the source control repository</li>
<li>Have your CI/CD pipeline build it, run the tests and then push
the binaries to Azure Functions environment</li>
</ul>
<h2 id="http-trigger">HTTP Trigger</h2>
<p>Timer-triggered functions are useful, but that&#39;s just one limited use case.
Several other event types can trigger Azure Functions, and for all of them
you can create precompiled functions and run them locally.</p>
<p>The most ubiquotous trigger for any serverless app is probably HTTP. So,
for the rest of the article I will focus on several approaches to 
implement HTTP functions. Nonetheless, the same techique can be applied to
other triggers too.</p>
<p>F# code for the simplest HTTP Function can look like this:</p>
<pre><code class="lang-fsharp">namespace PrecompiledApp

open Microsoft.AspNetCore.Mvc
open Microsoft.AspNetCore.Http
open Microsoft.Azure.WebJobs.Host

module PrecompiledHttp =

  let run(req: HttpRequest, log: TraceWriter) =
    log.Info(&quot;F# HTTP trigger function processed a request.&quot;)
    ContentResult(Content = &quot;HO HO HO Merry Christmas&quot;, ContentType = &quot;text/html&quot;)
</code></pre>
<p>You can find a full example of HTTP Function App 
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/5-precompiled">here</a>.</p>
<p>This code is using ASP.NET Core classes for request and response. It&#39;s still
just an F# function, so we need to bind it to a trigger in <code>function.json</code>:</p>
<pre><code class="lang-json">{
  &quot;bindings&quot;: [
    {
      &quot;type&quot;: &quot;httpTrigger&quot;,
      &quot;methods&quot;: [&quot;get&quot;],
      &quot;authLevel&quot;: &quot;anonymous&quot;,
      &quot;name&quot;: &quot;req&quot;,
      &quot;route&quot;: &quot;hellosanta&quot;
    }
  ],
  &quot;scriptFile&quot;: &quot;../bin/PrecompiledApp.dll&quot;,
  &quot;entryPoint&quot;: &quot;PrecompiledApp.PrecompiledHttp.run&quot;
}
</code></pre>
<p>If you run the app, the function will be hosted at localhost</p>
<p><img src="/2017/12/precompiled-azure-functions-in-fsharp/./httpstart.png" alt="HTTP Trigger Working"></p>
<p>And a request to <code>http://localhost:7071/api/hellosanta</code> will get responded
with our &quot;HO HO HO&quot; message.</p>
<p>This function is of &quot;Hello World&quot; level, but the fact that it&#39;s inside a
normal F# library gives you lots of power.</p>
<p>Let&#39;s see at some examples of how to use it.</p>
<h2 id="suave-function">Suave Function</h2>
<p>What can we do to enhance developer experience? We can use our 
favourite F# libraries.</p>
<p><a href="http://suave.io/">Suave</a> is one of the most popular libraries to 
implement Web API&#39;s with. And we can use it in Azure Functions too!</p>
<p>Let&#39;s first make a small twist to HTTP trigger definition in <code>function.json</code>:</p>
<pre><code class="lang-json">&quot;bindings&quot;: [
  {
    &quot;type&quot;: &quot;httpTrigger&quot;,
    &quot;methods&quot;: [&quot;get&quot;],
    &quot;authLevel&quot;: &quot;anonymous&quot;,
    &quot;name&quot;: &quot;req&quot;,
    &quot;route&quot;: &quot;{*anything}&quot;
  }
],
</code></pre>
<p>Binding now defines a wildcard route to redirect all requests 
to this function. That&#39;s because we want Suave to take care of routing
for us.</p>
<p>The definition of such routing will look familiar to all Suave users:</p>
<pre><code class="lang-fsharp">module App =
  open Suave
  open Suave.Successful
  open Suave.Operators
  open Suave.Filters

  let app = 
    GET &gt;=&gt; choose
      [ path &quot;/api/what&quot; &gt;=&gt; OK &quot;Every time we love, every time we give, it&#39;s Christmas.&quot;
        path &quot;/api/when&quot; &gt;=&gt; OK &quot;Christmas isn&#39;t a season. It&#39;s a feeling.&quot;
        path &quot;/api/how&quot; &gt;=&gt; OK &quot;For it is in giving that we receive.&quot; ]
</code></pre>
<p>Azure Function is just a one-liner wiring Suave app into the pipeline:</p>
<pre><code class="lang-fsharp">module Http =
  open Suave.Azure.Functions.Context

  let run req =
    req |&gt; runWebPart App.app  |&gt; Async.StartAsTask
</code></pre>
<p>The heavy lifting is done by <code>runWebPart</code> function, which is a utility
function defined in the same application. You can see the full code
of this wiring in <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/7-suave">my repo</a>.</p>
<p>Run the application and request the URL <code>http://localhost:7071/api/what</code> 
to see the function in action.</p>
<p>This example is very simple, but you can do lots of powerful stuff with Suave!
Most probably, you shouldn&#39;t go over the root and try to fit whole
mulpti-resource REST API into a single Azure Function. But it might still
make sense to keep related HTTP calls together, and Suave can help to keep
it cleaner.</p>
<h2 id="managing-dependencies-with-paket">Managing Dependencies with Paket</h2>
<p>Once your Function App becomes bigger and you start using multiple F#
projects, it makes sense to switch to <a href="https://fsprojects.github.io/Paket/">Paket</a>
package manager.</p>
<p>It is totally possible to use Paket with Azure Functions. There isn&#39;t much
specific to Azure Functions, really. Here is an example of <code>paket.dependecies</code>
file</p>
<pre><code>source https://www.nuget.org/api/v2

framework: &gt;= netstandard2.0
nuget FSharp.Core
nuget Microsoft.NET.Sdk.Functions
nuget Microsoft.AspNetCore.Mvc.Core
</code></pre><p>that I used in <a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/8-paket">example</a> 
which demonstrates Paket + Functions combination.</p>
<h2 id="attribute-based-functions">Attribute-Based Functions</h2>
<p>Up until now, we were writing <code>function.json</code> files manually for each 
function. This is not very tedious, but it is error prone. Microsoft offers an alternative 
programming model where these files are auto-generated by Functions SDK.</p>
<p>This programming model is based on attributes, which are similar to WebJobs 
SDK attributes. With this approach, there&#39;s no <code>function.json</code> file in 
the project. Instead, the function declaration is decorated with attributes:</p>
<pre><code class="lang-fsharp">[&lt;FunctionName(&quot;AttributeBased&quot;)&gt;]
let run([&lt;HttpTrigger&gt;] req: HttpRequest, log: TraceWriter)
</code></pre>
<p>The same development flow still works. Once you run <code>dotnet build</code>, a new 
<code>function.json</code> file will be generated and placed into <code>bin</code> folder. Functions 
runtime will be able to use it to run the function as usual.</p>
<p>Note that the generated file looks a bit different from the manual 
equivalent:</p>
<ol>
<li><p>It manifests itself with</p>
<pre><code class="lang-json"> &quot;generatedBy&quot;: &quot;Microsoft.NET.Sdk.Functions.Generator-1.0.6&quot;,
 &quot;configurationSource&quot;: &quot;attributes&quot;,
</code></pre>
</li>
<li><p>In case you use input and output bindings, you won&#39;t be able to see them
in the generated file. Only trigger will be visible in <code>json</code>. Don&#39;t worry,
input and output bindings will still work.</p>
</li>
</ol>
<p>You can find an example of HTTP function with attributes 
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples/tree/master/9-attributes">here</a>.</p>
<p>There are pro&#39;s and con&#39;s in this model. Obviously, not having to write
JSON files manually is beneficial. Some people find the binding attributes
really ugly though, especially when you have 3 or 4 bindings and each has 
multiple parameters. </p>
<p>My preference is to use attributes, but don&#39;t mix attribute decoration
with real code. I.e. keep the Function&#39;s body to a simple 1-liner, and
delegate the call to a properly defined F# function with the actual
domain logic.</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>Lots of F# users value the language for how quickly one can be productive
with it: based on concise syntax, powerful libraries and tools like FSI.</p>
<p>In my opinion, Azure Functions fit nicely into the picture. It takes just
several minutes before you can run your first Function App on developer
machine, and then seamlessly transfer it into the cloud.</p>
<p>I&#39;ve prepared a github repository where you can find more
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples">Examples of Azure Functions implemented in F#</a>.</p>
<p>Merry Serverless Functional Christmas!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/f#/'>F#</a>, <a href='/tags/f#-advent-calendar/'>F# Advent Calendar</a>, <a href='/tags/azure/'>Azure</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Nov 10th, 2017</div>
    
    <h1><a href='/2017/11/azure-functions-fsharp-talk/'>Azure F#unctions Talk at FSharping Meetup in Prague</a></h1>
    
    <div class="post-content">
        <p>On November 8th 2017 I gave a talk about developing Azure Functions
in F# at
<a href="https://www.meetup.com/FSharping/events/244137693/">FSharping</a>
meetup in Prague. </p>
<p>I really enjoyed giving this talk: the audience was
great and asked awesome questions. One more prove that F# community is
so welcoming and energizing!</p>
<p>All the demos of that session can be found in my
<a href="https://github.com/mikhailshilkov/azure-functions-fsharp-examples">github repository</a>.</p>
<p>The slides were only a small portion of my talk, but you can see them
below anyways.</p>
<p>Link to full-screen HTML slides: 
<a href="https://mikhail.io/talks/fsharping-azure-functions/">Azure F#unctions</a></p>
<p>Slides on SlideShare:</p>
<iframe src="//www.slideshare.net/slideshow/embed_code/key/oQIZywbdCRXdQA" width="595" height="485" frameborder="0" marginwidth="0" marginheight="0" scrolling="no" style="border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;" allowfullscreen=""> 
</iframe> 

<p>Thanks for attending my talk! Feel free to post any feedback in the comments.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/talk/'>Talk</a>, <a href='/tags/meetup/'>Meetup</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/f#/'>F#</a>, <a href='/tags/slides/'>Slides</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Oct 5th, 2017</div>
    
    <h1><a href='/2017/10/azure-function-triggered-by-azure-event-grid/'>Azure Function Triggered by Azure Event Grid</a></h1>
    
    <div class="post-content">
        <p><em>Update: I missed the elephant in the room. There actually exists a specialized
trigger for Event Grid binding. In the portal, just select <code>Experimental</code>
in <code>Scenario</code> drop down while creating the function. In precompiled 
functions, reference <code>Microsoft.Azure.WebJobs.Extensions.EventGrid</code> NuGet
package.</em></p>
<p><em>The rest of the article describes my original approach to trigger an
Azure Function from <a href="https://azure.microsoft.com/en-us/services/event-grid/">Azure Event Grid</a> 
with generic Web Hook trigger.</em></p>
<p>Here are the steps to follow:</p>
<h2 id="create-a-function-with-webhook-trigger">Create a Function with Webhook Trigger</h2>
<p>I&#39;m not aware of a specialized trigger type for Event Grid, so
I decided to use Generic Webhook trigger (which is essentially an
HTTP trigger).</p>
<p>I used the Azure Portal to generate a function, so here is the 
<code>function.json</code> that I got:</p>
<pre><code class="lang-json">{
  &quot;bindings&quot;: [
    {
      &quot;type&quot;: &quot;httpTrigger&quot;,
      &quot;direction&quot;: &quot;in&quot;,
      &quot;webHookType&quot;: &quot;genericJson&quot;,
      &quot;name&quot;: &quot;req&quot;
    },
    {
      &quot;type&quot;: &quot;http&quot;,
      &quot;direction&quot;: &quot;out&quot;,
      &quot;name&quot;: &quot;res&quot;
    }
  ],
  &quot;disabled&quot;: false
}
</code></pre>
<p>For precompiled functions, just decorate it with <code>HttpTriggerAttribute</code> with
POST method:</p>
<pre><code class="lang-csharp">public static Task&lt;HttpResponseMessage&gt; Run(
    [HttpTrigger(AuthorizationLevel.Function, &quot;post&quot;)] HttpRequestMessage req)
</code></pre>
<h2 id="parse-the-payload">Parse the Payload</h2>
<p>Events from Event Grid will arrive in a specific predefined JSON format.
Here is an example of events to expect:</p>
<pre><code class="lang-json">[{
  &quot;id&quot;: &quot;0001&quot;,
  &quot;eventType&quot;: &quot;MyHelloWorld&quot;,
  &quot;subject&quot;: &quot;Hello World!&quot;,
  &quot;eventTime&quot;: &quot;2017-10-05T08:53:07&quot;,
  &quot;data&quot;: {
    &quot;hello&quot;: &quot;world&quot;
  },
  &quot;topic&quot;: &quot;/SUBSCRIPTIONS/GUID/RESOURCEGROUPS/NAME/PROVIDERS/MICROSOFT.EVENTGRID/TOPICS/MY-EVENTGRID-TOPIC1&quot;
}]
</code></pre>
<p>To be able to parse those data more easily, I defined a C# class to deserialize
JSON to:</p>
<pre><code class="lang-csharp">public class GridEvent
{
    public string Id { get; set; }
    public string EventType { get; set; }
    public string Subject { get; set; }
    public DateTime EventTime { get; set; }
    public Dictionary&lt;string, string&gt; Data { get; set; }
    public string Topic { get; set; }
}
</code></pre>
<p>Now, the function can read the events (note, that they are sent in arrays)
from the body of POST request:</p>
<pre><code class="lang-csharp">public static async Task&lt;HttpResponseMessage&gt; Run(HttpRequestMessage req, TraceWriter log)
{
    string jsonContent = await req.Content.ReadAsStringAsync();
    var events = JsonConvert.DeserializeObject&lt;GridEvent[]&gt;(jsonContent);

    // do something with events

    return req.CreateResponse(HttpStatusCode.OK);
}
</code></pre>
<h2 id="validate-the-endpoint">Validate the Endpoint</h2>
<p>To prevent you from sending events to endpoints that you don&#39;t own, Event
Grid requires each subsriber to validate itself. For this purpose, Event
Grid will send events of the special type <code>SubscriptionValidation</code>. </p>
<p>The validation request will contain a code, which we need to echo back in
200-OK HTTP response. </p>
<p>Here is a small piece of code to do just that:</p>
<pre><code class="lang-csharp">if (req.Headers.GetValues(&quot;Aeg-Event-Type&quot;).FirstOrDefault() == &quot;SubscriptionValidation&quot;)
{
    var code = events[0].Data[&quot;validationCode&quot;];
    return req.CreateResponse(HttpStatusCode.OK,
        new { validationResponse = code });
}
</code></pre>
<p>The function is ready!</p>
<h2 id="create-a-custom-event-grid-topic">Create a Custom Event Grid Topic</h2>
<p>To test it out, go to the portal and create a custom Event Grid topic.
Then click on Add Event Subscription button, give it a name and copy paste
the function URL (including key) to Subscriber Endpoint field:</p>
<p><img src="/2017/10/azure-function-triggered-by-azure-event-grid//function-url.png" alt="Azure Function URL"></p>
<p><img src="/2017/10/azure-function-triggered-by-azure-event-grid//event-subscription.png" alt="Event Grid Subscription"></p>
<p>Creating a subscription will immediately trigger a validation request to
your function, so you should see one invocation in the logs.</p>
<h2 id="send-custom-events">Send Custom Events</h2>
<p>Now, go to your favorite HTTP client (curl, Postman, etc) and send a sample
event to check how the whole setup works:</p>
<pre><code class="lang-http">POST /api/events HTTP/1.1
Host: &lt;your-eventgrid-topic&gt;.westus2-1.eventgrid.azure.net
aeg-sas-key: &lt;key&gt;
Content-Type: application/json

[{
  &quot;id&quot;: &quot;001&quot;,
  &quot;eventType&quot;: &quot;MyHelloWorld&quot;,
  &quot;subject&quot;: &quot;Hello World!&quot;,
  &quot;eventTime&quot;: &quot;2017-10-05T08:53:07&quot;,
  &quot;data&quot;: {
    &quot;hello&quot;: &quot;world&quot;
  }
}]
</code></pre>
<p>Obviously, adjust the endpoint and key based on the data from the portal.</p>
<p>You should get a 200-OK back and then see your event in Azure Function 
invocation logs.</p>
<p>Have fun!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/azure-event-grid/'>Azure Event Grid</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Sep 25th, 2017</div>
    
    <h1><a href='/2017/09/wanted-effectively-once-processing-in-azure/'>Wanted: Effectively-Once Processing in Azure</a></h1>
    
    <div class="post-content">
        <p><em>This experimental post is a question. The question
is too broad for StackOverflow, so I&#39;m posting it here. Please engage in the
comments section, or forward the link to subject experts.</em></p>
<p>TL;DR: Are there any known patterns / tools / frameworks to provide 
scalable, stateful, effectively-once, end-to-end processing of messages, 
to be hosted in Azure, preferably on PaaS-level of service?</p>
<h2 id="motivational-example">Motivational Example</h2>
<p>Let&#39;s say we are making a TODO app. There is a constant flow of requests
to create a TODO in the system. Each request contains just two fields:
a title and a project ID which TODO should belong to. Here is the definition:</p>
<pre><code class="lang-fsharp">type TodoRequest = {
  ProjectId: int
  Title: string
}
</code></pre>
<p>Now, we want to process the request and assign each TODO an identifier,
which should be an auto-incremented integer. Numeration is unique per project,
so each TODO must have its own combination of <code>ProjectId</code> and <code>Id</code>:</p>
<pre><code class="lang-fsharp">type Todo = {
  ProjectId: int
  Id: int
  Title: string
}
</code></pre>
<p>Now, instead of relying on some database sequences, I want to describe this
transformation as a function. The function has the type <code>(TodoRequest, int) -&gt;
(Todo, int)</code>, i.e. it transforms a tuple of a request and current per-project
state (last generated ID) to a tuple of a TODO and post-processing state:</p>
<pre><code class="lang-fsharp">let create (request: TodoRequest, state: int) =
  let nextId = state + 1
  let todo = {
    ProjectId = request.ProjectId
    Id = nextId
    Title = request.Title
  }
  todo, nextId
</code></pre>
<p>This is an extremely simple function, and I can use it to great success to
process local, non-durable data.</p>
<p>But if I need to make a reliable distributed application out of it, I need
to take care of lots of things:</p>
<ol>
<li><p>No request should be lost. I need to persist all the requests into 
a durable storage in case of processor crash. </p>
</li>
<li><p>Similarly, I need to persist TODO&#39;s too. Presumably, some downstream 
logic will use the persisted data later on in TODO&#39;s lifecycle.</p>
</li>
<li><p>The state (the counter) must be durable too. In case of crash of processing
function, I want to be able to restart processing after recovery. </p>
</li>
<li><p>Processing of the requests should be sequential per project ID. Otherwise
I might get a clash of ID&#39;s in case two requests belonging to the same 
project are processed concurrently.</p>
</li>
<li><p>I still want requests to different projects to be processed in parallel,
to make sure the system scales up with the growth of project count.</p>
</li>
<li><p>There must be no holes or duplicates in TODO numbering per project, even
in face of system failures. In worst case, I agree to tolerate a duplicated
entry in the output log, but it must be exactly the same entry (i.e. two 
entries with same project id, id and title).</p>
</li>
<li><p>The system should tolerate a permanent failure of any single hardware
dependency and automatically fail-over within reasonable time.</p>
</li>
</ol>
<p>It&#39;s not feasible to meet all of those requirements without relying on some
battle-tested distributed services or frameworks.</p>
<p>Which options do I know of?</p>
<h2 id="transactions">Transactions</h2>
<p>Traditionally, this kind of requirements were solved by using transactions
in something like SQL Server. If I store requests, TODO&#39;s and current ID per
project in the same relational database, I can make each processing step a
single atomic transaction. </p>
<p>This addresses all the concerns, as long as we can stay inside the single 
database. That&#39;s probably a viable option for the TODO app, but less of so
if I convert my toy example to some real applications like IoT data 
processing.</p>
<p>Can we do the same for distributed systems at scale?</p>
<h2 id="azure-event-hubs">Azure Event Hubs</h2>
<p>Since I touched IoT space, the logical choice would be to store our entries
in Azure Event Hubs. That works for many criteria, but I don&#39;t see any available
approach to make such processing consistent in the face of failures.</p>
<p>When processing is done, we need to store 3 pieces: generated TODO event,
current processing offset and current ID. Event goes to another event hub,
processing offset is stored in Blob Storage and ID can be saved to something
like Table Storage. </p>
<p>But there&#39;s no way to store those 3 pieces atomically. Whichever order we 
choose, we are bound to get anomalies in some specific failure modes.</p>
<h2 id="azure-functions">Azure Functions</h2>
<p>Azure Functions don&#39;t solve those problems. But I want to mention this
Function-as-a-Service offering because they provide an ideal programming
model for my use case.</p>
<p>I need to take just one step from my domain function to Azure Function: 
to define bindings for e.g. Event Hubs and Table Storage.</p>
<p>However, reliability guarantees will stay poor. I won&#39;t get neither sequential
processing per Event Hub partition key, nor atomic state commit.</p>
<h2 id="azure-service-fabric">Azure Service Fabric</h2>
<p>Service Fabric sounds like a good candidate service for reliable processing. 
Unfortunately, I don&#39;t have much experience with it to judge.</p>
<p>Please leave a comment if you do.</p>
<h2 id="jvm-world">JVM World</h2>
<p>There are products in JVM world which claim to solve my problem perfectly.</p>
<p>Apache Kafka was the inspiration for Event Hubs log-based messaging. The recent
Kafka release provides effectively-once processing semantics as long as
data stay inside Kafka. Kafka does that with atomic publishing to multiple
topics, and state storage based on compacted topics.</p>
<p>Apache Flink has similar guarantees for its stream processing APIs.</p>
<p>Great, but how do I get such awesomeness in .NET code, and without installing 
expensive ZooKeeper-managed clusters?</p>
<h2 id="call-for-feedback">Call for Feedback</h2>
<p>Do you know a solution, product or service?</p>
<p>Have you developed effectively-once processing on .NET / Azure stack?</p>
<p>Are you in touch with somebody who works on such framework?</p>
<p>Please leave a comment, or ping me on Twitter.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/architecture/'>Architecture</a>, <a href='/tags/data-processing/'>Data Processing</a>, <a href='/tags/stream-processing/'>Stream Processing</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Aug 31st, 2017</div>
    
    <h1><a href='/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic/'>Azure Functions: Are They Really Infinitely Scalable and Elastic?</a></h1>
    
    <div class="post-content">
        <p><em>Updated results are available at 
<a href="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic/">Azure Functions Get More Scalable and Elastic</a>.</em></p>
<p>Automatic elastic scaling is a built-in feature of Serverless computing
paradigm. One doesn&#39;t have to provision servers anymore, they just need to
write code that will be provisioned on as many servers as needed based on the
actual load. That&#39;s the theory.</p>
<p>In particular, Azure Functions can be hosted on the Consumption plan:</p>
<blockquote>
<p>The Consumption plan automatically allocates compute power when your 
code is running, scales out as necessary to handle load, and then scales 
down when code is not running.</p>
</blockquote>
<p>In this post I will run a simple stress test to get a feel of how such
automatic allocation works in practice and what kind of characteristics 
we can rely on.</p>
<h2 id="setup">Setup</h2>
<p>Here are the parameters that I chose for my test of today:</p>
<ul>
<li>Azure Function written in C# and hosted on Consumption plan</li>
<li>Triggered by Azure Storage Queue binding</li>
<li>Workload is strictly CPU-bound, no I/O is executed</li>
</ul>
<p>Specifically, each queue item represents one password that I need to hash.
Each function call performs 12-round <a href="https://en.wikipedia.org/wiki/Bcrypt">Bcrypt</a>
hashing. Bcrypt is a slow algorithm recommended for
password hashing, because it makes potential hash collision attacks really 
hard and costly.</p>
<p>My function is based on <a href="https://github.com/BcryptNet/bcrypt.net">Bcrypt.Net</a>
implementation, and it&#39;s extremely simple:</p>
<pre><code class="lang-csharp">public static void Run([QueueTrigger(&quot;bcrypt-password&quot;)] string password)
{
    BCrypt.Net.BCrypt.HashPassword(password, 12);
}
</code></pre>
<p>It turns out that a single execution of this function takes approximately
1 second on an instance of Consumption plan, and consumes 100% CPU during
that second.</p>
<p>Now, the challenge is simple. I send 100,000 passwords
to the queue and see how long it will take to hash them, and also how the
autoscaling will behave. I will run it two times, with different pace of
sending messages to the queue.</p>
<p>That sounds like a perfect job for a Function App on Consumption plan:</p>
<ul>
<li>Needs to scale based on load</li>
<li>CPU intensive - easy to see how busy each server is</li>
<li>Queue-based - easy to see the incoming vs outgoing rate</li>
</ul>
<p>Let&#39;s see how it went.</p>
<h2 id="experiment-1-steady-load">Experiment 1: Steady Load</h2>
<p>In my first run, I was sending messages at constant rate. 100,000 messages
were sent within 2 hours, without spikes or drops in the pace.</p>
<p>Sounds like an easy job for autoscaling facilities. But here is the actual 
chart of data processing:</p>
<p><img src="/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//FunctionAppScaling.png" alt="Function App Scaling"></p>
<p>The horizontal axis is time in minutes since the first message came in.</p>
<p>The orange line shows the queue backlog - the amount of messages sitting in
the queue at a given moment.</p>
<p>The blue area represents the amount of instances (virtual servers) allocated
to the function by Azure runtime (see the numbers at the right side).</p>
<p>We can divide the whole process into 3 logical segments, approximately 
40 minutes each:</p>
<p><strong>Laging behind</strong>. Runtime starts with 0 instances, and immediately switches
to 1 when the first message comes in. However it&#39;s reluctant to add any more
servers for the next 20 (!) minutes. The scaling heuristic is probably based
on the past history for this queue/function, and it wasn&#39;t busy at all during
the hours before.</p>
<p>After 20 minutes, the runtime starts adding more instances: it goes up to 2, 
then jumps to 4, then reaches 5 at minute 40. The CPU is constantly at 
100% and the queue backlog grows linearly.</p>
<p><strong>Rapid scale up</strong>. After minute 40, it looks like the runtime realizes 
that it needs more power. Much more power! The growth speeds up real quick
and by minute 54 the backlog stops growing, even though the messages are still
coming in. But there are now 21 instances working, which is enough to
finally match and beat the rate of incoming messages.</p>
<p>The runtime doesn&#39;t stop growing though. CPU&#39;s are still at 100%, and the backlog
is still very high, so the scaling goes up and up. The amount of instances
reaches astonishing 55, at which point all the backlog is processed and
there are no messages in the queue.</p>
<p><strong>Searching for balance</strong>. When queue is almost empty and CPU drops below
100% for the first time, the runtime decides to scale down. It does that quickly
and aggressively, switching from 55 to 21 instances in just 2 minutes.</p>
<p>From there it keeps slowly reducing the number of instances until the backlog 
starts growing again. The runtime allows the backlog to grow a bit, but
then figures out a balanced number of servers (17) to keep the backlog flat 
at around 2,000 messages. </p>
<p>It stays at 17 until the producer stops sending new messages. The backlog 
goes to 0, and the amount of instances gradually drops to 0 within 10 minutes.</p>
<p>The second chart from the same experiment looks very similar, but it shows
different metrics:</p>
<p><img src="/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//FunctionAppDelay.png" alt="Function App Delay"></p>
<p>The gray line is the delay in minutes since the currently processed message
got enqueued (message &quot;age&quot;, in-queue latency). The blue line is the 
total processing rate, measured in messages per minute.</p>
<p>Due to perfect scalability and stability of my function, both charts are almost
exactly the same. I&#39;ve put it here so that you could see that the slowest
message spent more than 40 minutes sitting inside the queue.</p>
<h2 id="experiment-2-spiky-load">Experiment 2: Spiky Load</h2>
<p>With the second run, I tried to emulate a spiky load profile. I was sending
my 100,000 messages throughout 6 hours at lower pace than during the first
run. But sometimes the producer switched to fast mode and sent a bigger bunch
of messages in just several minutes. Here is the actual chart of incoming
message rate:</p>
<p><img src="/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//SpikyLoad.png" alt="Spiky Load"></p>
<p>It&#39;s easy to imagine some service which has a usage pattern like that, when
spikes of the events happen from time to time, or in rush hours.</p>
<p>This is how the Function App managed to process the messages:</p>
<p><img src="/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//SpikyLoadProcessing.png" alt="Spiky Load Processing Result"></p>
<p>The green line still shows the amount of incoming messages per minute. The 
blue line denotes how many messages were actually processed at that minute.
And the orange bars are queue backlogs - the amount of messages pending.</p>
<p>Here are several observations:</p>
<ul>
<li><p>Obviously, processing latency is way too far from real time. There is
constantly quite a significant backlog in the queue, and processing delay
reaches 20 minutes at peak.</p>
</li>
<li><p>It took the runtime 2 hours to clean the backlog for the first time. Even
without any spikes during the first hour, the autoscaling algorithm needs
time to get up to speed.</p>
</li>
<li><p>Function App runtime is able to scale up quite fast (look at the reaction
on the fourth spike), but it&#39;s not really willing to do that most of the time.</p>
</li>
<li><p>The growth of the backlog after minute 280 is purely caused by wrong
decision of runtime. While the load is completely steady, the runtime
decided to shut down most workers after 20 minutes of empty backlog, and could
not recover for the next hour.</p>
</li>
</ul>
<h2 id="conclusions">Conclusions</h2>
<p>I tried to get a feeling about the ability of Azure Functions to scale
on demand, adapting to the workload. The function under test was purely CPU-bound,
and for that I can give two main conclusions:</p>
<ul>
<li><p>Function Apps are able to scale to high amount of instances running at the
same time, and to eventually process large parallel jobs (at least up to 55
instances).</p>
</li>
<li><p>Significant processing delays are to be expected for heavy loads. Function
App runtime has quite some inertia, and the resulting processing latency can
easily go up to tens of minutes.</p>
</li>
</ul>
<p>If you know how these results can be improved, or why they are less than 
optimal, please leave a comment or contact me directly.</p>
<p>I look forward to conducting more tests in the future!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/scalability/'>Scalability</a>
    </div>
    
</article>


<div class="page-nav">
    
    <a class="page-nav-newer" href="/2/">&lt;&lt; Previous page</a>
    
    
    <a class="page-nav-older" href="/4/">Next page &gt;&gt;</span></a>
    
</div>

<div id="me">
    <p itemscope itemtype="http://data-vocabulary.org/Person">
        <img src="/images/Headshot-Square.jpg" alt="Mikhail Shilkov" itemprop="photo" />
        I'm <b><span itemprop="name">Mikhail Shilkov</span></b>, a <span itemprop="title">software developer</span>. I enjoy F#, C#, Javascript and SQL development, reasoning about distributed systems, data processing pipelines, cloud and web apps. I blog about my experience on this website.
    </p>
    <p>
        <a href="https://www.linkedin.com/in/mikhailshilkov/">LinkedIn</a> &#8226;
        <a href="https://twitter.com/mikhailshilkov">@mikhailshilkov</a> &#8226;
        <a href="https://github.com/mikhailshilkov">GitHub</a> &#8226;
        <a href="https://stackoverflow.com/users/1171619/mikhail">Stack Overflow</a>
    </p>
</div>

</div>
<div class="container">
    <div class="navbar navbar-footer">
        <p class="navbar-center navbar-text">Content copyright &copy; 2018 Mikhail Shilkov</p>
    </div>
</div>



<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.pack.js"></script>
<script src="/vendor/prism.js"></script>
<script src="/site.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59218480-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>