<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="content-type" content="text/html; charset=utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>

    <meta name="description" content="Software development using .NET, C#, SQL, Javascript and related technologies" />

    <title>Mikhail Shilkov</title>
    <meta name="author" content="Mikhail Shilkov">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link href="/feed/" rel="alternate" title="mikhail.io" type="application/atom+xml">
    <link href="/favicon.ico?v=2" rel="shortcut icon">

    <!-- Bootstrap -->
    <link href="/styles/site.css" rel="stylesheet" media="screen">

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="/scripts/vendor/html5shiv.js"></script>
    <script src="/scripts/vendor/respond.min.js"></script>
    <![endif]-->

    <meta name="generator" content="DocPad v6.78.6" />
    
</head>
<body>

<div class="navbar navbar-default navbar-static-top">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">
                <span class="text-primary">Mikhail Shilkov</span><br />
                <span class="elevator-pitch">F#, C#, JS, SQL, Azure programmer</span>
            </a>
        </div>
        <div class="collapse navbar-collapse navbar-right">
            <ul class="nav navbar-nav">
                <!--<li><a href="/">Blog</a></li>-->
                
                    <li><a href="/tags/">Topics</a></li>
                
                    <li><a href="/archives/">Archives</a></li>
                
                    <li><a href="/talks/">Talks</a></li>
                
                    <li><a href="/about/">About</a></li>
                
                <li class="hidden-xs">
                    <a href="/feed/" class="rss"><span class="icon icon-feed"></span></a>
                    <a href="https://www.linkedin.com/in/mikhailshilkov" class="linkedin"><span class="icon icon-linkedin"></span></a>
                    <a href="https://twitter.com/mikhailshilkov" class="twitter"><span class="icon icon-twitter"></span></a>
                    <a href="https://github.com/mikhailshilkov" class="github"><span class="icon icon-github"></span></a>
                </li>
            </ul>
            <form class="navbar-form navbar-right hidden-xs" role="search" action="https://google.com/search"
                  method="get">
                <div class="form-group">
                    <input type="search" name="q" class="form-control" placeholder="Search">
                    <input type="hidden" name="q" value="site:mikhail.io">
                </div>
            </form>
        </div>
    </div>
</div>
<div class="container">
    
    <article class="post">
    <div class="post-date">Oct 5th, 2017</div>
    
    <h1><a href='/2017/10/azure-function-triggered-by-azure-event-grid/'>Azure Function Triggered by Azure Event Grid</a></h1>
    
    <div class="post-content">
        <p><em>Update: I missed the elephant in the room. There actually exists a specialized
trigger for Event Grid binding. In the portal, just select <code>Experimental</code>
in <code>Scenario</code> drop down while creating the function. In precompiled 
functions, reference <code>Microsoft.Azure.WebJobs.Extensions.EventGrid</code> NuGet
package.</em></p>
<p><em>The rest of the article describes my original approach to trigger an
Azure Function from <a href="https://azure.microsoft.com/en-us/services/event-grid/">Azure Event Grid</a> 
with generic Web Hook trigger.</em></p>
<p>Here are the steps to follow:</p>
<h2 id="create-a-function-with-webhook-trigger">Create a Function with Webhook Trigger</h2>
<p>I&#39;m not aware of a specialized trigger type for Event Grid, so
I decided to use Generic Webhook trigger (which is essentially an
HTTP trigger).</p>
<p>I used the Azure Portal to generate a function, so here is the 
<code>function.json</code> that I got:</p>
<pre class="highlight"><code class="hljs json">{
  <span class="hljs-attr">"bindings"</span>: [
    {
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"httpTrigger"</span>,
      <span class="hljs-attr">"direction"</span>: <span class="hljs-string">"in"</span>,
      <span class="hljs-attr">"webHookType"</span>: <span class="hljs-string">"genericJson"</span>,
      <span class="hljs-attr">"name"</span>: <span class="hljs-string">"req"</span>
    },
    {
      <span class="hljs-attr">"type"</span>: <span class="hljs-string">"http"</span>,
      <span class="hljs-attr">"direction"</span>: <span class="hljs-string">"out"</span>,
      <span class="hljs-attr">"name"</span>: <span class="hljs-string">"res"</span>
    }
  ],
  <span class="hljs-attr">"disabled"</span>: <span class="hljs-literal">false</span>
}
</code></pre>
<p>For precompiled functions, just decorate it with <code>HttpTriggerAttribute</code> with
POST method:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> Task&lt;HttpResponseMessage&gt; <span class="hljs-title">Run</span>(<span class="hljs-params">
    [HttpTrigger(AuthorizationLevel.Function, <span class="hljs-string">"post"</span></span>)] HttpRequestMessage req)
</span></code></pre>
<h2 id="parse-the-payload">Parse the Payload</h2>
<p>Events from Event Grid will arrive in a specific predefined JSON format.
Here is an example of events to expect:</p>
<pre class="highlight"><code class="hljs json">[{
  <span class="hljs-attr">"id"</span>: <span class="hljs-string">"0001"</span>,
  <span class="hljs-attr">"eventType"</span>: <span class="hljs-string">"MyHelloWorld"</span>,
  <span class="hljs-attr">"subject"</span>: <span class="hljs-string">"Hello World!"</span>,
  <span class="hljs-attr">"eventTime"</span>: <span class="hljs-string">"2017-10-05T08:53:07"</span>,
  <span class="hljs-attr">"data"</span>: {
    <span class="hljs-attr">"hello"</span>: <span class="hljs-string">"world"</span>
  },
  <span class="hljs-attr">"topic"</span>: <span class="hljs-string">"/SUBSCRIPTIONS/GUID/RESOURCEGROUPS/NAME/PROVIDERS/MICROSOFT.EVENTGRID/TOPICS/MY-EVENTGRID-TOPIC1"</span>
}]
</code></pre>
<p>To be able to parse those data more easily, I defined a C# class to deserialize
JSON to:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">GridEvent</span>
{
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Id { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> EventType { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Subject { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> DateTime EventTime { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> Dictionary&lt;<span class="hljs-keyword">string</span>, <span class="hljs-keyword">string</span>&gt; Data { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Topic { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}
</code></pre>
<p>Now, the function can read the events (note, that they are sent in arrays)
from the body of POST request:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;HttpResponseMessage&gt; <span class="hljs-title">Run</span>(<span class="hljs-params">HttpRequestMessage req, TraceWriter log</span>)
</span>{
    <span class="hljs-keyword">string</span> jsonContent = <span class="hljs-keyword">await</span> req.Content.ReadAsStringAsync();
    <span class="hljs-keyword">var</span> events = JsonConvert.DeserializeObject&lt;GridEvent[]&gt;(jsonContent);

    <span class="hljs-comment">// do something with events</span>

    <span class="hljs-keyword">return</span> req.CreateResponse(HttpStatusCode.OK);
}
</code></pre>
<h2 id="validate-the-endpoint">Validate the Endpoint</h2>
<p>To prevent you from sending events to endpoints that you don&#39;t own, Event
Grid requires each subsriber to validate itself. For this purpose, Event
Grid will send events of the special type <code>SubscriptionValidation</code>. </p>
<p>The validation request will contain a code, which we need to echo back in
200-OK HTTP response. </p>
<p>Here is a small piece of code to do just that:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">if</span> (req.Headers.GetValues(<span class="hljs-string">"Aeg-Event-Type"</span>).FirstOrDefault() == <span class="hljs-string">"SubscriptionValidation"</span>)
{
    <span class="hljs-keyword">var</span> code = events[<span class="hljs-number">0</span>].Data[<span class="hljs-string">"validationCode"</span>];
    <span class="hljs-keyword">return</span> req.CreateResponse(HttpStatusCode.OK,
        <span class="hljs-keyword">new</span> { validationResponse = code });
}
</code></pre>
<p>The function is ready!</p>
<h2 id="create-a-custom-event-grid-topic">Create a Custom Event Grid Topic</h2>
<p>To test it out, go to the portal and create a custom Event Grid topic.
Then click on Add Event Subscription button, give it a name and copy paste
the function URL (including key) to Subscriber Endpoint field:</p>
<p><img src="/2017/10/azure-function-triggered-by-azure-event-grid//function-url.png" alt="Azure Function URL"></p>
<p><img src="/2017/10/azure-function-triggered-by-azure-event-grid//event-subscription.png" alt="Event Grid Subscription"></p>
<p>Creating a subscription will immediately trigger a validation request to
your function, so you should see one invocation in the logs.</p>
<h2 id="send-custom-events">Send Custom Events</h2>
<p>Now, go to your favorite HTTP client (curl, Postman, etc) and send a sample
event to check how the whole setup works:</p>
<pre class="highlight"><code class="hljs http"><span class="hljs-keyword">POST</span> <span class="hljs-string">/api/events</span> HTTP/1.1
<span class="hljs-attribute">Host</span>: &lt;your-eventgrid-topic&gt;.westus2-1.eventgrid.azure.net
<span class="hljs-attribute">aeg-sas-key</span>: &lt;key&gt;
<span class="hljs-attribute">Content-Type</span>: application/json

<span class="json">[{
  <span class="hljs-attr">"id"</span>: <span class="hljs-string">"001"</span>,
  <span class="hljs-attr">"eventType"</span>: <span class="hljs-string">"MyHelloWorld"</span>,
  <span class="hljs-attr">"subject"</span>: <span class="hljs-string">"Hello World!"</span>,
  <span class="hljs-attr">"eventTime"</span>: <span class="hljs-string">"2017-10-05T08:53:07"</span>,
  <span class="hljs-attr">"data"</span>: {
    <span class="hljs-attr">"hello"</span>: <span class="hljs-string">"world"</span>
  }
}]
</span></code></pre>
<p>Obviously, adjust the endpoint and key based on the data from the portal.</p>
<p>You should get a 200-OK back and then see your event in Azure Function 
invocation logs.</p>
<p>Have fun!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/azure-event-grid/'>Azure Event Grid</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Sep 25th, 2017</div>
    
    <h1><a href='/2017/09/wanted-effectively-once-processing-in-azure/'>Wanted: Effectively-Once Processing in Azure</a></h1>
    
    <div class="post-content">
        <p><em>This experimental post is a question. The question
is too broad for StackOverflow, so I&#39;m posting it here. Please engage in the
comments section, or forward the link to subject experts.</em></p>
<p>TL;DR: Are there any known patterns / tools / frameworks to provide 
scalable, stateful, effectively-once, end-to-end processing of messages, 
to be hosted in Azure, preferably on PaaS-level of service?</p>
<h2 id="motivational-example">Motivational Example</h2>
<p>Let&#39;s say we are making a TODO app. There is a constant flow of requests
to create a TODO in the system. Each request contains just two fields:
a title and a project ID which TODO should belong to. Here is the definition:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">TodoRequest</span> </span>= {
  ProjectId: int
  Title: string
}
</code></pre>
<p>Now, we want to process the request and assign each TODO an identifier,
which should be an auto-incremented integer. Numeration is unique per project,
so each TODO must have its own combination of <code>ProjectId</code> and <code>Id</code>:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-class"><span class="hljs-keyword">type</span> <span class="hljs-title">Todo</span> </span>= {
  ProjectId: int
  Id: int
  Title: string
}
</code></pre>
<p>Now, instead of relying on some database sequences, I want to describe this
transformation as a function. The function has the type <code>(TodoRequest, int) -&gt;
(Todo, int)</code>, i.e. it transforms a tuple of a request and current per-project
state (last generated ID) to a tuple of a TODO and post-processing state:</p>
<pre class="highlight"><code class="hljs fs"><span class="hljs-keyword">let</span> create (request: TodoRequest, state: int) =
  <span class="hljs-keyword">let</span> nextId = state + <span class="hljs-number">1</span>
  <span class="hljs-keyword">let</span> todo = {
    ProjectId = request.ProjectId
    Id = nextId
    Title = request.Title
  }
  todo, nextId
</code></pre>
<p>This is an extremely simple function, and I can use it to great success to
process local, non-durable data.</p>
<p>But if I need to make a reliable distributed application out of it, I need
to take care of lots of things:</p>
<ol>
<li><p>No request should be lost. I need to persist all the requests into 
a durable storage in case of processor crash. </p>
</li>
<li><p>Similarly, I need to persist TODO&#39;s too. Presumably, some downstream 
logic will use the persisted data later on in TODO&#39;s lifecycle.</p>
</li>
<li><p>The state (the counter) must be durable too. In case of crash of processing
function, I want to be able to restart processing after recovery. </p>
</li>
<li><p>Processing of the requests should be sequential per project ID. Otherwise
I might get a clash of ID&#39;s in case two requests belonging to the same 
project are processed concurrently.</p>
</li>
<li><p>I still want requests to different projects to be processed in parallel,
to make sure the system scales up with the growth of project count.</p>
</li>
<li><p>There must be no holes or duplicates in TODO numbering per project, even
in face of system failures. In worst case, I agree to tolerate a duplicated
entry in the output log, but it must be exactly the same entry (i.e. two 
entries with same project id, id and title).</p>
</li>
<li><p>The system should tolerate a permanent failure of any single hardware
dependency and automatically fail-over within reasonable time.</p>
</li>
</ol>
<p>It&#39;s not feasible to meet all of those requirements without relying on some
battle-tested distributed services or frameworks.</p>
<p>Which options do I know of?</p>
<h2 id="transactions">Transactions</h2>
<p>Traditionally, this kind of requirements were solved by using transactions
in something like SQL Server. If I store requests, TODO&#39;s and current ID per
project in the same relational database, I can make each processing step a
single atomic transaction. </p>
<p>This addresses all the concerns, as long as we can stay inside the single 
database. That&#39;s probably a viable option for the TODO app, but less of so
if I convert my toy example to some real applications like IoT data 
processing.</p>
<p>Can we do the same for distributed systems at scale?</p>
<h2 id="azure-event-hubs">Azure Event Hubs</h2>
<p>Since I touched IoT space, the logical choice would be to store our entries
in Azure Event Hubs. That works for many criteria, but I don&#39;t see any available
approach to make such processing consistent in the face of failures.</p>
<p>When processing is done, we need to store 3 pieces: generated TODO event,
current processing offset and current ID. Event goes to another event hub,
processing offset is stored in Blob Storage and ID can be saved to something
like Table Storage. </p>
<p>But there&#39;s no way to store those 3 pieces atomically. Whichever order we 
choose, we are bound to get anomalies in some specific failure modes.</p>
<h2 id="azure-functions">Azure Functions</h2>
<p>Azure Functions don&#39;t solve those problems. But I want to mention this
Function-as-a-Service offering because they provide an ideal programming
model for my use case.</p>
<p>I need to take just one step from my domain function to Azure Function: 
to define bindings for e.g. Event Hubs and Table Storage.</p>
<p>However, reliability guarantees will stay poor. I won&#39;t get neither sequential
processing per Event Hub partition key, nor atomic state commit.</p>
<h2 id="azure-service-fabric">Azure Service Fabric</h2>
<p>Service Fabric sounds like a good candidate service for reliable processing. 
Unfortunately, I don&#39;t have much experience with it to judge.</p>
<p>Please leave a comment if you do.</p>
<h2 id="jvm-world">JVM World</h2>
<p>There are products in JVM world which claim to solve my problem perfectly.</p>
<p>Apache Kafka was the inspiration for Event Hubs log-based messaging. The recent
Kafka release provides effectively-once processing semantics as long as
data stay inside Kafka. Kafka does that with atomic publishing to multiple
topics, and state storage based on compacted topics.</p>
<p>Apache Flink has similar guarantees for its stream processing APIs.</p>
<p>Great, but how do I get such awesomeness in .NET code, and without installing 
expensive ZooKeeper-managed clusters?</p>
<h2 id="call-for-feedback">Call for Feedback</h2>
<p>Do you know a solution, product or service?</p>
<p>Have you developed effectively-once processing on .NET / Azure stack?</p>
<p>Are you in touch with somebody who works on such framework?</p>
<p>Please leave a comment, or ping me on Twitter.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/architecture/'>Architecture</a>, <a href='/tags/data-processing/'>Data Processing</a>, <a href='/tags/stream-processing/'>Stream Processing</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Aug 31st, 2017</div>
    
    <h1><a href='/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic/'>Azure Functions: Are They Really Infinitely Scalable and Elastic?</a></h1>
    
    <div class="post-content">
        <p><em>Updated results are available at 
<a href="https://mikhail.io/2017/12/azure-functions-get-more-scalable-and-elastic/">Azure Functions Get More Scalable and Elastic</a>.</em></p>
<p>Automatic elastic scaling is a built-in feature of Serverless computing
paradigm. One doesn&#39;t have to provision servers anymore, they just need to
write code that will be provisioned on as many servers as needed based on the
actual load. That&#39;s the theory.</p>
<p>In particular, Azure Functions can be hosted on the Consumption plan:</p>
<blockquote>
<p>The Consumption plan automatically allocates compute power when your 
code is running, scales out as necessary to handle load, and then scales 
down when code is not running.</p>
</blockquote>
<p>In this post I will run a simple stress test to get a feel of how such
automatic allocation works in practice and what kind of characteristics 
we can rely on.</p>
<h2 id="setup">Setup</h2>
<p>Here are the parameters that I chose for my test of today:</p>
<ul>
<li>Azure Function written in C# and hosted on Consumption plan</li>
<li>Triggered by Azure Storage Queue binding</li>
<li>Workload is strictly CPU-bound, no I/O is executed</li>
</ul>
<p>Specifically, each queue item represents one password that I need to hash.
Each function call performs 12-round <a href="https://en.wikipedia.org/wiki/Bcrypt">Bcrypt</a>
hashing. Bcrypt is a slow algorithm recommended for
password hashing, because it makes potential hash collision attacks really 
hard and costly.</p>
<p>My function is based on <a href="https://github.com/BcryptNet/bcrypt.net">Bcrypt.Net</a>
implementation, and it&#39;s extremely simple:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Run</span>(<span class="hljs-params">[QueueTrigger(<span class="hljs-string">"bcrypt-password"</span></span>)] <span class="hljs-keyword">string</span> password)
</span>{
    BCrypt.Net.BCrypt.HashPassword(password, <span class="hljs-number">12</span>);
}
</code></pre>
<p>It turns out that a single execution of this function takes approximately
1 second on an instance of Consumption plan, and consumes 100% CPU during
that second.</p>
<p>Now, the challenge is simple. I send 100,000 passwords
to the queue and see how long it will take to hash them, and also how the
autoscaling will behave. I will run it two times, with different pace of
sending messages to the queue.</p>
<p>That sounds like a perfect job for a Function App on Consumption plan:</p>
<ul>
<li>Needs to scale based on load</li>
<li>CPU intensive - easy to see how busy each server is</li>
<li>Queue-based - easy to see the incoming vs outgoing rate</li>
</ul>
<p>Let&#39;s see how it went.</p>
<h2 id="experiment-1-steady-load">Experiment 1: Steady Load</h2>
<p>In my first run, I was sending messages at constant rate. 100,000 messages
were sent within 2 hours, without spikes or drops in the pace.</p>
<p>Sounds like an easy job for autoscaling facilities. But here is the actual 
chart of data processing:</p>
<p><img src="/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//FunctionAppScaling.png" alt="Function App Scaling"></p>
<p>The horizontal axis is time in minutes since the first message came in.</p>
<p>The orange line shows the queue backlog - the amount of messages sitting in
the queue at a given moment.</p>
<p>The blue area represents the amount of instances (virtual servers) allocated
to the function by Azure runtime (see the numbers at the right side).</p>
<p>We can divide the whole process into 3 logical segments, approximately 
40 minutes each:</p>
<p><strong>Laging behind</strong>. Runtime starts with 0 instances, and immediately switches
to 1 when the first message comes in. However it&#39;s reluctant to add any more
servers for the next 20 (!) minutes. The scaling heuristic is probably based
on the past history for this queue/function, and it wasn&#39;t busy at all during
the hours before.</p>
<p>After 20 minutes, the runtime starts adding more instances: it goes up to 2, 
then jumps to 4, then reaches 5 at minute 40. The CPU is constantly at 
100% and the queue backlog grows linearly.</p>
<p><strong>Rapid scale up</strong>. After minute 40, it looks like the runtime realizes 
that it needs more power. Much more power! The growth speeds up real quick
and by minute 54 the backlog stops growing, even though the messages are still
coming in. But there are now 21 instances working, which is enough to
finally match and beat the rate of incoming messages.</p>
<p>The runtime doesn&#39;t stop growing though. CPU&#39;s are still at 100%, and the backlog
is still very high, so the scaling goes up and up. The amount of instances
reaches astonishing 55, at which point all the backlog is processed and
there are no messages in the queue.</p>
<p><strong>Searching for balance</strong>. When queue is almost empty and CPU drops below
100% for the first time, the runtime decides to scale down. It does that quickly
and aggressively, switching from 55 to 21 instances in just 2 minutes.</p>
<p>From there it keeps slowly reducing the number of instances until the backlog 
starts growing again. The runtime allows the backlog to grow a bit, but
then figures out a balanced number of servers (17) to keep the backlog flat 
at around 2,000 messages. </p>
<p>It stays at 17 until the producer stops sending new messages. The backlog 
goes to 0, and the amount of instances gradually drops to 0 within 10 minutes.</p>
<p>The second chart from the same experiment looks very similar, but it shows
different metrics:</p>
<p><img src="/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//FunctionAppDelay.png" alt="Function App Delay"></p>
<p>The gray line is the delay in minutes since the currently processed message
got enqueued (message &quot;age&quot;, in-queue latency). The blue line is the 
total processing rate, measured in messages per minute.</p>
<p>Due to perfect scalability and stability of my function, both charts are almost
exactly the same. I&#39;ve put it here so that you could see that the slowest
message spent more than 40 minutes sitting inside the queue.</p>
<h2 id="experiment-2-spiky-load">Experiment 2: Spiky Load</h2>
<p>With the second run, I tried to emulate a spiky load profile. I was sending
my 100,000 messages throughout 6 hours at lower pace than during the first
run. But sometimes the producer switched to fast mode and sent a bigger bunch
of messages in just several minutes. Here is the actual chart of incoming
message rate:</p>
<p><img src="/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//SpikyLoad.png" alt="Spiky Load"></p>
<p>It&#39;s easy to imagine some service which has a usage pattern like that, when
spikes of the events happen from time to time, or in rush hours.</p>
<p>This is how the Function App managed to process the messages:</p>
<p><img src="/2017/08/azure-functions-are-they-really-infinitely-scalable-and-elastic//SpikyLoadProcessing.png" alt="Spiky Load Processing Result"></p>
<p>The green line still shows the amount of incoming messages per minute. The 
blue line denotes how many messages were actually processed at that minute.
And the orange bars are queue backlogs - the amount of messages pending.</p>
<p>Here are several observations:</p>
<ul>
<li><p>Obviously, processing latency is way too far from real time. There is
constantly quite a significant backlog in the queue, and processing delay
reaches 20 minutes at peak.</p>
</li>
<li><p>It took the runtime 2 hours to clean the backlog for the first time. Even
without any spikes during the first hour, the autoscaling algorithm needs
time to get up to speed.</p>
</li>
<li><p>Function App runtime is able to scale up quite fast (look at the reaction
on the fourth spike), but it&#39;s not really willing to do that most of the time.</p>
</li>
<li><p>The growth of the backlog after minute 280 is purely caused by wrong
decision of runtime. While the load is completely steady, the runtime
decided to shut down most workers after 20 minutes of empty backlog, and could
not recover for the next hour.</p>
</li>
</ul>
<h2 id="conclusions">Conclusions</h2>
<p>I tried to get a feeling about the ability of Azure Functions to scale
on demand, adapting to the workload. The function under test was purely CPU-bound,
and for that I can give two main conclusions:</p>
<ul>
<li><p>Function Apps are able to scale to high amount of instances running at the
same time, and to eventually process large parallel jobs (at least up to 55
instances).</p>
</li>
<li><p>Significant processing delays are to be expected for heavy loads. Function
App runtime has quite some inertia, and the resulting processing latency can
easily go up to tens of minutes.</p>
</li>
</ul>
<p>If you know how these results can be improved, or why they are less than 
optimal, please leave a comment or contact me directly.</p>
<p>I look forward to conducting more tests in the future!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/scalability/'>Scalability</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Jul 26th, 2017</div>
    
    <h1><a href='/2017/07/authoring-custom-binding-azure-functions/'>Authoring a Custom Binding for Azure Functions</a></h1>
    
    <div class="post-content">
        <p>In my <a href="https://mikhail.io/2017/07/custom-autoscaling-with-durable-functions/">previous post</a>
I described how I used Durable Functions extensions
in Azure Function App. Durable Functions are using several binding types
that are not part of the standard suite: <code>OrchestrationClient</code>,
<code>OrchestrationTrigger</code>, <code>ActivityTrigger</code>. These custom bindings 
<a href="https://azure.github.io/azure-functions-durable-extension/articles/installation.html">are installed</a>
by copying the corresponding assemblies to a special Extensions folder.</p>
<p>Although Bring-Your-Own-Binding (BYOB) feature hasn&#39;t been released yet, I
decided to follow the path of Durable Functions and create my own 
custom binding.</p>
<h2 id="configuration-binding">Configuration Binding</h2>
<p>I&#39;ve picked a really simple use case for my first experiments with custom
bindings: reading configuration values.</p>
<p>Azure Functions store their configuration values in App Settings (local
runtime uses <code>local.settings.json</code> file for that).</p>
<p>That means, when you need a configuration value inside your C# code,
you normally do</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">string</span> setting = ConfigurationManager.AppSettings[<span class="hljs-string">"MySetting"</span>];
</code></pre>
<p>Alternatively, <code>Environment.GetEnvironmentVariable()</code> method can be used.</p>
<p>When I <a href="https://mikhail.io/2017/07/custom-auto-scaling-in-azure/">needed to collect</a> 
service bus subscription metrics, I wrote this kind of bulky code:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> resourceToScale = ConfigurationManager.AppSettings[<span class="hljs-string">"ResourceToScale"</span>];

<span class="hljs-keyword">var</span> connectionString = ConfigurationManager.AppSettings[<span class="hljs-string">"ServiceBusConnection"</span>];
<span class="hljs-keyword">var</span> topic = ConfigurationManager.AppSettings[<span class="hljs-string">"Topic"</span>];
<span class="hljs-keyword">var</span> subscription = ConfigurationManager.AppSettings[<span class="hljs-string">"Subscription"</span>];
</code></pre>
<p>The code is no rocket science, but it&#39;s tedious to write, so instead I came
up with this idea to define Functions:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">void</span> <span class="hljs-title">MyFunction</span>(<span class="hljs-params">
    [TimerTrigger(<span class="hljs-string">"0 */1 * * * *"</span></span>)] TimerInfo timer,
    [<span class="hljs-title">Configuration</span>(<span class="hljs-params">Key = <span class="hljs-string">"ResourceToScale"</span></span>)] <span class="hljs-keyword">string</span> resource,
    [Configuration] ServiceBusSubscriptionConfig config)
</span></code></pre>
<p>Note two usages of <code>Configuration</code> attribute. The first one defines the 
specific configuration key, and binds its value to a string parameter. The 
other one binds <em>multiple</em> configuration values to a POCO parameter. I defined
the config class as</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">ServiceBusSubscriptionConfig</span>
{
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-title">ServiceBusSubscriptionConfig</span>(<span class="hljs-params"><span class="hljs-keyword">string</span> serviceBusConnection, <span class="hljs-keyword">string</span> topic, <span class="hljs-keyword">string</span> subscription</span>)
    </span>{
        ServiceBusConnection = serviceBusConnection;
        Topic = topic;
        Subscription = subscription;
    }

    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> ServiceBusConnection { <span class="hljs-keyword">get</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Topic { <span class="hljs-keyword">get</span>; }
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Subscription { <span class="hljs-keyword">get</span>; }
}
</code></pre>
<p>The immutable class is a bit verbose, but I still prefer it over get-set
container in this scenario.</p>
<p>The binding behavior is convention-based in this case: the binding engine
should load configuration values based on the names of class properties.</p>
<h2 id="motivation">Motivation</h2>
<p>So, why do I need such binding?</p>
<p>As I said, it&#39;s a simple use case to play with BYOB feature, and overall,
<strong>understand</strong> the internals of Function Apps a bit better.</p>
<p>But apart from that, I removed 4 lines of garbage from the function body
(at the cost of two extra parameters). <strong>Less noise</strong> means more readable code,
especially when I put this code on a webpage.</p>
<p>As a bonus, the <strong>testability</strong> of the function immediately increased. It&#39;s so
much easier for the test just to accept the configuration as input parameter,
instead of fine-tuning the configuration files inside test projects, or
hiding <code>ConfigurationManager</code> usage behind a mockable facade.</p>
<p>Such approach does seem to be the strength of Azure Functions code in
general. It&#39;s often possible to reduce imperative IO-related code to 
attribute-decorated function parameters.</p>
<h2 id="implementing-a-custom-binding">Implementing a Custom Binding</h2>
<p>The actual implementation process of a custom non-trigger binding is quite
simple:</p>
<p><strong>Create a class library</strong> with the word &quot;Extension&quot; in its name. Import
<code>Microsoft.Azure.WebJobs</code> and <code>Microsoft.Azure.WebJobs.Extensions</code> NuGet
packages (at the time of writing I used <code>2.1.0-beta1</code> version).</p>
<p><strong>Define</strong> a class for binding attribute:</p>
<pre class="highlight"><code class="hljs cs">[<span class="hljs-meta">AttributeUsage(AttributeTargets.Parameter)</span>]
[<span class="hljs-meta">Binding</span>]
<span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">ConfigurationAttribute</span> : <span class="hljs-title">Attribute</span>
{
    [<span class="hljs-meta">AutoResolve</span>]
    <span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> Key { <span class="hljs-keyword">get</span>; <span class="hljs-keyword">set</span>; }
}
</code></pre>
<p>The attribute is marked as <code>Binding</code> and the <code>Key</code> property is marked as
resolvable from <code>function.json</code>.</p>
<p><strong>Implement</strong> <code>IExtensionConfigProvider</code> which will tell the function runtime
how to use your binding correctly.</p>
<p>The interface has just one method to implement:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">public</span> <span class="hljs-keyword">class</span> <span class="hljs-title">ConfigurationExtensionConfigProvider</span> : <span class="hljs-title">IExtensionConfigProvider</span>
{
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title">Initialize</span>(<span class="hljs-params">ExtensionConfigContext context</span>)
    </span>{
        <span class="hljs-comment">// ... see below</span>
    }
}
</code></pre>
<p>The first step of the implementation is to define a rule for our new
<code>ConfigurationAttribute</code> and tell this rule how to get a string value out
of any attribute instance:</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">var</span> rule = context.AddBindingRule&lt;ConfigurationAttribute&gt;();
rule.BindToInput&lt;<span class="hljs-keyword">string</span>&gt;(a =&gt; ConfigurationManager.AppSettings[a.Key]);
</code></pre>
<p>That&#39;s really all that needs to happen to bind <code>string</code> parameters.</p>
<p>To make our binding work with any POCO, we need a more elaborate construct:</p>
<pre class="highlight"><code class="hljs cs">rule.BindToInput&lt;Env&gt;(_ =&gt; <span class="hljs-keyword">new</span> Env());
<span class="hljs-keyword">var</span> cm = context.Config.GetService&lt;IConverterManager&gt;();
cm.AddConverter&lt;Env, OpenType, ConfigurationAttribute&gt;(<span class="hljs-keyword">typeof</span>(PocoConverter&lt;&gt;));
</code></pre>
<p>I instruct the rule to bind to my custom class <code>Env</code>, and then I say that
this class <code>Env</code> is convertable to any type (denoted by special <code>OpenType</code>
type argument) with a generic converter called <code>PocoConverter</code>.</p>
<p>The <code>Env</code> class is a bit dummy (it exists just because I need <em>some</em> class):</p>
<pre class="highlight"><code class="hljs cs"><span class="hljs-keyword">private</span> <span class="hljs-keyword">class</span> <span class="hljs-title">Env</span>
{
    <span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">string</span> <span class="hljs-title">GetValue</span>(<span class="hljs-params"><span class="hljs-keyword">string</span> key</span>) </span>=&gt; ConfigurationManager.AppSettings[key];
}
</code></pre>
<p>And <code>PocoConverter</code> is a piece of reflection, that loops through property
names and reads configuration values out of them. Then it calls a constructor
which matches the property count:</p>
<pre class="highlight"><code class="hljs undefined">private class PocoConverter&lt;T&gt; : IConverter&lt;Env, T&gt;
{
    public T Convert(Env env)
    {
        var values = typeof(T)
            .GetProperties()
            .Select(p =&gt; p.Name)
            .Select(env.GetValue)
            .Cast&lt;object&gt;()
            .ToArray();

        var constructor = typeof(T).GetConstructor(values.Select(v =&gt; v.GetType()).ToArray());
        if (constructor == null)
        {
            throw new Exception("We tried to bind to your C# class, but it looks like there's no constructor which accepts all property values");
        }

        return (T)constructor.Invoke(values);
    }
}
</code></pre>
<p>This piece of code is not particularly robust, but it is good enough to
illustrate the concept.</p>
<p>And that&#39;s it, the binding it ready! You can find the complete example in
<a href="https://github.com/mikhailshilkov/mikhailio-samples/tree/master/custom-binding-azure-functions">my github repo</a>.</p>
<h2 id="deploying-custom-bindings">Deploying Custom Bindings</h2>
<p>Since BYOB feature is in early preview, there is no tooling for automated
deployment, and we need to do everything manually. But the process is not
too sophisticated:</p>
<ol>
<li><p>Create a folder for custom bindings, e.g. <code>D:\BindingExtensions</code>.</p>
</li>
<li><p>Set <code>AzureWebJobs_ExtensionsPath</code> parameter in your app settings
to that folder&#39;s path. For local development add a line to <code>local.settings.json</code>:</p>
<pre class="highlight"><code class="hljs undefined"> "AzureWebJobs_ExtensionsPath": "D:\\BindingExtensions",
</code></pre>
</li>
<li><p>Create a subfolder for your extension, e.g. 
<code>D:\BindingExtensions\ConfigurationExtension</code>.</p>
</li>
<li><p>Copy the contents of <code>bin\Debug\</code> of your extension&#39;s class library
to that folder.</p>
</li>
<li><p>Reference your extension library from your Function App.</p>
</li>
</ol>
<p>You are good to go! Decorate your function parameters with the new attribute.</p>
<p>Run the function app locally to try it out. In the console output you should
be able to see something like</p>
<pre class="highlight"><code class="hljs oxygene">Loaded custom <span class="hljs-keyword">extension</span>: ConfigurationExtensionConfigProvider <span class="hljs-keyword">from</span> 
<span class="hljs-string">'D:\BindingExtensions\ConfigurationExtension\MyExtensions.dll'</span>
</code></pre><p>You will be able to debug your extension if needed.</p>
<h2 id="useful-links">Useful Links</h2>
<p>Use the following links to find out more about custom bindings, see more
examples and walkthroughs, and get fresh updates:</p>
<ul>
<li><a href="https://github.com/Azure/azure-webjobs-sdk/wiki/Extensibility">Extensibility in Azure WebJobs SDK</a></li>
<li><a href="https://github.com/Azure/WebJobsExtensionSamples/tree/master/SampleExtension">Sample Extension for Azure Functions</a>,
<a href="https://github.com/Azure/WebJobsExtensionSamples/blob/master/FunctionApp/ReaderFunction.cs">Sample Usage in Precompiled App</a> and
<a href="https://github.com/Azure/WebJobsExtensionSamples/tree/master/ScriptRuntimeSample/Reader">Sample Usage in Script Runtime</a></li>
<li><a href="https://github.com/Azure/azure-functions-durable-extension/tree/master/src/WebJobs.Extensions.DurableTask">Custom Bindings of Durable Functions</a></li>
<li><a href="https://azure.github.io/azure-functions-durable-extension/articles/installation.html">Installation Guide for Durable Functions</a></li>
</ul>
<p>Have a good binding!</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>
    </div>
    
</article>

    <article class="post">
    <div class="post-date">Jul 24th, 2017</div>
    
    <h1><a href='/2017/07/custom-autoscaling-with-durable-functions/'>Custom Autoscaling with Durable Functions</a></h1>
    
    <div class="post-content">
        <p>In my previous post 
<a href="https://mikhail.io/2017/07/custom-auto-scaling-in-azure/">Custom Autoscaling of Azure App Service with a Function App</a>
I&#39;ve created a Function App which watches a Service Bus Subscription
backlog and adjusts the scale of App Service based on the observed load.</p>
<p>It works fine but there are two minor issues that I would like to address
in this article:</p>
<ul>
<li><p><strong>Scaling Logic</strong> function from that workflow needs to preserve state
between calls. I used Table Storage bindings for that, which proved to
be a bit verbose and low level: I needed to manage conversion to entity and 
JSON serialization myself;</p>
</li>
<li><p>There is no feedback from <strong>Scaler</strong> function (which executes the change)
back to <strong>Scaling Logic</strong> function. Thus, if scaling operation is slow or
fails, there is no easy way to notify the logic about that.</p>
</li>
</ul>
<p>Let&#39;s see how these issues can be solved with Azure Durable Functions.</p>
<h2 id="meet-durable-functions">Meet Durable Functions</h2>
<p>Microsoft has recently announced the preview of 
<a href="https://azure.github.io/azure-functions-durable-extension/">Durable Functions</a>:</p>
<blockquote>
<p>Durable Functions is an Azure Functions extension for building long-running, 
stateful function orchestrations in code using C# in a serverless environment.</p>
</blockquote>
<p>The library is built on top of <a href="https://github.com/Azure/durabletask">Durable Task Framework</a>
and introduces several patterns for Function coordination and stateful
processing. Please go read the <a href="https://azure.github.io/azure-functions-durable-extension/">documentation</a>,
it&#39;s great and has some very useful examples.</p>
<p>I decided to give Durable Functions a try for my autoscaling workflow. Feel
free to refer to <a href="https://mikhail.io/2017/07/custom-auto-scaling-in-azure/">the first part</a>
to understand my goals and the previous implementation.</p>
<h2 id="architecture">Architecture</h2>
<p>The flow of metric collection, scaling logic and scaling action stays the
same. The state and cross-function communication aspects are now delegated
to Durable Functions, so the diagram becomes somewhat simpler:</p>
<p><img src="/2017/07/custom-autoscaling-with-durable-functions//AutoscalingArchitecture.png" alt="Autoscaling Architecture"></p>
<p>The blue sign on <strong>Scaling Logic</strong> function denotes its statefulness.</p>
<p>Let&#39;s walk through the functions implementation to see how the workflow
plays out.</p>
<p>This time I&#39;ll start with <strong>Scaler</strong> function and then flow from right to left
to make the explanation more clear.</p>
<h2 id="scaler">Scaler</h2>
<p><strong>Scaler</strong> function applies the scaling decisions to the Azure resource, App
Service Plan in my case. I&#39;ve extracted App Service related code to a helper, 
to keep the function minimal and clean. You can see the full code in 
<a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/customautoscaling/durable-functions/DurableScaling.cs">my github repo</a>.</p>
<p><strong>Scaler</strong> function is triggered by Durable Function&#39;s <code>ActivityTrigger</code>. That
basically means that it&#39;s ready to be called from other functions. Here is
the code:</p>
<pre class="highlight"><code class="hljs cs">[<span class="hljs-meta">FunctionName(nameof(Scaler))</span>]
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">int</span> <span class="hljs-title">Scaler</span>(<span class="hljs-params">[ActivityTrigger] DurableActivityContext context</span>)
</span>{
    <span class="hljs-keyword">var</span> action = context.GetInput&lt;ScaleAction&gt;();

    <span class="hljs-keyword">var</span> newCapacity = ScalingHelper.ChangeAppServiceInstanceCount(
        action.ResourceName,
        action.Type == ScaleActionType.Down ? <span class="hljs-number">-1</span> : +<span class="hljs-number">1</span>);

    <span class="hljs-keyword">return</span> newCapacity;
}
</code></pre>
<p>In order to receive an input value, I utilize <code>context.GetInput()</code> method.
I believe that the team is working on support of custom classes 
(<code>ScaleAction</code> in my case) directly as function parameters.</p>
<p>The function then executes the scale change and returns back the new capacity
of App Service Plan. Note that this is new: we were not able to return
values in the previous implementation.</p>
<h2 id="scaling-logic">Scaling Logic</h2>
<p><strong>Scaling Logic</strong> is using <a href="https://azure.github.io/azure-functions-durable-extension/articles/samples/counter.html">Stateful Actor pattern</a>.
One instance of such actor is created for each scalable resource (I only use
1 now). Here is the implementation (again, simplified for readability):</p>
<pre class="highlight"><code class="hljs cs">[<span class="hljs-meta">FunctionName(nameof(ScalingLogic))</span>]
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task&lt;ScalingState&gt; <span class="hljs-title">ScalingLogic</span>(<span class="hljs-params">
    [OrchestrationTrigger] DurableOrchestrationContext context, 
    TraceWriter log</span>)
</span>{
    <span class="hljs-keyword">var</span> state = context.GetInput&lt;ScalingState&gt;();

    <span class="hljs-keyword">var</span> metric = <span class="hljs-keyword">await</span> context.WaitForExternalEvent&lt;Metric&gt;(<span class="hljs-keyword">nameof</span>(Metric));

    UpdateHistory(state.History, metric.Value);
    ScaleAction action = CalculateScalingAction(state);

    <span class="hljs-keyword">if</span> (action != <span class="hljs-literal">null</span>)
    {
        <span class="hljs-keyword">var</span> result = <span class="hljs-keyword">await</span> context.CallFunctionAsync&lt;<span class="hljs-keyword">int</span>&gt;(<span class="hljs-keyword">nameof</span>(Scaler), action);
        log.Info(<span class="hljs-string">$"Scaling logic: Scaled to <span class="hljs-subst">{result}</span> instances."</span>);
        state.LastScalingActionTime = context.CurrentUtcDateTime;
    }

    context.ContinueAsNew(state);
    <span class="hljs-keyword">return</span> state;
}
</code></pre>
<p>Here is how it works:</p>
<ul>
<li><p>Function is bound to <code>OrchestrationTrigger</code>, yet another trigger type from
Durable Functions;</p>
</li>
<li><p>It loads durable state from the received <code>context</code>;</p>
</li>
<li><p>It then waits for an external event called Metric (to be sent by <strong>Collector</strong>
function, see the next section);</p>
</li>
<li><p>When an event is received, the function updates its state and calculates
if a scaling action is warranted;</p>
</li>
<li><p>If yes, it calls <strong>Scaler</strong> function and sends the scale action. It expects
an integer result, denoting the new amount of instances;</p>
</li>
<li><p>It then calls <code>ContinueAsNew</code> method to start a new iteration of the actor
loop, providing the updated state.</p>
</li>
</ul>
<p>One important note: the orchestrated function 
<a href="https://azure.github.io/azure-functions-durable-extension/articles/topics/checkpointing-and-replay.html">has to be deterministic</a>. 
That means, for example, that <code>DateTime.Now</code> is not allowed to be used. 
I use <code>context.CurrentUtcDateTime</code> instead for time-related calculations.</p>
<p>The implementation of this function solves both problems that I mentioned 
in the introduction. We do not manage state storage and serialization manually,
and we now have the ability to get feedback from <strong>Scaler</strong> function.</p>
<h2 id="metrics-collector">Metrics Collector</h2>
<p>I&#39;ve extracted Service Bus related code to a helper to keep the code sample
minimal and clean. You can see the full code in 
<a href="https://github.com/mikhailshilkov/mikhailio-samples/blob/master/customautoscaling/durable-functions/DurableScaling.cs">my github repo</a>.</p>
<p>Here is the remaining implementation of <strong>Metric Collector</strong>:</p>
<pre class="highlight"><code class="hljs cs">[<span class="hljs-meta">FunctionName(nameof(MetricCollector))</span>]
<span class="hljs-function"><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">async</span> Task <span class="hljs-title">MetricCollector</span>(<span class="hljs-params">
    [TimerTrigger(<span class="hljs-string">"0 */1 * * * *"</span></span>)] TimerInfo myTimer,
    [OrchestrationClient] DurableOrchestrationClient client,
    TraceWriter log)
</span>{
    <span class="hljs-keyword">var</span> resource = Environment.GetEnvironmentVariable(<span class="hljs-string">"ResourceToScale"</span>);

    <span class="hljs-keyword">var</span> status = <span class="hljs-keyword">await</span> client.GetStatusAsync(resource);
    <span class="hljs-keyword">if</span> (status == <span class="hljs-literal">null</span>)
    {
        <span class="hljs-keyword">await</span> client.StartNewAsync(<span class="hljs-keyword">nameof</span>(ScalingLogic), resource, <span class="hljs-keyword">new</span> ScalingState());
    }
    <span class="hljs-keyword">else</span>
    {
        <span class="hljs-keyword">var</span> metric = ServiceBusHelper.GetSubscriptionMetric(resource);
        log.Info(<span class="hljs-string">$"Collector: Current metric value is <span class="hljs-subst">{metric.Value.Value}</span> at <span class="hljs-subst">{DateTime.Now}</span>"</span>);
        <span class="hljs-keyword">await</span> client.RaiseEventAsync(resource, <span class="hljs-keyword">nameof</span>(Metric), metric);
    }
}
</code></pre>
<p>It&#39;s still a timer-triggered &quot;normal&quot; (non-durable) function, but now it 
also has an additional binding to <code>OrchestrationClient</code>. This client is used 
to communicate metric data to the <strong>Scaling Logic</strong>.</p>
<p>With the current implementation, <strong>Metric Collector</strong> also has a second
responsibility: actor instance management. At every iteration, it queries
for the current status of corresponding actor. If that is <code>null</code>, Collector
creates a new instance with initial empty state.</p>
<p>To my liking, this aspect is a bit unfortunate, but it seems to be required
with the current implementation of Durable Functions framework. See 
<a href="https://github.com/Azure/azure-functions-durable-extension/issues/21">my related question on github</a>.</p>
<h2 id="conclusions">Conclusions</h2>
<p>I adjusted the initial flow of autoscaling functions to use Durable Functions
library. It made the state management look more straightforward, and also
allowed direct communication between two functions in strongly-typed
request-response manner.</p>
<p>The resulting code is relatively clear and resembles the typical structure
of async-await code that C# developers are used to.</p>
<p>There are some downsides that I found about Durable Functions too:</p>
<ul>
<li><p>This is a very early preview, so there are some implementation issues.
A couple times I managed to put my functions into a state where they were stuck
and no calls could be made anymore. The only way I could get out of there is by
clearing some blobs in the Storage Account;</p>
</li>
<li><p>The actor instance management story feels raw. The function, which needs to
send events to actors, has to manage their lifecycle and instance IDs. I would
need to add some more checks to make the code production ready, e.g. to 
restart actors if they end up in faulty state;</p>
</li>
<li><p>There are some concurrency issues in function-to-function communication
to be resolved;</p>
</li>
<li><p>Some discipline is required to keep Durable functions side-effect free
and deterministic. The multiple executions caused by awaits and replays are
counter-intuitive (at least for novice devs), and thus error-prone.</p>
</li>
</ul>
<p>Having said that, I believe Durable Functions can be a very useful abstraction
to simplify some of the more advanced scenarios and workflows. I look
forward to further iterations of the library, and I will keep trying it out
for more scenarios.</p>

    </div>

    

    
    <div class="post-tags">
        Posted In: <a href='/tags/azure/'>Azure</a>, <a href='/tags/azure-functions/'>Azure Functions</a>, <a href='/tags/scalability/'>Scalability</a>, <a href='/tags/azure-app-service/'>Azure App Service</a>, <a href='/tags/azure-service-bus/'>Azure Service Bus</a>, <a href='/tags/durable-functions/'>Durable Functions</a>
    </div>
    
</article>


<div class="page-nav">
    
    <a class="page-nav-newer" href="/"><span class="icon icon-arrow-left-2"></span> Next page</a>
    
    
    <a class="page-nav-older" href="/3/">Previous page <span class="icon icon-arrow-right-2"></span></a>
    
</div>

<div id="me">
    <p itemscope itemtype="http://data-vocabulary.org/Person">
        <img src="/images/Headshot-Square.jpg" alt="Mikhail Shilkov" itemprop="photo" />
        I'm <b><span itemprop="name">Mikhail Shilkov</span></b>, a <span itemprop="title">software developer</span>. I enjoy F#, C#, Javascript and SQL development, reasoning about distributed systems, data processing pipelines, cloud and web apps. I blog about my experience on this website.
    </p>
    <p>
        <a href="https://www.linkedin.com/in/mikhailshilkov/">LinkedIn</a> &#8226;
        <a href="https://twitter.com/mikhailshilkov">@mikhailshilkov</a> &#8226;
        <a href="https://github.com/mikhailshilkov">GitHub</a> &#8226;
        <a href="https://stackoverflow.com/users/1171619/mikhail">Stack Overflow</a>
    </p>
</div>

</div>
<div class="container">
    <div class="navbar navbar-footer">
        <p class="navbar-center navbar-text">Content copyright &copy; 2017 Mikhail Shilkov</p>
    </div>
</div>



<script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
<script src="//netdna.bootstrapcdn.com/bootstrap/3.0.0/js/bootstrap.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.5/jquery.fancybox.pack.js"></script>
<script src="/vendor/highlight.pack.js"></script>
<script src="/site.js"></script>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59218480-1', 'auto');
  ga('send', 'pageview');

</script>
</body>
</html>